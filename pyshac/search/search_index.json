{
    "docs": [
        {
            "location": "/",
            "text": "PySHAC : Python Sequential Halving and Classification\n\u00b6\n\n\nPySHAC is a python library to use the Sequential Halving and Classification algorithm from the paper\n\nParallel Architecture and Hyperparameter Search via Successive Halving and Classification\n with ease.\n\n\nNote : This library is not affiliated with Google.\n\n\n\n\nDocumentation\n\u00b6\n\n\nStable build documentation can be found at \nPySHAC Documentation\n.\n\n\nIt contains a User Guide, as well as explanation of the different engines that can be used with PySHAC.\n\n\n\n\n\n\n\n\nTopic\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nInstallation\n\n\nhttp://titu1994.github.io/pyshac/install/\n\n\n\n\n\n\nUser Guide\n\n\nhttp://titu1994.github.io/pyshac/guide/\n\n\n\n\n\n\nManaged Engines\n\n\nhttp://titu1994.github.io/pyshac/managed/\n\n\n\n\n\n\nCustom Hyper Parameters\n\n\nhttp://titu1994.github.io/pyshac/custom-hyper-parameters/\n\n\n\n\n\n\nSerial Evaluation\n\n\nhttp://titu1994.github.io/pyshac/serial-execution/\n\n\n\n\n\n\nExternal Dataset Training\n\n\nhttp://titu1994.github.io/pyshac/external-dataset-training/\n\n\n\n\n\n\nCallbacks\n\n\nhttp://titu1994.github.io/pyshac/callbacks/\n\n\n\n\n\n\n\n\nInstallation\n\u00b6\n\n\nThis library is available for Python 2.7 and 3.4+ via pip for Windows, MacOSX and Linux.\n\n\npip\n \ninstall\n \npyshac\n\n\n\n\n\nTo install the master branch of this library :\n\n\ngit clone https://github.com/titu1994/pyshac.git\ncd pyshac\npip install .\n\nor pip install .[tests]  # to also include dependencies necessary for testing\n\n\n\n\nTo install the requirements before installing the library :\n\n\npip install -r \"requirements.txt\"\n\n\n\n\nTo build the docs, additional packages must be installed :\n\npip install -r \"doc_requirements.txt\"\n\n\n\nGetting started with PySHAC\n\u00b6\n\n\nFirst, build the set of hyper parameters. The three main HyperParameter classes are :\n\u00b6\n\n\n\n\nDiscreteHyperParameter\n\n\nUniformContinuousHyperParameter\n\n\nNormalContinuousHyperParameter\n\n\n\n\nThere are also 3 additional hyper parameters, which are useful when a parameter needs to be sampled multiple times\nfor each evaluation :\n\n\n\n\nMultiDiscreteHyperParameter\n\n\nMultiUniformContinuousHyperParameter\n\n\nMultiNormalContinuousHyperParameter\n\n\n\n\nThese multi parameters have an additional argument \nsample_count\n which can be used to sample multiple times\nper step.\n\n\nNote\n: The values will be concatenated linearly, so each multi parameter will have a list of values\nreturned in the resultant OrderedDict. If you wish to flatten the entire search space, you can\nuse \npyshac.flatten_parameters\n on this OrderedDict.\n\n\nimport\n \npyshac\n\n\n\n# Discrete parameters\n\n\ndice_rolls\n \n=\n \npyshac\n.\nDiscreteHyperParameter\n(\n'dice'\n,\n \nvalues\n=\n[\n1\n,\n \n2\n,\n \n3\n,\n \n4\n,\n \n5\n,\n \n6\n])\n\n\ncoin_flip\n \n=\n \npyshac\n.\nDiscreteHyperParameter\n(\n'coin'\n,\n \nvalues\n=\n[\n0\n,\n \n1\n])\n\n\n\n# Continuous Parameters\n\n\nclassifier_threshold\n \n=\n \npyshac\n.\nUniformContinuousHyperParameter\n(\n'threshold'\n,\n \nmin_value\n=\n0.0\n,\n \nmax_value\n=\n1.0\n)\n\n\nnoise\n \n=\n \npyshac\n.\nNormalContinuousHyperParameter\n(\n'noise'\n,\n \nmean\n=\n0.0\n,\n \nstd\n=\n1.0\n)\n\n\n\n\n\nSetup the engine\n\u00b6\n\n\nWhen setting up the SHAC engine, we need to define a few important parameters which will be used by the engine :\n\n\n\n\nHyper Parameter list\n: A list of parameters that have been declared. This will constitute the search space.\n\n\nTotal budget\n: The number of evaluations that will occur.\n\n\nNumber of batches\n: The number of samples per batch of evaluation.\n\n\nObjective\n: String value which can be either \nmax\n or \nmin\n. Defines whether the objective should be maximised or minimised.\n\n\nMaximum number of classifiers\n: As it suggests, decides the upper limit of how many classifiers can be trained. This is optional, and usually not required to specify.\n\n\n\n\nimport\n \nnumpy\n \nas\n \nnp\n\n\nimport\n \npyshac\n\n\n\n# define the parameters\n\n\nparam_x\n \n=\n \npyshac\n.\nUniformContinuousHyperParameter\n(\n'x'\n,\n \n-\n5.0\n,\n \n5.0\n)\n\n\nparam_y\n \n=\n \npyshac\n.\nUniformContinuousHyperParameter\n(\n'y'\n,\n \n-\n2.0\n,\n \n2.0\n)\n\n\n\nparameters\n \n=\n \n[\nparam_x\n,\n \nparam_y\n]\n\n\n\n# define the total budget as 100 evaluations\n\n\ntotal_budget\n \n=\n \n100\n  \n# 100 evaluations at maximum\n\n\n\n# define the number of batches\n\n\nnum_batches\n \n=\n \n10\n  \n# 10 samples per batch\n\n\n\n# define the objective\n\n\nobjective\n \n=\n \n'min'\n  \n# minimize the squared loss\n\n\n\nshac\n \n=\n \npyshac\n.\nSHAC\n(\nparameters\n,\n \ntotal_budget\n,\n \nnum_batches\n,\n \nobjective\n)\n\n\n\n\n\nTraining the classifiers\n\u00b6\n\n\nTo train a classifier, the user must define an Evaluation function. This is a user defined function,\nthat accepts 2 or more inputs as defined by the engine, and returns a python floating point value.\n\n\nThe \nEvaluation Function\n receives at least 2 inputs :\n\n\n\n\nWorker ID\n: Integer id that can be left alone when executing only on CPU or used to determine the iteration number in the current epoch of evaluation.\n\n\nParameter OrderedDict\n: An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.\n\n\nSince it is an ordered dict, if only the values are required, \nlist(parameters.values())\n can be used to get the list of values in the same order as when the Parameters were declared to the engine.\n\n\nThese are the values of the sampled hyper parameters which have passed through the current cascade of models.\n\n\n\n\n\n\n\n\nAn example of a defined evaluation function :\n\n\n# define the evaluation function\n\n\ndef\n \nsquared_error_loss\n(\nid\n,\n \nparameters\n):\n\n    \nx\n \n=\n \nparameters\n[\n'x'\n]\n\n    \ny\n \n=\n \nparameters\n[\n'y'\n]\n\n    \ny_sample\n \n=\n \n2\n \n*\n \nx\n \n-\n \ny\n\n\n    \n# assume best values of x and y and 2 and 0 respectively\n\n    \ny_true\n \n=\n \n4.\n\n\n    \nreturn\n \nnp\n.\nsquare\n(\ny_sample\n \n-\n \ny_true\n)\n\n\n\n\n\nA single call to \nshac.fit()\n will begin training the classifiers.\n\n\nThere are a few cases to consider:\n\n\n\n\nThere can be cases where the search space is not large enough to train the maximum number of classifier (usually 18).\n\n\nThere may be instances where we want to allow some relaxations of the constraint that the next batch must pass through all\nof the previous classifiers. This allows classifiers to train on the same search space repeatedly rather than divide the search space.\n\n\n\n\nIn these cases, we can utilize a few additional parameters to allow the training behaviour to better adapt to these circumstances.\nThese parameters are :\n\n\n\n\nskip_cv_checks\n: As it suggests, if the number of samples per batch is too small, it is preferable to skip the cross validation check, as most classifiers will not pass them.\n\n\nearly_stop\n: Determines whether training should halt as soon as an epoch of failed learning occurs. This is useful when evaluations are very costly.\n\n\nrelax_checks\n: This will instead relax the constrain of having the sample pass through all classifiers to having the classifier past through most of the classifiers. In doing so, more samples can be obtained for the same search space.\n\n\n\n\n# `early stopping` default is False, and it is preferred not to use it when using `relax checks`\n\n\nshac\n.\nfit\n(\nsquared_error_loss\n,\n \nskip_cv_checks\n=\nTrue\n,\n \nearly_stop\n=\nFalse\n,\n \nrelax_checks\n=\nTrue\n)\n\n\n\n\n\nSampling the best hyper parameters\n\u00b6\n\n\nOnce the models have been trained by the engine, it is as simple as calling \npredict()\n to sample multiple samples or batches of parameters.\n\n\nSamples can be obtained in a per instance or per batch (or even a combination) using the two parameters - \nnum_samples\n and \nnum_batches\n.\n\n\n# sample a single instance of hyper parameters\n\n\nparameter_samples\n \n=\n \nshac\n.\npredict\n()\n  \n# Gets 1 sample.\n\n\n\n# sample multiple instances of hyper parameters\n\n\nparameter_samples\n \n=\n \nshac\n.\npredict\n(\n10\n)\n  \n# Gets 10 samples.\n\n\n\n# sample a batch of hyper parameters\n\n\nparameter_samples\n \n=\n \nshac\n.\npredict\n(\nnum_batches\n=\n5\n)\n  \n# samples 5 batches, each containing 10 samples.\n\n\n\n# sample multiple batches and a few additional instances of hyper parameters\n\n\nparameter_samples\n \n=\n \nshac\n.\npredict\n(\n5\n,\n \n5\n)\n  \n# samples 5 batches (each containing 10 samples) and an additional 5 samples.\n\n\n\n\n\nExamples\n\u00b6\n\n\nExamples based on the \nBranin\n and \nHartmann6\n problems can be found in the \nExamples folder\n.\n\n\nAn example of how to use the \nTensorflowSHAC\n engine is provided \nin the example foldes as well\n.\n\n\nComparison scripts of basic optimization, \nBranin\n and \nHartmann6\n using Tensorflow Eager 1.8 are provided in the respective folders.\n\n\nEvaluation of Branin\n\u00b6\n\n\nBrannin to close to the true optima as described in the paper.\n\n\n\n\nEvaluation of Hardmann 6\n\u00b6\n\n\nHartmann 6 was a much harder dataset, and results are worse than Random Search 2x and the one from the paper. Perhaps it was due to a bad run, and may be fixed with larger budget for training.\n\n\n\n\nEvaluation of Simple Optimization Objective\n\u00b6\n\n\nThe task is to sample two parameters \nx\n and \ny\n, such that \nz = 2 * x - y\n and we want \nz\n to approach the value of 4. We utilize MSE \nas the metric between z and the optimal value.\n\n\n\n\nEvaluation of Hyper Parameter Optimization\n\u00b6\n\n\nThe task is to sample hyper parameters which provide high accuracy values using TensorflowSHAC engine.",
            "title": "Home"
        },
        {
            "location": "/#pyshac-python-sequential-halving-and-classification",
            "text": "PySHAC is a python library to use the Sequential Halving and Classification algorithm from the paper Parallel Architecture and Hyperparameter Search via Successive Halving and Classification  with ease.  Note : This library is not affiliated with Google.",
            "title": "PySHAC : Python Sequential Halving and Classification"
        },
        {
            "location": "/#documentation",
            "text": "Stable build documentation can be found at  PySHAC Documentation .  It contains a User Guide, as well as explanation of the different engines that can be used with PySHAC.     Topic  Link      Installation  http://titu1994.github.io/pyshac/install/    User Guide  http://titu1994.github.io/pyshac/guide/    Managed Engines  http://titu1994.github.io/pyshac/managed/    Custom Hyper Parameters  http://titu1994.github.io/pyshac/custom-hyper-parameters/    Serial Evaluation  http://titu1994.github.io/pyshac/serial-execution/    External Dataset Training  http://titu1994.github.io/pyshac/external-dataset-training/    Callbacks  http://titu1994.github.io/pyshac/callbacks/",
            "title": "Documentation"
        },
        {
            "location": "/#installation",
            "text": "This library is available for Python 2.7 and 3.4+ via pip for Windows, MacOSX and Linux.  pip   install   pyshac   To install the master branch of this library :  git clone https://github.com/titu1994/pyshac.git\ncd pyshac\npip install .\n\nor pip install .[tests]  # to also include dependencies necessary for testing  To install the requirements before installing the library :  pip install -r \"requirements.txt\"  To build the docs, additional packages must be installed : pip install -r \"doc_requirements.txt\"",
            "title": "Installation"
        },
        {
            "location": "/#getting-started-with-pyshac",
            "text": "",
            "title": "Getting started with PySHAC"
        },
        {
            "location": "/#first-build-the-set-of-hyper-parameters-the-three-main-hyperparameter-classes-are",
            "text": "DiscreteHyperParameter  UniformContinuousHyperParameter  NormalContinuousHyperParameter   There are also 3 additional hyper parameters, which are useful when a parameter needs to be sampled multiple times\nfor each evaluation :   MultiDiscreteHyperParameter  MultiUniformContinuousHyperParameter  MultiNormalContinuousHyperParameter   These multi parameters have an additional argument  sample_count  which can be used to sample multiple times\nper step.  Note : The values will be concatenated linearly, so each multi parameter will have a list of values\nreturned in the resultant OrderedDict. If you wish to flatten the entire search space, you can\nuse  pyshac.flatten_parameters  on this OrderedDict.  import   pyshac  # Discrete parameters  dice_rolls   =   pyshac . DiscreteHyperParameter ( 'dice' ,   values = [ 1 ,   2 ,   3 ,   4 ,   5 ,   6 ])  coin_flip   =   pyshac . DiscreteHyperParameter ( 'coin' ,   values = [ 0 ,   1 ])  # Continuous Parameters  classifier_threshold   =   pyshac . UniformContinuousHyperParameter ( 'threshold' ,   min_value = 0.0 ,   max_value = 1.0 )  noise   =   pyshac . NormalContinuousHyperParameter ( 'noise' ,   mean = 0.0 ,   std = 1.0 )",
            "title": "First, build the set of hyper parameters. The three main HyperParameter classes are :"
        },
        {
            "location": "/#setup-the-engine",
            "text": "When setting up the SHAC engine, we need to define a few important parameters which will be used by the engine :   Hyper Parameter list : A list of parameters that have been declared. This will constitute the search space.  Total budget : The number of evaluations that will occur.  Number of batches : The number of samples per batch of evaluation.  Objective : String value which can be either  max  or  min . Defines whether the objective should be maximised or minimised.  Maximum number of classifiers : As it suggests, decides the upper limit of how many classifiers can be trained. This is optional, and usually not required to specify.   import   numpy   as   np  import   pyshac  # define the parameters  param_x   =   pyshac . UniformContinuousHyperParameter ( 'x' ,   - 5.0 ,   5.0 )  param_y   =   pyshac . UniformContinuousHyperParameter ( 'y' ,   - 2.0 ,   2.0 )  parameters   =   [ param_x ,   param_y ]  # define the total budget as 100 evaluations  total_budget   =   100    # 100 evaluations at maximum  # define the number of batches  num_batches   =   10    # 10 samples per batch  # define the objective  objective   =   'min'    # minimize the squared loss  shac   =   pyshac . SHAC ( parameters ,   total_budget ,   num_batches ,   objective )",
            "title": "Setup the engine"
        },
        {
            "location": "/#training-the-classifiers",
            "text": "To train a classifier, the user must define an Evaluation function. This is a user defined function,\nthat accepts 2 or more inputs as defined by the engine, and returns a python floating point value.  The  Evaluation Function  receives at least 2 inputs :   Worker ID : Integer id that can be left alone when executing only on CPU or used to determine the iteration number in the current epoch of evaluation.  Parameter OrderedDict : An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.  Since it is an ordered dict, if only the values are required,  list(parameters.values())  can be used to get the list of values in the same order as when the Parameters were declared to the engine.  These are the values of the sampled hyper parameters which have passed through the current cascade of models.     An example of a defined evaluation function :  # define the evaluation function  def   squared_error_loss ( id ,   parameters ): \n     x   =   parameters [ 'x' ] \n     y   =   parameters [ 'y' ] \n     y_sample   =   2   *   x   -   y \n\n     # assume best values of x and y and 2 and 0 respectively \n     y_true   =   4. \n\n     return   np . square ( y_sample   -   y_true )   A single call to  shac.fit()  will begin training the classifiers.  There are a few cases to consider:   There can be cases where the search space is not large enough to train the maximum number of classifier (usually 18).  There may be instances where we want to allow some relaxations of the constraint that the next batch must pass through all\nof the previous classifiers. This allows classifiers to train on the same search space repeatedly rather than divide the search space.   In these cases, we can utilize a few additional parameters to allow the training behaviour to better adapt to these circumstances.\nThese parameters are :   skip_cv_checks : As it suggests, if the number of samples per batch is too small, it is preferable to skip the cross validation check, as most classifiers will not pass them.  early_stop : Determines whether training should halt as soon as an epoch of failed learning occurs. This is useful when evaluations are very costly.  relax_checks : This will instead relax the constrain of having the sample pass through all classifiers to having the classifier past through most of the classifiers. In doing so, more samples can be obtained for the same search space.   # `early stopping` default is False, and it is preferred not to use it when using `relax checks`  shac . fit ( squared_error_loss ,   skip_cv_checks = True ,   early_stop = False ,   relax_checks = True )",
            "title": "Training the classifiers"
        },
        {
            "location": "/#sampling-the-best-hyper-parameters",
            "text": "Once the models have been trained by the engine, it is as simple as calling  predict()  to sample multiple samples or batches of parameters.  Samples can be obtained in a per instance or per batch (or even a combination) using the two parameters -  num_samples  and  num_batches .  # sample a single instance of hyper parameters  parameter_samples   =   shac . predict ()    # Gets 1 sample.  # sample multiple instances of hyper parameters  parameter_samples   =   shac . predict ( 10 )    # Gets 10 samples.  # sample a batch of hyper parameters  parameter_samples   =   shac . predict ( num_batches = 5 )    # samples 5 batches, each containing 10 samples.  # sample multiple batches and a few additional instances of hyper parameters  parameter_samples   =   shac . predict ( 5 ,   5 )    # samples 5 batches (each containing 10 samples) and an additional 5 samples.",
            "title": "Sampling the best hyper parameters"
        },
        {
            "location": "/#examples",
            "text": "Examples based on the  Branin  and  Hartmann6  problems can be found in the  Examples folder .  An example of how to use the  TensorflowSHAC  engine is provided  in the example foldes as well .  Comparison scripts of basic optimization,  Branin  and  Hartmann6  using Tensorflow Eager 1.8 are provided in the respective folders.",
            "title": "Examples"
        },
        {
            "location": "/#evaluation-of-branin",
            "text": "Brannin to close to the true optima as described in the paper.",
            "title": "Evaluation of Branin"
        },
        {
            "location": "/#evaluation-of-hardmann-6",
            "text": "Hartmann 6 was a much harder dataset, and results are worse than Random Search 2x and the one from the paper. Perhaps it was due to a bad run, and may be fixed with larger budget for training.",
            "title": "Evaluation of Hardmann 6"
        },
        {
            "location": "/#evaluation-of-simple-optimization-objective",
            "text": "The task is to sample two parameters  x  and  y , such that  z = 2 * x - y  and we want  z  to approach the value of 4. We utilize MSE \nas the metric between z and the optimal value.",
            "title": "Evaluation of Simple Optimization Objective"
        },
        {
            "location": "/#evaluation-of-hyper-parameter-optimization",
            "text": "The task is to sample hyper parameters which provide high accuracy values using TensorflowSHAC engine.",
            "title": "Evaluation of Hyper Parameter Optimization"
        },
        {
            "location": "/install/",
            "text": "Installation\n\u00b6\n\n\n\n\nInstallation of this project is dependent on XGBoost, which has a slightly difficult installation process.\n\n\nInstalling XGBoost\n\u00b6\n\n\nSince this library depends heavily on XGBoost, we recommend following the installation instructions posted there\nfor installing XGBoost on your system.\n\n\nWe use the Scikit-Learn Python wrappers for XGBoost, which do not support GPU execution at the moment, and the models\nthemselves are trained on exceedingly small amounts of data, therefore we do not require GPU execution of XGBoost.\n\n\n\n\nXGBoost : Install Instructions\n\n\nOr via pip : \npip install --upgrade xgboost\n\n\n\n\n\n\nWindows Installation\n\n\nFor installation of XGBoost on Windows, it is preferred to use the unofficial binaries\nprovided here if you do not wish to build the project yourself :\n\n\nXGBoost : Unofficial Windows Binaries\n\n\n\n\nInstallation of PySHAC\n\u00b6\n\n\nOnce the XGBoost package is installed and verifier, we can simply clone this repository and run\n\npython setup.py install\n to install this package.\n\n\ngit clone https://github.com/titu1994/pyshac.git\ncd pyshac\npip install .\n\n\n\n\nInstallation of External Libraries\n\u00b6\n\n\nWhen using the managed engines, it is required to separately install external libraries such as :\n\n\n\n\nTensorflow\n\n\nPyTorch\n\n\nKeras",
            "title": "Installation"
        },
        {
            "location": "/install/#installation",
            "text": "Installation of this project is dependent on XGBoost, which has a slightly difficult installation process.",
            "title": "Installation"
        },
        {
            "location": "/install/#installing-xgboost",
            "text": "Since this library depends heavily on XGBoost, we recommend following the installation instructions posted there\nfor installing XGBoost on your system.  We use the Scikit-Learn Python wrappers for XGBoost, which do not support GPU execution at the moment, and the models\nthemselves are trained on exceedingly small amounts of data, therefore we do not require GPU execution of XGBoost.   XGBoost : Install Instructions  Or via pip :  pip install --upgrade xgboost    Windows Installation  For installation of XGBoost on Windows, it is preferred to use the unofficial binaries\nprovided here if you do not wish to build the project yourself :  XGBoost : Unofficial Windows Binaries",
            "title": "Installing XGBoost"
        },
        {
            "location": "/install/#installation-of-pyshac",
            "text": "Once the XGBoost package is installed and verifier, we can simply clone this repository and run python setup.py install  to install this package.  git clone https://github.com/titu1994/pyshac.git\ncd pyshac\npip install .",
            "title": "Installation of PySHAC"
        },
        {
            "location": "/install/#installation-of-external-libraries",
            "text": "When using the managed engines, it is required to separately install external libraries such as :   Tensorflow  PyTorch  Keras",
            "title": "Installation of External Libraries"
        },
        {
            "location": "/guide/",
            "text": "Guide\n\u00b6\n\n\n\n\nPySHAC has a very simple interface, which follows similar semantics to Scikit-Learn. Simply importing as below grants the majority of the functionality of the library.\n\n\nimport\n \npyshac\n\n\n\n\n\nThere are three main processes that are followed when using PySHAC :\n\n\n\n\n\n\nDeclaration of hyper parameters\n:\n\n\n\n\nHyper parameters can be discrete or continuous, and if continuous, be sampled from different distributions.\n\n\nAll hyper parameters must be defined before being passed to the engine.\n\n\n\n\n\n\n\n\nTraining of the models\n:\n\n\n\n\nOnce the parameters are defined, we create an instance of the engine.\n\n\nThis engine is passed an evaluation function that the user must write, along with the hyper parameter declarations and other parameters as required (such as total budget and number of batches)\n\n\nThe engine's \nfit()\n method is used to perform training of the classifiers.\n\n\nTraining can be stopped at any time between epochs. All models are serialized at the end of each epoch.\n\n\n\n\n\n\n\n\nSampling the best hyper parameters\n:\n\n\n\n\nUsing the serialized models, we can sample the search space in order to obtain the best hyper parameters possible.\n\n\nThis is done using the engine's \npredict()\n method.\n\n\n\n\n\n\n\n\nImportant Note for Windows Platform\n\u00b6\n\n\n\n\nWarning\n\n\nThe \nfit\n and \npredict\n methods \nmust be called only from inside of a \nif __name__ == '__main__'\n block.\n when using the \nmultiprocessing\n backend.\nThis is no longer an issue when using the \nloky\n backend (default).\n\n\nThis is a limitation of how Windows does not support forking, and so the engine definition and its methods must be called\ninside of a \n__main__\n block when using the \nmultiprocessing\n backend.\n\n\nIt is simpler to put this code inside of a function, and simply call this function from the \n__main__\n block\nto have better readability of code.\n\n\n\n\nDeclaration of Hyper Parameters\n\u00b6\n\n\n\n\nThere are 3 available hyper parameters made available :\n\n\n\n\nDiscreteHyperParameter\n\n\nUniformContinuousHyperParameter\n\n\nNormalContinuousHyperParameter\n\n\n\n\nThere are also 3 additional hyper parameters, which are useful when a parameter needs to be sampled multiple times\nfor each evaluation :\n\n\n\n\nMultiDiscreteHyperParameter\n\n\nMultiUniformContinuousHyperParameter\n\n\nMultiNormalContinuousHyperParameter\n\n\n\n\nThese multi parameters have an additional argument \nsample_count\n which can be used to sample multiple times\nper step.\n\n\n\n\nNote\n\n\nThe values will be concatenated linearly, so each multi parameter will have a list of values\nreturned in the resultant OrderedDict. If you wish to flatten the entire search space, you can\nuse \npyshac.flatten_parameters\n on this OrderedDict.\n\n\n\n\nWhile these can declare most of the common hyper parameters, if there is a need for custom hyper parameters, then they\ncan very easily be added as shown in \nCustom Hyper Parameters\n.\n\n\n\n\nNaming hyper parameters\n\u00b6\n\n\nFor the engine to work correctly, all hyper parameters must have \nunique names\n associated with them.\n\n\nThese names are the keyword arguments of the dictionary received by the evaluation function, so we can get the value\nof the sample by this name inside the evaluation function.\n\n\n\n\nDeclaring hyper parameters\n\u00b6\n\n\nDeclaring hyper parameters is as easy as follows :\n\n\nimport\n \npyshac\n\n\n\n# Discrete parameters\n\n\ndice_rolls\n \n=\n \npyshac\n.\nDiscreteHyperParameter\n(\n'dice'\n,\n \nvalues\n=\n[\n1\n,\n \n2\n,\n \n3\n,\n \n4\n,\n \n5\n,\n \n6\n])\n\n\ncoin_flip\n \n=\n \npyshac\n.\nDiscreteHyperParameter\n(\n'coin'\n,\n \nvalues\n=\n[\n0\n,\n \n1\n])\n\n\n\n# Continuous Parameters\n\n\nclassifier_threshold\n \n=\n \npyshac\n.\nUniformContinuousHyperParameter\n(\n'threshold'\n,\n \nmin_value\n=\n0.0\n,\n \nmax_value\n=\n1.0\n)\n\n\nnoise\n \n=\n \npyshac\n.\nNormalContinuousHyperParameter\n(\n'noise'\n,\n \nmean\n=\n0.0\n,\n \nstd\n=\n1.0\n)\n\n\n\n\n\nTraining of Models\n\u00b6\n\n\nThere are multiple engines available for use, and their use case differs based on what work is being done.\nFor this guide, we are considering our task will be accomplished with python classifiers (XGBoost, Scikit-Learn etc)\nwhich do not depend on GPU acceleration.\n\n\nHowever, when working with Tensorflow, PyTorch or Keras models, it is advisable to use the appropriate engine.\nMore information can be found in \nManaged Engines\n.\n\n\n\n\nSetting up the engine\n\u00b6\n\n\nWhen setting up the SHAC engine, we need to define a few important parameters which will be used by the engine :\n\n\n\n\nHyper Parameter list\n: A list of parameters that have been declared. This will constitute the search space.\n\n\nTotal budget\n: The number of evaluations that will occur.\n\n\nNumber of batches\n: The number of batches per epoch of evaluation.\n\n\nObjective\n: String value which can be either \nmax\n or \nmin\n. Defines whether the objective should be maximised or minimised.\n\n\nMaximum number of classifiers\n: As it suggests, decides the upper limit of how many classifiers can be trained. This is optional, and usually not required to specify.\n\n\n\n\n\n\nWarning\n\n\nThe total budget needs to be divisible by the number of batches, since all evaluations need to have the same number of samples.\nThis eases the training of models as well, since we can be sure of how many samples are present after each epoch.\n\n\n\n\nEvaluation Function\n receives 2 inputs :\n\n\n\n\nWorker ID\n: Integer id that can be left alone when executing only on CPU or used to determine the iteration number in the current epoch of evaluation.\n\n\nParameter OrderedDict\n: An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.\n\n\nSince it is an ordered dict, if only the values are required, \nlist(parameters.values())\n can be used to get the list of values in the same order as when the Parameters were declared to the engine.\n\n\nThese are the values of the sampled hyper parameters which have passed through the current cascade of models.\n\n\n\n\n\n\n\n\nThese parameters can be easily defined as :\n\n\nimport\n \nnumpy\n \nas\n \nnp\n\n\nimport\n \npyshac\n\n\n\nif\n \n__name__\n \n==\n \n'__main__'\n:\n  \n# this is required for Windows ; not for Unix or Linux\n\n\n    \n# define the parameters\n\n    \nparam_x\n \n=\n \npyshac\n.\nUniformContinuousHyperParameter\n(\n'x'\n,\n \n-\n5.0\n,\n \n5.0\n)\n\n    \nparam_y\n \n=\n \npyshac\n.\nUniformContinuousHyperParameter\n(\n'y'\n,\n \n-\n2.0\n,\n \n2.0\n)\n\n\n    \nparameters\n \n=\n \n[\nparam_x\n,\n \nparam_y\n]\n\n\n    \n# define the total budget as 100 evaluations\n\n    \ntotal_budget\n \n=\n \n100\n  \n# 100 evaluations at maximum\n\n\n    \n# define the number of batches\n\n    \nnum_batches\n \n=\n \n10\n  \n# 10 samples per batch\n\n\n    \n# define the objective\n\n    \nobjective\n \n=\n \n'min'\n  \n# minimize the squared loss\n\n\n    \nshac\n \n=\n \npyshac\n.\nSHAC\n(\nparameters\n,\n \ntotal_budget\n,\n \nnum_batches\n,\n \nobjective\n)\n\n\n\n\n\nWhile this looks like a lot, these few lines are in essence all that is required to define the search space,\nthe evaluation measure and the engine.\n\n\nTraining the classifiers\n\u00b6\n\n\nTo train a classifier, the user must define an Evaluation function. This is a user defined function,\nthat accepts 2 or more inputs as defined by the engine, and returns a python floating point value.\n\n\nThe \nEvaluation Function\n receives at least 2 inputs :\n\n\n\n\nWorker ID\n: Integer id that can be left alone when executing only on CPU or used to determine the iteration number in the current epoch of evaluation.\n\n\nParameter OrderedDict\n: An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.\n\n\nSince it is an ordered dict, if only the values are required, \nlist(parameters.values())\n can be used to get the list of values in the same order as when the Parameters were declared to the engine.\n\n\nThese are the values of the sampled hyper parameters which have passed through the current cascade of models.\n\n\n\n\n\n\n\n\nAn example of a defined evaluation function :\n\n\n# define the evaluation function\n\n\ndef\n \nsquared_error_loss\n(\nid\n,\n \nparameters\n):\n\n    \nx\n \n=\n \nparameters\n[\n'x'\n]\n\n    \ny\n \n=\n \nparameters\n[\n'y'\n]\n\n    \ny_sample\n \n=\n \n2\n \n*\n \nx\n \n-\n \ny\n\n\n    \n# assume best values of x and y and 2 and 0 respectively\n\n    \ny_true\n \n=\n \n4.\n\n\n    \nreturn\n \nnp\n.\nsquare\n(\ny_sample\n \n-\n \ny_true\n)\n\n\n\n\n\nOnce the engine has been created, then it is simply a matter of calling \nfit()\n on the engine with the evaluation function\nas the parameter. This will create the worker threads, generate the samples, test them if they pass all of the current\nclassifiers, prepare the dataset for that batch, test a cross validated classifier to see if it will train properly on\nthe dataset, finally train a classifier and then begin the next epoch.\n\n\n# assuming shac here is from the above code inside __main__\n\n\nshac\n.\nfit\n(\nsquared_error_loss\n)\n\n\n\n\n\nThere are a few cases to consider:\n\n\n\n\nThere can be cases where the search space is not large enough to train the maximum number of classifier (usually 18).\n\n\nThere may be instances where we want to allow some relaxations of the constraint that the next batch must pass through all\nof the previous classifiers. This allows classifiers to train on the same search space repeatedly rather than divide the search space.\n\n\n\n\nIn these cases, we can utilize additional arguments to allow the training behaviour to better adapt to these circumstances.\nThese parameters are :\n\n\n\n\nskip_cv_checks\n: As it suggests, if the number of samples per batch is too small, it is preferable to skip the cross validation check, as most classifiers will not pass them.\n\n\nearly_stop\n: Determines whether training should halt as soon as an epoch of failed learning occurs. This is useful when evaluations are very costly.\n\n\nrelax_checks\n: This will instead relax the constrain of having the sample pass through all classifiers to having the classifier past through most of the classifiers. In doing so, more samples can be obtained for the same search space.\n\n\n\n\n# `early stopping` default is False, and it is preferred not to use it when using `relax checks`\n\n\nshac\n.\nfit\n(\nsquared_error_loss\n,\n \nskip_cv_checks\n=\nTrue\n,\n \nearly_stop\n=\nFalse\n,\n \nrelax_checks\n=\nTrue\n)\n\n\n\n\n\nSampling the best hyper parameters\n\u00b6\n\n\nOnce the models have been trained by the engine, it is as simple as calling \npredict()\n to sample multiple samples or batches of parameters.\n\n\nSamples can be obtained in a per instance or per batch (or even a combination) using the two parameters - \nnum_samples\n and \nnum_batches\n.\n\n\n# sample a single instance of hyper parameters\n\n\nparameter_samples\n \n=\n \nshac\n.\npredict\n()\n  \n# Gets 1 sample.\n\n\n\n# sample multiple instances of hyper parameters\n\n\nparameter_samples\n \n=\n \nshac\n.\npredict\n(\n10\n)\n  \n# Gets 10 samples.\n\n\n\n# sample a batch of hyper parameters\n\n\nparameter_samples\n \n=\n \nshac\n.\npredict\n(\nnum_batches\n=\n5\n)\n  \n# Samples 5 batches, each containing 10 samples.\n\n\n\n# sample multiple batches and a few additional instances of hyper parameters\n\n\nparameter_samples\n \n=\n \nshac\n.\npredict\n(\n5\n,\n \n5\n)\n  \n# Samples 5 batches (each containing 10 samples) and an additional 5 samples.\n\n\n\n\n\nDealing with long sampling time\n\u00b6\n\n\nWhen using a very large number of classifiers (default of 18), it may take an enormous amount of time to sample a single\nhyper parameter list, let alone a batch. Therefore, it is more efficient to reduce the checks if necessary by using a few parameters.\n\n\n\n\n\n\nnum_workers_per_batch\n:\n\n\n\n\nWhen using a large number of samples or large number of classifiers, it is advisable to have many parallel workers sampling batches at the same time to reduce the amount of time taken to get samples that pass through all classifiers.\n\n\nWhen using a small number of samples or small number of classifiers, it is advisable to reduce the time taken to sample each batch by reducing the number of parallel workers.\n\n\nIf left as \nNone\n, will determine the value that was used during training.\n\n\n\n\n\n\n\n\nrelax_checks\n: Same as for training, relaxes the checks during evaluation to sample parameters faster.\n\n\n\n\nmax_classfiers\n: Another way to reduce the time taken to sample parameters is to simply reduce the number of classifiers used to perform the check. This will use the first \nK\n classifier stages to perform the checks.\n\n\n\n\n# number of sample is 16, so using 16 processes to sample in parallel is more efficient than the default memory conservative count.\n\n\nparameter_samples\n \n=\n \nshac\n.\npredict\n(\n16\n,\n \nnum_workers_per_batch\n=\n16\n,\n \nrelax_checks\n=\nTrue\n,\n \nmax_classfiers\n=\n16\n)\n\n\n\n\n\nContinuing Training\n\u00b6\n\n\nAs mentioned at the beginning of this guide, training can be stopped at any time after an epoch has finished.\nAfter this, training run can be resumed from the last epoch successfully trained with only slight changes to how we\ndefine and use the engine before using \nfit()\n.\n\n\nThere are a few steps, and a few important cautions that must be taken when continuing training :\n\n\n\n\nCreate an instance of the engine in the same location as where the earlier model was trained.\n\n\nIt must be provided the same evaluation measure as before.\n\n\nIt is optional to provide the hyper parameter list. It is not required as it will be replaced by the parameters in the file.\n\n\nIf training further, \nit is essential to use the same \ntotal_budget\n, \nbatch_size\n and \nobjective\n as before.\n\n\nIf only evaluating the trained classifiers, using any value of \ntotal_budget\n is allowed (though the earlier value is better for consistency), however it must be divisible by \nbatch_size\n and the \nobjective\n must be same as before.\n\n\nWhen restoring data, it must find the \nshac\n folder and all of the sub-folders in the same directory level.\n\n\n\n\n\n\nCall \nrestore_data()\n on the engine. It will print out the number of samples and the number of classifiers it was able to find and load.\n\n\nCall \nfit()\n or \npredict()\n as before.\n\n\n\n\nIn doing so, the engine instance will be restored to the exact state as in the previous training session, and the new classifiers can be trained as normal.\n\n\nExample :\n\n\n# Reduced batch_size allows faster sampling\n\n\n# None for the hyper parameter list as it will be loaded in the restoration step.\n\n\nnew_shac\n \n=\n \npyshac\n.\nSHAC\n(\nNone\n,\n \ntotal_budget\n,\n \nbatch_size\n=\n5\n,\n \nobjective\n=\nobjective\n)\n\n\n\n# restore the engine\n\n\nnew_shac\n.\nrestore_data\n()\n\n\n\n# predict or train like before\n\n\nnew_shac\n.\nfit\n(\nsquared_error_loss\n)\n\n\n\nor\n\n\n\nsamples\n \n=\n \nnew_shac\n.\npredict\n()",
            "title": "User Guide"
        },
        {
            "location": "/guide/#guide",
            "text": "PySHAC has a very simple interface, which follows similar semantics to Scikit-Learn. Simply importing as below grants the majority of the functionality of the library.  import   pyshac   There are three main processes that are followed when using PySHAC :    Declaration of hyper parameters :   Hyper parameters can be discrete or continuous, and if continuous, be sampled from different distributions.  All hyper parameters must be defined before being passed to the engine.     Training of the models :   Once the parameters are defined, we create an instance of the engine.  This engine is passed an evaluation function that the user must write, along with the hyper parameter declarations and other parameters as required (such as total budget and number of batches)  The engine's  fit()  method is used to perform training of the classifiers.  Training can be stopped at any time between epochs. All models are serialized at the end of each epoch.     Sampling the best hyper parameters :   Using the serialized models, we can sample the search space in order to obtain the best hyper parameters possible.  This is done using the engine's  predict()  method.",
            "title": "Guide"
        },
        {
            "location": "/guide/#important-note-for-windows-platform",
            "text": "Warning  The  fit  and  predict  methods  must be called only from inside of a  if __name__ == '__main__'  block.  when using the  multiprocessing  backend.\nThis is no longer an issue when using the  loky  backend (default).  This is a limitation of how Windows does not support forking, and so the engine definition and its methods must be called\ninside of a  __main__  block when using the  multiprocessing  backend.  It is simpler to put this code inside of a function, and simply call this function from the  __main__  block\nto have better readability of code.",
            "title": "Important Note for Windows Platform"
        },
        {
            "location": "/guide/#declaration-of-hyper-parameters",
            "text": "There are 3 available hyper parameters made available :   DiscreteHyperParameter  UniformContinuousHyperParameter  NormalContinuousHyperParameter   There are also 3 additional hyper parameters, which are useful when a parameter needs to be sampled multiple times\nfor each evaluation :   MultiDiscreteHyperParameter  MultiUniformContinuousHyperParameter  MultiNormalContinuousHyperParameter   These multi parameters have an additional argument  sample_count  which can be used to sample multiple times\nper step.   Note  The values will be concatenated linearly, so each multi parameter will have a list of values\nreturned in the resultant OrderedDict. If you wish to flatten the entire search space, you can\nuse  pyshac.flatten_parameters  on this OrderedDict.   While these can declare most of the common hyper parameters, if there is a need for custom hyper parameters, then they\ncan very easily be added as shown in  Custom Hyper Parameters .",
            "title": "Declaration of Hyper Parameters"
        },
        {
            "location": "/guide/#naming-hyper-parameters",
            "text": "For the engine to work correctly, all hyper parameters must have  unique names  associated with them.  These names are the keyword arguments of the dictionary received by the evaluation function, so we can get the value\nof the sample by this name inside the evaluation function.",
            "title": "Naming hyper parameters"
        },
        {
            "location": "/guide/#declaring-hyper-parameters",
            "text": "Declaring hyper parameters is as easy as follows :  import   pyshac  # Discrete parameters  dice_rolls   =   pyshac . DiscreteHyperParameter ( 'dice' ,   values = [ 1 ,   2 ,   3 ,   4 ,   5 ,   6 ])  coin_flip   =   pyshac . DiscreteHyperParameter ( 'coin' ,   values = [ 0 ,   1 ])  # Continuous Parameters  classifier_threshold   =   pyshac . UniformContinuousHyperParameter ( 'threshold' ,   min_value = 0.0 ,   max_value = 1.0 )  noise   =   pyshac . NormalContinuousHyperParameter ( 'noise' ,   mean = 0.0 ,   std = 1.0 )",
            "title": "Declaring hyper parameters"
        },
        {
            "location": "/guide/#training-of-models",
            "text": "There are multiple engines available for use, and their use case differs based on what work is being done.\nFor this guide, we are considering our task will be accomplished with python classifiers (XGBoost, Scikit-Learn etc)\nwhich do not depend on GPU acceleration.  However, when working with Tensorflow, PyTorch or Keras models, it is advisable to use the appropriate engine.\nMore information can be found in  Managed Engines .",
            "title": "Training of Models"
        },
        {
            "location": "/guide/#setting-up-the-engine",
            "text": "When setting up the SHAC engine, we need to define a few important parameters which will be used by the engine :   Hyper Parameter list : A list of parameters that have been declared. This will constitute the search space.  Total budget : The number of evaluations that will occur.  Number of batches : The number of batches per epoch of evaluation.  Objective : String value which can be either  max  or  min . Defines whether the objective should be maximised or minimised.  Maximum number of classifiers : As it suggests, decides the upper limit of how many classifiers can be trained. This is optional, and usually not required to specify.    Warning  The total budget needs to be divisible by the number of batches, since all evaluations need to have the same number of samples.\nThis eases the training of models as well, since we can be sure of how many samples are present after each epoch.   Evaluation Function  receives 2 inputs :   Worker ID : Integer id that can be left alone when executing only on CPU or used to determine the iteration number in the current epoch of evaluation.  Parameter OrderedDict : An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.  Since it is an ordered dict, if only the values are required,  list(parameters.values())  can be used to get the list of values in the same order as when the Parameters were declared to the engine.  These are the values of the sampled hyper parameters which have passed through the current cascade of models.     These parameters can be easily defined as :  import   numpy   as   np  import   pyshac  if   __name__   ==   '__main__' :    # this is required for Windows ; not for Unix or Linux \n\n     # define the parameters \n     param_x   =   pyshac . UniformContinuousHyperParameter ( 'x' ,   - 5.0 ,   5.0 ) \n     param_y   =   pyshac . UniformContinuousHyperParameter ( 'y' ,   - 2.0 ,   2.0 ) \n\n     parameters   =   [ param_x ,   param_y ] \n\n     # define the total budget as 100 evaluations \n     total_budget   =   100    # 100 evaluations at maximum \n\n     # define the number of batches \n     num_batches   =   10    # 10 samples per batch \n\n     # define the objective \n     objective   =   'min'    # minimize the squared loss \n\n     shac   =   pyshac . SHAC ( parameters ,   total_budget ,   num_batches ,   objective )   While this looks like a lot, these few lines are in essence all that is required to define the search space,\nthe evaluation measure and the engine.",
            "title": "Setting up the engine"
        },
        {
            "location": "/guide/#training-the-classifiers",
            "text": "To train a classifier, the user must define an Evaluation function. This is a user defined function,\nthat accepts 2 or more inputs as defined by the engine, and returns a python floating point value.  The  Evaluation Function  receives at least 2 inputs :   Worker ID : Integer id that can be left alone when executing only on CPU or used to determine the iteration number in the current epoch of evaluation.  Parameter OrderedDict : An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.  Since it is an ordered dict, if only the values are required,  list(parameters.values())  can be used to get the list of values in the same order as when the Parameters were declared to the engine.  These are the values of the sampled hyper parameters which have passed through the current cascade of models.     An example of a defined evaluation function :  # define the evaluation function  def   squared_error_loss ( id ,   parameters ): \n     x   =   parameters [ 'x' ] \n     y   =   parameters [ 'y' ] \n     y_sample   =   2   *   x   -   y \n\n     # assume best values of x and y and 2 and 0 respectively \n     y_true   =   4. \n\n     return   np . square ( y_sample   -   y_true )   Once the engine has been created, then it is simply a matter of calling  fit()  on the engine with the evaluation function\nas the parameter. This will create the worker threads, generate the samples, test them if they pass all of the current\nclassifiers, prepare the dataset for that batch, test a cross validated classifier to see if it will train properly on\nthe dataset, finally train a classifier and then begin the next epoch.  # assuming shac here is from the above code inside __main__  shac . fit ( squared_error_loss )   There are a few cases to consider:   There can be cases where the search space is not large enough to train the maximum number of classifier (usually 18).  There may be instances where we want to allow some relaxations of the constraint that the next batch must pass through all\nof the previous classifiers. This allows classifiers to train on the same search space repeatedly rather than divide the search space.   In these cases, we can utilize additional arguments to allow the training behaviour to better adapt to these circumstances.\nThese parameters are :   skip_cv_checks : As it suggests, if the number of samples per batch is too small, it is preferable to skip the cross validation check, as most classifiers will not pass them.  early_stop : Determines whether training should halt as soon as an epoch of failed learning occurs. This is useful when evaluations are very costly.  relax_checks : This will instead relax the constrain of having the sample pass through all classifiers to having the classifier past through most of the classifiers. In doing so, more samples can be obtained for the same search space.   # `early stopping` default is False, and it is preferred not to use it when using `relax checks`  shac . fit ( squared_error_loss ,   skip_cv_checks = True ,   early_stop = False ,   relax_checks = True )",
            "title": "Training the classifiers"
        },
        {
            "location": "/guide/#sampling-the-best-hyper-parameters",
            "text": "Once the models have been trained by the engine, it is as simple as calling  predict()  to sample multiple samples or batches of parameters.  Samples can be obtained in a per instance or per batch (or even a combination) using the two parameters -  num_samples  and  num_batches .  # sample a single instance of hyper parameters  parameter_samples   =   shac . predict ()    # Gets 1 sample.  # sample multiple instances of hyper parameters  parameter_samples   =   shac . predict ( 10 )    # Gets 10 samples.  # sample a batch of hyper parameters  parameter_samples   =   shac . predict ( num_batches = 5 )    # Samples 5 batches, each containing 10 samples.  # sample multiple batches and a few additional instances of hyper parameters  parameter_samples   =   shac . predict ( 5 ,   5 )    # Samples 5 batches (each containing 10 samples) and an additional 5 samples.",
            "title": "Sampling the best hyper parameters"
        },
        {
            "location": "/guide/#dealing-with-long-sampling-time",
            "text": "When using a very large number of classifiers (default of 18), it may take an enormous amount of time to sample a single\nhyper parameter list, let alone a batch. Therefore, it is more efficient to reduce the checks if necessary by using a few parameters.    num_workers_per_batch :   When using a large number of samples or large number of classifiers, it is advisable to have many parallel workers sampling batches at the same time to reduce the amount of time taken to get samples that pass through all classifiers.  When using a small number of samples or small number of classifiers, it is advisable to reduce the time taken to sample each batch by reducing the number of parallel workers.  If left as  None , will determine the value that was used during training.     relax_checks : Same as for training, relaxes the checks during evaluation to sample parameters faster.   max_classfiers : Another way to reduce the time taken to sample parameters is to simply reduce the number of classifiers used to perform the check. This will use the first  K  classifier stages to perform the checks.   # number of sample is 16, so using 16 processes to sample in parallel is more efficient than the default memory conservative count.  parameter_samples   =   shac . predict ( 16 ,   num_workers_per_batch = 16 ,   relax_checks = True ,   max_classfiers = 16 )",
            "title": "Dealing with long sampling time"
        },
        {
            "location": "/guide/#continuing-training",
            "text": "As mentioned at the beginning of this guide, training can be stopped at any time after an epoch has finished.\nAfter this, training run can be resumed from the last epoch successfully trained with only slight changes to how we\ndefine and use the engine before using  fit() .  There are a few steps, and a few important cautions that must be taken when continuing training :   Create an instance of the engine in the same location as where the earlier model was trained.  It must be provided the same evaluation measure as before.  It is optional to provide the hyper parameter list. It is not required as it will be replaced by the parameters in the file.  If training further,  it is essential to use the same  total_budget ,  batch_size  and  objective  as before.  If only evaluating the trained classifiers, using any value of  total_budget  is allowed (though the earlier value is better for consistency), however it must be divisible by  batch_size  and the  objective  must be same as before.  When restoring data, it must find the  shac  folder and all of the sub-folders in the same directory level.    Call  restore_data()  on the engine. It will print out the number of samples and the number of classifiers it was able to find and load.  Call  fit()  or  predict()  as before.   In doing so, the engine instance will be restored to the exact state as in the previous training session, and the new classifiers can be trained as normal.  Example :  # Reduced batch_size allows faster sampling  # None for the hyper parameter list as it will be loaded in the restoration step.  new_shac   =   pyshac . SHAC ( None ,   total_budget ,   batch_size = 5 ,   objective = objective )  # restore the engine  new_shac . restore_data ()  # predict or train like before  new_shac . fit ( squared_error_loss )  or  samples   =   new_shac . predict ()",
            "title": "Continuing Training"
        },
        {
            "location": "/serial-execution/",
            "text": "Serial Execution of Evaluation Functions\n\u00b6\n\n\n\n\nFor all engines, to be efficient and reduce execution time, sample generation, and training of models is done using\nJoblib and Loky. However, the evaluation function cannot be managed by the training module, since it is a function written by the user.\n\n\nAs such, to offer maximum flexibility, we offer two alternatives :\n\n\n\n\nSerial Evaluation\n\n\nManaged Evaluations\n\n\n\n\nSerial Evaluation\n\u00b6\n\n\nDue to the need for forcing serial execution of the evaluation functions, there are 2 parameters exposed for all\nengines :\n\n\n\n\nnum_parallel_evaluators\n : Set this to \n1\n for serial execution of the evaluation function\n\n\nevaluator_backend\n : This is generally set to \nloky\n, but should be set to \nthreading\n for serial execution.\n\n\n\n\nshac\n \n=\n \nSHAC\n([\nparams\n...\n],\n \ntotal_budget\n,\n \nbatch_size\n)\n\n\n\n# This sets the engine to serial execution\n\n\nshac\n.\nset_num_parallel_evaluators\n(\n1\n)\n\n\nshac\n.\nconcurrent_evaluators\n()\n\n\n\n\n\nSimilarly, if for some reason you wish to force serial execution of the generators, there are 2 parameters exposed fpr all\nengines :\n\n\n\n\nnum_parallel_generators\n : Set this to \n1\n for serial execution of the evaluation function\n\n\ngenerator_backend\n : This is generally set to \nloky\n, but should be set to \nthreading\n for serial execution.\n\n\n\n\nshac\n \n=\n \nSHAC\n([\nparams\n...\n],\n \ntotal_budget\n,\n \nbatch_size\n)\n\n\n\n# This sets the engine to serial execution\n\n\nshac\n.\nset_num_parallel_generators\n(\n1\n)\n\n\nshac\n.\nparallel_evaluators\n()\n\n\n\n\n\n\n\nHelper functions for backends\n\n\nAll engines support two methods : \nparallel_evaluators()\n and \nconcurrent_evaluators()\n.\nUsing this will set the engine to use the \nloky\n and \nthreading\n backend respectively.\n\n\nDue to Python's Global Interpreter Lock, it is possible to use the \nthreading\n backend to\nreduce the number of parallel executions. However, these models are still executed concurrently,\ntherefore it must be ensured that the evaluators do not exhaust the system RAM / GPU RAM.\n\n\n\n\nManaged Evaluations\n\u00b6\n\n\nWhen using PySHAC for neural network hyper parameter searches or architecture generation, it would be extremely slow to\nevaluate each model sequentially.\n\n\nTherefore, there are extensions to the core engine, called \nTensorflowSHAC\n and \nKerasSHAC\n. These provide a managed backend,\ncreate seperate graphs for each core of execution and offer some parallel evaluation management.\n\n\n\n\n\n\nTorchSHAC\n : Provides a wrapper over \nSHAC\n so as to provide a unified interface alongside\nthe other managed session. Makes it simpler to explicitly set the parallelism of the evaluators.\n\n\n\n\n\n\nTensorflowSHAC\n : Provides a \ntf.Session\n alongside the worker id and the sampled parameters. This session is wrapped\nby the evaluation, so all tensors created inside the evaluation function can be run using this session. The graph can be\nobtained using the generic \ntf.get_default_graph()\n, if required.\n\n\n\n\n\n\nKerasSHAC\n : Provides a managed session similar to \nTensorflowSHAC\n, but can be possibly used with other backends. Since\nTheano does not support memory management (deletion of old models), only Tensorflow and CNTK backends are supported for\nthe moment.",
            "title": "Serial Evaluation"
        },
        {
            "location": "/serial-execution/#serial-execution-of-evaluation-functions",
            "text": "For all engines, to be efficient and reduce execution time, sample generation, and training of models is done using\nJoblib and Loky. However, the evaluation function cannot be managed by the training module, since it is a function written by the user.  As such, to offer maximum flexibility, we offer two alternatives :   Serial Evaluation  Managed Evaluations",
            "title": "Serial Execution of Evaluation Functions"
        },
        {
            "location": "/serial-execution/#serial-evaluation",
            "text": "Due to the need for forcing serial execution of the evaluation functions, there are 2 parameters exposed for all\nengines :   num_parallel_evaluators  : Set this to  1  for serial execution of the evaluation function  evaluator_backend  : This is generally set to  loky , but should be set to  threading  for serial execution.   shac   =   SHAC ([ params ... ],   total_budget ,   batch_size )  # This sets the engine to serial execution  shac . set_num_parallel_evaluators ( 1 )  shac . concurrent_evaluators ()   Similarly, if for some reason you wish to force serial execution of the generators, there are 2 parameters exposed fpr all\nengines :   num_parallel_generators  : Set this to  1  for serial execution of the evaluation function  generator_backend  : This is generally set to  loky , but should be set to  threading  for serial execution.   shac   =   SHAC ([ params ... ],   total_budget ,   batch_size )  # This sets the engine to serial execution  shac . set_num_parallel_generators ( 1 )  shac . parallel_evaluators ()    Helper functions for backends  All engines support two methods :  parallel_evaluators()  and  concurrent_evaluators() .\nUsing this will set the engine to use the  loky  and  threading  backend respectively.  Due to Python's Global Interpreter Lock, it is possible to use the  threading  backend to\nreduce the number of parallel executions. However, these models are still executed concurrently,\ntherefore it must be ensured that the evaluators do not exhaust the system RAM / GPU RAM.",
            "title": "Serial Evaluation"
        },
        {
            "location": "/serial-execution/#managed-evaluations",
            "text": "When using PySHAC for neural network hyper parameter searches or architecture generation, it would be extremely slow to\nevaluate each model sequentially.  Therefore, there are extensions to the core engine, called  TensorflowSHAC  and  KerasSHAC . These provide a managed backend,\ncreate seperate graphs for each core of execution and offer some parallel evaluation management.    TorchSHAC  : Provides a wrapper over  SHAC  so as to provide a unified interface alongside\nthe other managed session. Makes it simpler to explicitly set the parallelism of the evaluators.    TensorflowSHAC  : Provides a  tf.Session  alongside the worker id and the sampled parameters. This session is wrapped\nby the evaluation, so all tensors created inside the evaluation function can be run using this session. The graph can be\nobtained using the generic  tf.get_default_graph() , if required.    KerasSHAC  : Provides a managed session similar to  TensorflowSHAC , but can be possibly used with other backends. Since\nTheano does not support memory management (deletion of old models), only Tensorflow and CNTK backends are supported for\nthe moment.",
            "title": "Managed Evaluations"
        },
        {
            "location": "/managed/",
            "text": "Managed Engines for Advanced Workflows\n\u00b6\n\n\n\n\nWhen using just CPU resources, \nSHAC\n is sufficient for most tasks.\n\n\nHowever, when more complicated workflows are involved - such as training models and evaluation with\nTensorflow, PyTorch or Keras or other such libraries that involve graph based execution and memory\nmanagement, it is advised to use the Managed Engines detailed here.\n\n\nThere are three engines provided :\n\n\n\n\nTorchSHAC\n\n\nTensorflowSHAC\n\n\nKerasSHAC\n\n\n\n\nMotivation for Managed Engines\n\u00b6\n\n\n\n\n\n\nTensorflow / Keras use graphs to generate and train models. These graphs and their scopes need to be managed properly.\n\n\nIf evaluators are models which run on the GPU, it may not be possible to run more than 1 model at once due to memory constraints.\n\n\nIt is necessary to provide a simple interface to decide whether GPUs will be used or not.\n\n\n\n\n\n\nNote\n\n\nIt is upto the user to utilize the \nworker_id\n parameter to determine the placement of the operations.\n\n\nThe session provided \ndoes not\n wrap the evaluation function in a device, as certain ops may not be\navailable on GPUs.\n\n\nIn the same manner, when using PyTorch, the device is not set by the managed engine. It is the task of\nthe user to utilize the provided \nworker_id\n in pushing models onto the correct devices.\n\n\n\n\nTorchSHAC\n\u00b6\n\n\n\n\nThis is the most basic managed engine, which only provides a unified interface similar to \nTensorflowSHAC\n and\n\nKerasSHAC\n. In term's of functionality, it does not manage memory or graph execution, since PyTorch does not\nutilize a graph in a user facing way.\n\n\nIt simply provides a way to determine whether / how many evaluation processs can be started using the \nmax_gpu_evaluators\n\nargument.\n\n\nAs such, when using dynamic execution environments, such as \nPyTorch\n, \nTensorflow Eager\n or \ntf.keras\n with\nEager Execution enabled, it is suggested to use this backend.\n\n\nLike \nSHAC\n, the evaluation function will receive 2 inputs :\n\n\n\n\nWorker ID\n: Integer id that can be left alone when executing only on CPU or used to determine the GPU id on which the model will be evaluated.\n\n\nParameter OrderedDict\n: An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.\n\n\nThese are the values of the sampled hyper parameters which have passed through the current cascade of models.\n\n\n\n\n\n\n\n\nTensorflowSHAC\n\u00b6\n\n\nDue to its graph based execution, Tensorflow is the primary candidate to use a managed session.\n\n\nUnlike the \nSHAC\n and \nTorchSHAC\n engines, an evaluation function using the \nTensorflowSHAC\n engine will receive\n3 inputs :\n\n\n\n\nTensorflow Session\n: This session manages a separate graph for each parallel evaluator.\n\n\nThe scope of all ops inside the evaluation function is the scope of the managed graph.\n\n\nIt can be used to run all operations inside of the evaluation function.\n\n\n\n\n\n\nWorker Id\n: An integer id that can be used alongside multiple GPU's to determine which GPU will be used to\n\n\nParameter OrderedDict\n: An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.\n\n\nThese are the values of the sampled hyper parameters which have passed through the current cascade of models.\n\n\n\n\n\n\n\n\nSince these graphs are managed by the engine, once the evaluation function has provided a value, the respective graph\nwill be destroyed and resources released automatically by the engine.\n\n\nKerasSHAC\n\u00b6\n\n\nSince Keras is a wrapper over Tensorflow and CNTK which support multiple GPU execution, this wrapper simply\nprovides a thin wrapper over the \nTensorflowSHAC\n engine. It's primary purpose is to release resources\nafter the evaluation of the function.\n\n\nUnlike the \nSHAC\n and \nTorchSHAC\n engines, an evaluation function using the \nKerasSHAC\n engine will receive\n3 inputs :\n\n\n\n\nTensorflow Session or None\n: This session manages a separate graph for each parallel evaluator.\n\n\nThe scope of all ops inside the evaluation function is the scope of the managed graph.\n\n\nIt can be used to run all operations inside of the evaluation function.\n\n\nWhen using the CNTK backend, this argument will be \nNone\n.\n\n\n\n\n\n\nWorker Id\n: An integer id that can be used alongside multiple GPU's to determine which GPU will be used to\n\n\nParameter OrderedDict\n: An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.\n\n\nThese are the values of the sampled hyper parameters which have passed through the current cascade of models.\n\n\n\n\n\n\n\n\nSince these graphs are managed by the engine, once the evaluation function has provided a value, the respective graph\nwill be destroyed and resources released automatically by the engine.",
            "title": "Managed Engines"
        },
        {
            "location": "/managed/#managed-engines-for-advanced-workflows",
            "text": "When using just CPU resources,  SHAC  is sufficient for most tasks.  However, when more complicated workflows are involved - such as training models and evaluation with\nTensorflow, PyTorch or Keras or other such libraries that involve graph based execution and memory\nmanagement, it is advised to use the Managed Engines detailed here.  There are three engines provided :   TorchSHAC  TensorflowSHAC  KerasSHAC",
            "title": "Managed Engines for Advanced Workflows"
        },
        {
            "location": "/managed/#motivation-for-managed-engines",
            "text": "Tensorflow / Keras use graphs to generate and train models. These graphs and their scopes need to be managed properly.  If evaluators are models which run on the GPU, it may not be possible to run more than 1 model at once due to memory constraints.  It is necessary to provide a simple interface to decide whether GPUs will be used or not.    Note  It is upto the user to utilize the  worker_id  parameter to determine the placement of the operations.  The session provided  does not  wrap the evaluation function in a device, as certain ops may not be\navailable on GPUs.  In the same manner, when using PyTorch, the device is not set by the managed engine. It is the task of\nthe user to utilize the provided  worker_id  in pushing models onto the correct devices.",
            "title": "Motivation for Managed Engines"
        },
        {
            "location": "/managed/#torchshac",
            "text": "This is the most basic managed engine, which only provides a unified interface similar to  TensorflowSHAC  and KerasSHAC . In term's of functionality, it does not manage memory or graph execution, since PyTorch does not\nutilize a graph in a user facing way.  It simply provides a way to determine whether / how many evaluation processs can be started using the  max_gpu_evaluators \nargument.  As such, when using dynamic execution environments, such as  PyTorch ,  Tensorflow Eager  or  tf.keras  with\nEager Execution enabled, it is suggested to use this backend.  Like  SHAC , the evaluation function will receive 2 inputs :   Worker ID : Integer id that can be left alone when executing only on CPU or used to determine the GPU id on which the model will be evaluated.  Parameter OrderedDict : An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.  These are the values of the sampled hyper parameters which have passed through the current cascade of models.",
            "title": "TorchSHAC"
        },
        {
            "location": "/managed/#tensorflowshac",
            "text": "Due to its graph based execution, Tensorflow is the primary candidate to use a managed session.  Unlike the  SHAC  and  TorchSHAC  engines, an evaluation function using the  TensorflowSHAC  engine will receive\n3 inputs :   Tensorflow Session : This session manages a separate graph for each parallel evaluator.  The scope of all ops inside the evaluation function is the scope of the managed graph.  It can be used to run all operations inside of the evaluation function.    Worker Id : An integer id that can be used alongside multiple GPU's to determine which GPU will be used to  Parameter OrderedDict : An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.  These are the values of the sampled hyper parameters which have passed through the current cascade of models.     Since these graphs are managed by the engine, once the evaluation function has provided a value, the respective graph\nwill be destroyed and resources released automatically by the engine.",
            "title": "TensorflowSHAC"
        },
        {
            "location": "/managed/#kerasshac",
            "text": "Since Keras is a wrapper over Tensorflow and CNTK which support multiple GPU execution, this wrapper simply\nprovides a thin wrapper over the  TensorflowSHAC  engine. It's primary purpose is to release resources\nafter the evaluation of the function.  Unlike the  SHAC  and  TorchSHAC  engines, an evaluation function using the  KerasSHAC  engine will receive\n3 inputs :   Tensorflow Session or None : This session manages a separate graph for each parallel evaluator.  The scope of all ops inside the evaluation function is the scope of the managed graph.  It can be used to run all operations inside of the evaluation function.  When using the CNTK backend, this argument will be  None .    Worker Id : An integer id that can be used alongside multiple GPU's to determine which GPU will be used to  Parameter OrderedDict : An OrderedDict which contains the (name, value) pairs of the Parameters passed to the engine.  These are the values of the sampled hyper parameters which have passed through the current cascade of models.     Since these graphs are managed by the engine, once the evaluation function has provided a value, the respective graph\nwill be destroyed and resources released automatically by the engine.",
            "title": "KerasSHAC"
        },
        {
            "location": "/custom-hyper-parameters/",
            "text": "Custom Hyper Parameters\n\u00b6\n\n\nThere are 3 available hyper parameters made available by default:\n\n\n\n\nDiscreteHyperParameter\n\n\nUniformContinuousHyperParameter\n\n\nNormalContinuousHyperParameter\n\n\n\n\nHowever, if other parameters need to be added, this can be done as follows :\n\n\n\n\nDefine a new class which extends \nAbstractHyperParameter\n or any of its subclasses (other than \nHyperParameterList\n).\n\n\nRegister this new hyper parameter with the module so that it can be saved and restored.\n\n\nUse the new hyper parameter as normal.\n\n\n\n\nDefine a new Hyper Parameter\n\u00b6\n\n\nA hyper parameter needs to define a few methods from the abstract class. They are :\n\n\n\n\nsample()\n: Sample a single value from the set of all possible values that this parameter can have.\n\n\nencode\n`: Encode a single value into an integer or floating point representation.\n\n\ndecode\n`: Decode an integer or floating point representation to the original value that it represents.\n\n\n_cast\n`: Cast the value provided to the original data type that was provided in the constructor.\n\n\nget_config\n`: Prepare a config of the arguments to the constructor of this class, so that it can be restored.\n\n\n\n\n\n\nThe following is a mock example that replicates some of \nUniformContinuousHyperParameter\n\n\nWe subclass \nAbstractContinuousHyperParameter\n, a subclass of \nAbstractHyperParameter\n, which defines useful functionality for\nhyper parameters that can have values in a range and can be sampled from a distribution.\n\n\nThis subclass is useful, since it pre-defines several methods for us :\n\n\n\n\nencode\n\n\ndecode\n\n\n_cast\n\n\n\n\n\n\nimport\n \npyshac\n\n\nfrom\n \npyshac.config.hyperparameters\n \nimport\n \nAbstractContinuousHyperParameter\n\n\n\nclass\n \nCustomUniformHP\n(\nAbstractContinuousHyperParameter\n):\n\n\n    \ndef\n \n__init__\n(\nself\n,\n \nname\n,\n \nmin_value\n,\n \nmax_value\n):\n\n        \nsuper\n(\nCustomUniformHP\n,\n \nself\n)\n.\n__init__\n(\nname\n,\n \nmin_value\n,\n \nmax_value\n)\n\n\n    \ndef\n \nsample\n(\nself\n):\n\n        \n\"\"\"\n\n\n        Here, self._val1 and self._val2 are the private members of `AbstractContinuousHyperParameters`,\n\n\n        which represent the range that this distribution can be sampled from.\n\n\n        \"\"\"\n\n        \nvalue\n \n=\n \nnp\n.\nrandom\n.\nuniform\n(\nself\n.\n_val1\n,\n \nself\n.\n_val2\n,\n \nsize\n=\n1\n)[\n0\n]\n\n        \nreturn\n \nvalue\n\n\n    \ndef\n \nget_config\n(\nself\n):\n\n        \n\"\"\"\n\n\n        Creates the config of the class with all of its values.\n\n\n\n        Note 1: The keys in this dict must match the argument names\n\n\n            defined in the constructor of this class.\n\n\n\n        Note 2: The `name` key is already assigned via the `base_config`,\n\n\n            so there is no need to add that to the config again.\n\n\n        \"\"\"\n\n        \nconfig\n \n=\n \n{\n\n            \n'min_value'\n:\n \nself\n.\nmin_value\n,\n\n            \n'max_value'\n:\n \nself\n.\nmax_value\n,\n\n        \n}\n\n\n        \n# add the base class config alongside this classes config\n\n        \nbase_config\n \n=\n \nsuper\n(\nUniformContinuousHyperParameter\n,\n \nself\n)\n.\nget_config\n()\n\n        \nreturn\n \ndict\n(\nlist\n(\nbase_config\n.\nitems\n())\n \n+\n \nlist\n(\nconfig\n.\nitems\n()))\n\n\n\n\n\nRegister the new hyper parameter\n\u00b6\n\n\nIt takes just two lines to register this new hyper parameter. Simply use the \nset_custom_parameter_class\n method\ndefined in the \npyshac.config.hyperparameters\n module to register a new class.\n\n\nfrom\n \npyshac.config.hyperparemeters\n \nimport\n \nset_custom_parameter_class\n\n\n\nset_custom_parameter_class\n(\nCustomUniformHP\n)\n\n\n\n\n\nUse this new hyper parameter\n\u00b6\n\n\nAfter this registration, this new hyper parameter will be available to include in a list, training,\npredicting new samples and saving and restoring state of the engine.\n\n\n\n\nRemember to set the custom parameter \nbefore\n restoring the engine\n\n\nDue to how the class is bound and re-created when being restored, it is important to\nset the custom parameter to the module before using \nrestore_data()\n on any engine.",
            "title": "Custom Hyper Parameters"
        },
        {
            "location": "/custom-hyper-parameters/#custom-hyper-parameters",
            "text": "There are 3 available hyper parameters made available by default:   DiscreteHyperParameter  UniformContinuousHyperParameter  NormalContinuousHyperParameter   However, if other parameters need to be added, this can be done as follows :   Define a new class which extends  AbstractHyperParameter  or any of its subclasses (other than  HyperParameterList ).  Register this new hyper parameter with the module so that it can be saved and restored.  Use the new hyper parameter as normal.",
            "title": "Custom Hyper Parameters"
        },
        {
            "location": "/custom-hyper-parameters/#define-a-new-hyper-parameter",
            "text": "A hyper parameter needs to define a few methods from the abstract class. They are :   sample() : Sample a single value from the set of all possible values that this parameter can have.  encode `: Encode a single value into an integer or floating point representation.  decode `: Decode an integer or floating point representation to the original value that it represents.  _cast `: Cast the value provided to the original data type that was provided in the constructor.  get_config `: Prepare a config of the arguments to the constructor of this class, so that it can be restored.    The following is a mock example that replicates some of  UniformContinuousHyperParameter  We subclass  AbstractContinuousHyperParameter , a subclass of  AbstractHyperParameter , which defines useful functionality for\nhyper parameters that can have values in a range and can be sampled from a distribution.  This subclass is useful, since it pre-defines several methods for us :   encode  decode  _cast    import   pyshac  from   pyshac.config.hyperparameters   import   AbstractContinuousHyperParameter  class   CustomUniformHP ( AbstractContinuousHyperParameter ): \n\n     def   __init__ ( self ,   name ,   min_value ,   max_value ): \n         super ( CustomUniformHP ,   self ) . __init__ ( name ,   min_value ,   max_value ) \n\n     def   sample ( self ): \n         \"\"\"          Here, self._val1 and self._val2 are the private members of `AbstractContinuousHyperParameters`,          which represent the range that this distribution can be sampled from.          \"\"\" \n         value   =   np . random . uniform ( self . _val1 ,   self . _val2 ,   size = 1 )[ 0 ] \n         return   value \n\n     def   get_config ( self ): \n         \"\"\"          Creates the config of the class with all of its values.          Note 1: The keys in this dict must match the argument names              defined in the constructor of this class.          Note 2: The `name` key is already assigned via the `base_config`,              so there is no need to add that to the config again.          \"\"\" \n         config   =   { \n             'min_value' :   self . min_value , \n             'max_value' :   self . max_value , \n         } \n\n         # add the base class config alongside this classes config \n         base_config   =   super ( UniformContinuousHyperParameter ,   self ) . get_config () \n         return   dict ( list ( base_config . items ())   +   list ( config . items ()))",
            "title": "Define a new Hyper Parameter"
        },
        {
            "location": "/custom-hyper-parameters/#register-the-new-hyper-parameter",
            "text": "It takes just two lines to register this new hyper parameter. Simply use the  set_custom_parameter_class  method\ndefined in the  pyshac.config.hyperparameters  module to register a new class.  from   pyshac.config.hyperparemeters   import   set_custom_parameter_class  set_custom_parameter_class ( CustomUniformHP )",
            "title": "Register the new hyper parameter"
        },
        {
            "location": "/custom-hyper-parameters/#use-this-new-hyper-parameter",
            "text": "After this registration, this new hyper parameter will be available to include in a list, training,\npredicting new samples and saving and restoring state of the engine.   Remember to set the custom parameter  before  restoring the engine  Due to how the class is bound and re-created when being restored, it is important to\nset the custom parameter to the module before using  restore_data()  on any engine.",
            "title": "Use this new hyper parameter"
        },
        {
            "location": "/external-dataset-training/",
            "text": "External Dataset Training\n\u00b6\n\n\n\n\nIn many cases, one may posses results from other search processes such as bayesian optimization, which is used for\nhyper parameter tuning or even neural architecture search.\n\n\nHowever, they come with their own set of limitations, and can often be very costly for searching over\nvery large search spaces.\n\n\nTherefore, we can utilize the results derived from such external processes and utilize them to train\nSHAC engines quickly, which can then be used for speedy inference of optimal parameters in large search\nspaces.\n\n\nFormatting External Datasets\n\u00b6\n\n\n\n\nPySHAC uses a standard CSV file to define the contents of the dataset that it generates, which makes it highly\nconvenient to create or transform external datasets into a format that can be readily used by the engine.\n\n\n\n\nStandard format of datasets\n\n\nEach dataset csv file must contain an integer id column named \"id\"\nas its 1\nst\n column, followed by several columns describing the values\ntaken by the hyper parameters, and the final column must be for\nthe the objective criterion, and \nmust\n be named \"scores\".\nThe csv file \nmust\n contain a header, following the above format.\n\n\n\n\nExample:\n\n\nid,hp1,hp2,scores\n0,1,h1,1.0\n1,1,h2,0.2\n2,0,h1,0.0\n3,0,h3,0.5\n...\n\n\n\n\n\nTraining with an External Dataset\n\u00b6\n\n\n\n\nThere are a few requirements for the engine when loading external datasets.\n\n\n1) The parameter list provided to the engine must match the parameter list of the dataset. It is not\npossible to provide an empty HyperParameter list when training via an external dataset.\n\n\n2) The number of samples in the dataset must be greater than or equal to the total budget. If it is\ngreater than the total budget, the additional samples will not be used for training.\n\n\nOnce these requirements are met, it is as simple as calling a single function of the engine to\ntrain a model using external data.\n\n\nshac\n.\nfit_dataset\n(\n'path/to/dataset.csv'\n,\n \npresort\n=\nTrue\n)\n\n\n\n\n\nThe \npresort\n option will first sort the dataset automatically in ascending or descending order with respect to\nthe objective function optimization flag provided to the engine, and this can often improve the performance\nof the final cascade of classifiers of the SHAC engine.\n\n\nAfter training, which should be extremely fast for even large datasets, we can predict new samples using\n\npredict\n as always without any modifications.\n\n\nExample\n\u00b6\n\n\nAn example script showing the usage of external dataset training is provided in the \nexamples/basic_dataset\n folder",
            "title": "External Dataset Training"
        },
        {
            "location": "/external-dataset-training/#external-dataset-training",
            "text": "In many cases, one may posses results from other search processes such as bayesian optimization, which is used for\nhyper parameter tuning or even neural architecture search.  However, they come with their own set of limitations, and can often be very costly for searching over\nvery large search spaces.  Therefore, we can utilize the results derived from such external processes and utilize them to train\nSHAC engines quickly, which can then be used for speedy inference of optimal parameters in large search\nspaces.",
            "title": "External Dataset Training"
        },
        {
            "location": "/external-dataset-training/#formatting-external-datasets",
            "text": "PySHAC uses a standard CSV file to define the contents of the dataset that it generates, which makes it highly\nconvenient to create or transform external datasets into a format that can be readily used by the engine.   Standard format of datasets  Each dataset csv file must contain an integer id column named \"id\"\nas its 1 st  column, followed by several columns describing the values\ntaken by the hyper parameters, and the final column must be for\nthe the objective criterion, and  must  be named \"scores\".\nThe csv file  must  contain a header, following the above format.   Example:  id,hp1,hp2,scores\n0,1,h1,1.0\n1,1,h2,0.2\n2,0,h1,0.0\n3,0,h3,0.5\n...",
            "title": "Formatting External Datasets"
        },
        {
            "location": "/external-dataset-training/#training-with-an-external-dataset",
            "text": "There are a few requirements for the engine when loading external datasets.  1) The parameter list provided to the engine must match the parameter list of the dataset. It is not\npossible to provide an empty HyperParameter list when training via an external dataset.  2) The number of samples in the dataset must be greater than or equal to the total budget. If it is\ngreater than the total budget, the additional samples will not be used for training.  Once these requirements are met, it is as simple as calling a single function of the engine to\ntrain a model using external data.  shac . fit_dataset ( 'path/to/dataset.csv' ,   presort = True )   The  presort  option will first sort the dataset automatically in ascending or descending order with respect to\nthe objective function optimization flag provided to the engine, and this can often improve the performance\nof the final cascade of classifiers of the SHAC engine.  After training, which should be extremely fast for even large datasets, we can predict new samples using predict  as always without any modifications.",
            "title": "Training with an External Dataset"
        },
        {
            "location": "/external-dataset-training/#example",
            "text": "An example script showing the usage of external dataset training is provided in the  examples/basic_dataset  folder",
            "title": "Example"
        },
        {
            "location": "/callbacks/",
            "text": "Callbacks\n\u00b6\n\n\n\n\nCallbacks can be used with PySHAC for custom code execution, such as monitoring the improvement of the engine,\nmaintaining a history of the training session or simply writing the logs to files.\n\n\nCallbacks allow you the flexibility to prepare your state prior to training or evaluation, and in doing so can\nallow one to perform stateful evaluation if necessary using concurrent evaluators.\n\n\nUsage\n\u00b6\n\n\nCallbacks can be imported from the \npyshac.config.callbacks\n package as shown below.\n\n\nfrom\n \npyshac.config.callbacks\n \nimport\n \nHistory\n,\n \nCSVLogger\n\n\n\nshac\n \n=\n \nSHAC\n(\n...\n)\n\n\n\n# History is not needed here, as it is automatically added by default for all .fit / .fit_dataset calls.\n\n\ncallbacks\n \n=\n \n[\nHistory\n(),\n \nCSVLogger\n(\n'path/to/file.csv'\n)]\n\n\n\nhistory\n \n=\n \nshac\n.\nfit\n(\nevaluation_function\n,\n \ncallbacks\n=\ncallbacks\n)\n\n\nOR\n\n\nhistory\n \n=\n \nshac\n.\nfit_dataset\n(\n'path/to/dataset'\n,\n \ncallbacks\n=\ncallbacks\n)\n\n\n\nprint\n(\nhistory\n.\nhistory\n)\n\n\n\n\n\nHistory\n\u00b6\n\n\nAll calls to \nshac.fit\n and \nshac.fit_dataset\n will now return a \nHistory\n object, which is a callback to\nmonitor and log all valuable information occurring during training.\n\n\nThe \nHistory\n object has a special member, also called \nhistory\n, which is a dictionary containing all of\nthe logged values.\n\n\n\n\nHistory is added by default\n\n\nThe \nHistory\n callback is added by default to all calls to \nfit\n or \nfit_dataset\n and therefore\nthere it is not necessary to add this callback manually.",
            "title": "Callbacks"
        },
        {
            "location": "/callbacks/#callbacks",
            "text": "Callbacks can be used with PySHAC for custom code execution, such as monitoring the improvement of the engine,\nmaintaining a history of the training session or simply writing the logs to files.  Callbacks allow you the flexibility to prepare your state prior to training or evaluation, and in doing so can\nallow one to perform stateful evaluation if necessary using concurrent evaluators.",
            "title": "Callbacks"
        },
        {
            "location": "/callbacks/#usage",
            "text": "Callbacks can be imported from the  pyshac.config.callbacks  package as shown below.  from   pyshac.config.callbacks   import   History ,   CSVLogger  shac   =   SHAC ( ... )  # History is not needed here, as it is automatically added by default for all .fit / .fit_dataset calls.  callbacks   =   [ History (),   CSVLogger ( 'path/to/file.csv' )]  history   =   shac . fit ( evaluation_function ,   callbacks = callbacks )  OR  history   =   shac . fit_dataset ( 'path/to/dataset' ,   callbacks = callbacks )  print ( history . history )",
            "title": "Usage"
        },
        {
            "location": "/callbacks/#history",
            "text": "All calls to  shac.fit  and  shac.fit_dataset  will now return a  History  object, which is a callback to\nmonitor and log all valuable information occurring during training.  The  History  object has a special member, also called  history , which is a dictionary containing all of\nthe logged values.   History is added by default  The  History  callback is added by default to all calls to  fit  or  fit_dataset  and therefore\nthere it is not necessary to add this callback manually.",
            "title": "History"
        },
        {
            "location": "/config/hyperparameters/",
            "text": "Hyper Parameters\n\u00b6\n\n\n\n\nThere are 3 primary hyper parameters :\n\n\n\n\nDiscreteHyperParameter (DiscreteHP)\n\n\nUniformContinuousHyperParameter (UniformHP)\n\n\nNormalContinuousHyperParameter (NormalHP)\n\n\n\n\nAs their names suggest, each hyper paramter takes specific parameters or value ranges.\n\n\n\n\n\n\nDiscrete Hyper Parmeters takes lists of any python data type that can be serialized.\n\n\n\n\nThis includes numpy values, and even numpy arrays\n\n\n\n\n\n\n\n\nContinuous Hyper Parameters take ranges of values\n\n\n\n\nUniform Continuous Hyper Parameters will sample uniformly between the min and max values\n\n\nNormal Continuous Hyper Parameters will sample from the normal distribution with the provided mean and standard deviation\n\n\n\n\n\n\n\n\nA special composite hyper parameter, called \nHyperParameterList\n is used to provide a convenient interface to several\nhyper parameters at once, and is used internally by the training algorithm.\n\n\nClass Information\n\u00b6\n\n\n\n\n[source]\n\n\nAbstractHyperParameter\n\u00b6\n\n\npyshac\n.\nconfig\n.\nhyperparameters\n.\nAbstractHyperParameter\n(\nname\n,\n \nvalues\n)\n\n\n\n\n\nAbstract Hyper Parameter that defines the methods that all hyperparameters\nneed to supply\n\n\nArguments:\n\n\n\n\nname (str):\n Name of the hyper parameter\n\n\nvalues (List, None):\n A list of values (must all be pickle-able and hashable)\n    values or None. If None, it is assumed to be a continuous value generator.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the \nname\n is not specified.\n\n\n\n\n\n\nAbstractHyperParameter methods\n\u00b6\n\n\ndecode\n\u00b6\n\n\ndecode\n(\nx\n)\n\n\n\n\n\nAbstract method that defines how the parameter is decoded so\nthat the model can be properly trained.\n\n\nArguments:\n\n\n\n\nx (int | float):\n an encoded value that needs to be decoded.\n\n\n\n\nRaises:\n\n\n\n\nNotImplementedError\n: Must be overridden by the subclass.\n\n\n\n\nReturns:\n\n\na decoded value for the encoded input \nx\n.\n\n\n\n\nencode\n\u00b6\n\n\nencode\n(\nx\n)\n\n\n\n\n\nAbstract method that defines how the parameter is encoded\nso that the model can properly be trained.\n\n\nArguments:\n\n\n\n\nx (int | float | str):\n a single value that needs to be encoded.\n\n\n\n\nRaises:\n\n\n\n\nNotImplementedError\n: Must be overridden by the subclass.\n\n\n\n\nReturns:\n\n\nan encoded representation of the value of \nx\n.\n\n\n\n\nget_config\n\u00b6\n\n\nget_config\n()\n\n\n\n\n\nCreates the config of the class with all of its values.\n\n\nReturns:\n\n\na dictionary with the config of the class.\n\n\n\n\nload_from_config\n\u00b6\n\n\nload_from_config\n(\nconfig\n)\n\n\n\n\n\nUtilizes the provided config to instantiate a new\ninstance of the class with the same arguments.\n\n\nArguments:\n\n\n\n\nconfig (dict):\n A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.\n\n\n\n\nReturns:\n\n\nA new instance of this class with the correct arguments.\n\n\n\n\nsample\n\u00b6\n\n\nsample\n()\n\n\n\n\n\nAbstract method that defines how parameters are sampled.\n\n\nRaises:\n\n\n\n\nNotImplementedError\n: Must be overridden by the subclass.\n\n\n\n\nReturns:\n\n\na singular value sampled from possible values.\n\n\n\n\n[source]\n\n\nAbstractContinuousHyperParameter\n\u00b6\n\n\npyshac\n.\nconfig\n.\nhyperparameters\n.\nAbstractContinuousHyperParameter\n(\nname\n,\n \nval1\n,\n \nval2\n,\n \nlog_encode\n=\nFalse\n)\n\n\n\n\n\nAn abstract hyper parameter that represents a parameter that can take a range\nof values from a certain distribution.\n\n\nArguments:\n\n\n\n\nname (str):\n Name of the parameter.\n\n\nval1 (float):\n A symbolic value that is used by subclasses.\n\n\nval2 (float):\n A symbolic value that is used by subclasses.\n\n\nlog_encode (bool):\n Determines whether the encoding must be in natural\n    log-space or not.\n\n\n\n\nRaises:\n\n\n\n\nNotImplementedError\n: If \nsample()\n is called.\n\n\n\n\n\n\nAbstractContinuousHyperParameter methods\n\u00b6\n\n\ndecode\n\u00b6\n\n\ndecode\n(\nx\n)\n\n\n\n\n\nDecodes the floating point value into normal space if \nlog_space\n was set in\nthe constructor, else returns its original value.\n\n\nArguments:\n\n\n\n\nx (float):\n a single encoded sample.\n\n\n\n\nReturns:\n\n\nfloat.\n\n\n\n\nencode\n\u00b6\n\n\nencode\n(\nx\n)\n\n\n\n\n\nEncodes the floating point value into log space if \nlog_space\n was set in\nthe constructor, else returns its original value.\n\n\nArguments:\n\n\n\n\nx (float):\n a single sample.\n\n\n\n\nReturns:\n\n\nfloat.\n\n\n\n\nget_config\n\u00b6\n\n\nget_config\n()\n\n\n\n\n\nCreates the config of the class with all of its values.\n\n\nReturns:\n\n\na dictionary with the config of the class.\n\n\n\n\nload_from_config\n\u00b6\n\n\nload_from_config\n(\nconfig\n)\n\n\n\n\n\nUtilizes the provided config to instantiate a new\ninstance of the class with the same arguments.\n\n\nArguments:\n\n\n\n\nconfig (dict):\n A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.\n\n\n\n\nReturns:\n\n\nA new instance of this class with the correct arguments.\n\n\n\n\nsample\n\u00b6\n\n\nsample\n()\n\n\n\n\n\nAbstract method that must be redefined by base classes.\n\n\nReturns:\n\n\na float value.\n\n\n\n\n[source]\n\n\nAbstractMultiContinuousHyperParameter\n\u00b6\n\n\npyshac\n.\nconfig\n.\nhyperparameters\n.\nAbstractMultiContinuousHyperParameter\n(\nname\n,\n \nval1\n,\n \nval2\n,\n \nlog_encode\n=\nFalse\n,\n \nsample_count\n=\n1\n)\n\n\n\n\n\nAn abstract hyper parameter that represents a parameter that can take a range\nof values from a certain distribution, sampled multiple times.\n\n\nArguments:\n\n\n\n\nname (str):\n Name of the parameter.\n\n\nval1 (float):\n A symbolic value that is used by subclasses.\n\n\nval2 (float):\n A symbolic value that is used by subclasses.\n\n\nlog_encode (bool):\n Determines whether the encoding must be in natural\n    log-space or not.\n\n\nsample_count (int):\n Number of samples that are required from this\n    hyper parameter.\n\n\n\n\nRaises:\n\n\n\n\nNotImplementedError\n: If \nsample()\n is called.\n\n\nValueErroe\n: If sample count is less than 1.\n\n\n\n\n\n\nAbstractMultiContinuousHyperParameter methods\n\u00b6\n\n\ndecode\n\u00b6\n\n\ndecode\n(\nx\n)\n\n\n\n\n\nDecodes a list of floating point values into normal space if \nlog_space\n\nwas set in the constructor, else returns its original value.\n\n\nArguments:\n\n\n\n\nx (float):\n a list of encoded samples.\n\n\n\n\nReturns:\n\n\nlist of floats.\n\n\n\n\nencode\n\u00b6\n\n\nencode\n(\nx\n)\n\n\n\n\n\nEncodes a list of floating point values into log space if \nlog_space\n\nwas set in the constructor, else returns its original value.\n\n\nArguments:\n\n\n\n\nx (float):\n a list of samples.\n\n\n\n\nReturns:\n\n\nlist of floats.\n\n\n\n\nget_config\n\u00b6\n\n\nget_config\n()\n\n\n\n\n\nCreates the config of the class with all of its values.\n\n\nReturns:\n\n\na dictionary with the config of the class.\n\n\n\n\nload_from_config\n\u00b6\n\n\nload_from_config\n(\nconfig\n)\n\n\n\n\n\nUtilizes the provided config to instantiate a new\ninstance of the class with the same arguments.\n\n\nArguments:\n\n\n\n\nconfig (dict):\n A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.\n\n\n\n\nReturns:\n\n\nA new instance of this class with the correct arguments.\n\n\n\n\nsample\n\u00b6\n\n\nsample\n()\n\n\n\n\n\nAbstract method that must be redefined by base classes.\n\n\nReturns:\n\n\na float value.\n\n\n\n\n[source]\n\n\nDiscreteHyperParameter\n\u00b6\n\n\npyshac\n.\nconfig\n.\nhyperparameters\n.\nDiscreteHyperParameter\n(\nname\n,\n \nvalues\n)\n\n\n\n\n\nDiscrete Hyper Parameter that defines a set of discrete values that it can take.\n\n\nArguments:\n\n\n\n\nname (str):\n Name of the hyper parameter.\n\n\nvalues (list):\n A list of values (must all be pickle-able and hashable)\n    values or None.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the \nname\n is not specified.\n.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the \nname\n is not specified.\n\n\n\n\n\n\nDiscreteHyperParameter methods\n\u00b6\n\n\ndecode\n\u00b6\n\n\ndecode\n(\nx\n)\n\n\n\n\n\nDecodes a single encoded integer into its original value.\n\n\nArgs:\n\n\n\n\nx (int):\n an integer encoded value.\n\n\n\n\nReturns:\n\n\n(int | float | str) representing the actual decoded value.\n\n\n\n\nencode\n\u00b6\n\n\nencode\n(\nx\n)\n\n\n\n\n\nEncodes a single value into an integer index.\n\n\nArguments:\n\n\n\n\nx (int | float | str):\n A value sampled from its possible values.\n\n\n\n\nReturns:\n\n\nint value representing its encoded index.\n\n\n\n\nget_config\n\u00b6\n\n\nget_config\n()\n\n\n\n\n\nCreates the config of the class with all of its values.\n\n\nReturns:\n\n\na dictionary with the config of the class.\n\n\n\n\nload_from_config\n\u00b6\n\n\nload_from_config\n(\nconfig\n)\n\n\n\n\n\nUtilizes the provided config to instantiate a new\ninstance of the class with the same arguments.\n\n\nArguments:\n\n\n\n\nconfig (dict):\n A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.\n\n\n\n\nReturns:\n\n\nA new instance of this class with the correct arguments.\n\n\n\n\nsample\n\u00b6\n\n\nsample\n()\n\n\n\n\n\nSamples a single value from its set of discrete values.\n\n\nReturns:\n\n\na single value from its list of possible values.\n\n\n\n\n[source]\n\n\nUniformContinuousHyperParameter\n\u00b6\n\n\npyshac\n.\nconfig\n.\nhyperparameters\n.\nUniformContinuousHyperParameter\n(\nname\n,\n \nmin_value\n,\n \nmax_value\n,\n \nlog_encode\n=\nFalse\n)\n\n\n\n\n\nA hyper parameter that represents a parameter that can take a range\nof values from a uniform distribution.\n\n\nArguments:\n\n\n\n\nname (str):\n Name of the parameter.\n\n\nmin_value (float):\n The minimum value (inclusive) that the uniform\n    distribution can take.\n\n\nmax_value (float):\n The maximum value (exclusive) that the uniform\n    distribution can take.\n\n\nlog_encode (bool):\n Determines whether the encoding must be in natural\n    log-space or not.\n\n\n\n\n\n\nUniformContinuousHyperParameter methods\n\u00b6\n\n\ndecode\n\u00b6\n\n\ndecode\n(\nx\n)\n\n\n\n\n\nDecodes the floating point value into normal space if \nlog_space\n was set in\nthe constructor, else returns its original value.\n\n\nArguments:\n\n\n\n\nx (float):\n a single encoded sample.\n\n\n\n\nReturns:\n\n\nfloat.\n\n\n\n\nencode\n\u00b6\n\n\nencode\n(\nx\n)\n\n\n\n\n\nEncodes the floating point value into log space if \nlog_space\n was set in\nthe constructor, else returns its original value.\n\n\nArguments:\n\n\n\n\nx (float):\n a single sample.\n\n\n\n\nReturns:\n\n\nfloat.\n\n\n\n\nget_config\n\u00b6\n\n\nget_config\n()\n\n\n\n\n\nCreates the config of the class with all of its values.\n\n\nReturns:\n\n\na dictionary with the config of the class.\n\n\n\n\nload_from_config\n\u00b6\n\n\nload_from_config\n(\nconfig\n)\n\n\n\n\n\nUtilizes the provided config to instantiate a new\ninstance of the class with the same arguments.\n\n\nArguments:\n\n\n\n\nconfig (dict):\n A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.\n\n\n\n\nReturns:\n\n\nA new instance of this class with the correct arguments.\n\n\n\n\nsample\n\u00b6\n\n\nsample\n()\n\n\n\n\n\nSamples uniformly from the range [min_value, max_value).\n\n\nReturns:\n\n\nfloat.\n\n\n\n\n[source]\n\n\nNormalContinuousHyperParameter\n\u00b6\n\n\npyshac\n.\nconfig\n.\nhyperparameters\n.\nNormalContinuousHyperParameter\n(\nname\n,\n \nmean\n,\n \nstd\n)\n\n\n\n\n\nA hyper parameter that represents a parameter that can take a range\nof values from a normal distribution.\n\n\nArguments:\n\n\n\n\nname (str):\n Name of the parameter.\n\n\nmean (float):\n The mean of the normal distribution.\n\n\nstd (float):\n The standard deviation of the normal distribution.\n\n\n\n\n\n\nNormalContinuousHyperParameter methods\n\u00b6\n\n\ndecode\n\u00b6\n\n\ndecode\n(\nx\n)\n\n\n\n\n\nDecodes the floating point value into normal space if \nlog_space\n was set in\nthe constructor, else returns its original value.\n\n\nArguments:\n\n\n\n\nx (float):\n a single encoded sample.\n\n\n\n\nReturns:\n\n\nfloat.\n\n\n\n\nencode\n\u00b6\n\n\nencode\n(\nx\n)\n\n\n\n\n\nEncodes the floating point value into log space if \nlog_space\n was set in\nthe constructor, else returns its original value.\n\n\nArguments:\n\n\n\n\nx (float):\n a single sample.\n\n\n\n\nReturns:\n\n\nfloat.\n\n\n\n\nget_config\n\u00b6\n\n\nget_config\n()\n\n\n\n\n\nCreates the config of the class with all of its values.\n\n\nReturns:\n\n\na dictionary with the config of the class.\n\n\n\n\nload_from_config\n\u00b6\n\n\nload_from_config\n(\nconfig\n)\n\n\n\n\n\nUtilizes the provided config to instantiate a new\ninstance of the class with the same arguments.\n\n\nArguments:\n\n\n\n\nconfig (dict):\n A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.\n\n\n\n\nReturns:\n\n\nA new instance of this class with the correct arguments.\n\n\n\n\nsample\n\u00b6\n\n\nsample\n()\n\n\n\n\n\nSamples from the normal distribution with a mean and standard deviation\nas specified in the constructor.\n\n\nReturns:\n\n\nfloat.\n\n\n\n\n[source]\n\n\nMultiDiscreteHyperParameter\n\u00b6\n\n\npyshac\n.\nconfig\n.\nhyperparameters\n.\nMultiDiscreteHyperParameter\n(\nname\n,\n \nvalues\n,\n \nsample_count\n=\n1\n)\n\n\n\n\n\nDiscrete Hyper Parameter that defines a set of discrete values that it can take,\nand acts upon a list of samples.\n\n\nArguments:\n\n\n\n\nname (str):\n Name of the hyper parameter.\n\n\nvalues (list):\n A list of values (must all be pickle-able and hashable)\n    values or None.\n\n\nsample_count (int):\n Number of samples that are required from this\n    hyper parameter.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the \nname\n is not specified or if \nsample_count\n is less\n    than 1.\n.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the \nname\n is not specified or if \nsample_count\n is less\n    than 1.\n\n\n\n\n\n\nMultiDiscreteHyperParameter methods\n\u00b6\n\n\ndecode\n\u00b6\n\n\ndecode\n(\nx\n)\n\n\n\n\n\nDecodes a list of encoded integers into their original value.\n\n\nArgs:\n\n\n\n\nx (int):\n a list of integer encoded values.\n\n\n\n\nReturns:\n\n\nlist of (int | float | str) representing the actual decoded\n    values.\n\n\n\n\nencode\n\u00b6\n\n\nencode\n(\nx\n)\n\n\n\n\n\nEncodes a list of values into a list of the corresponding integer index.\n\n\nArguments:\n\n\n\n\nx (int | float | str):\n A list of values sampled from its\n    possible values.\n\n\n\n\nReturns:\n\n\nlist of int values representing their encoded index.\n\n\n\n\nget_config\n\u00b6\n\n\nget_config\n()\n\n\n\n\n\nCreates the config of the class with all of its values.\n\n\nReturns:\n\n\na dictionary with the config of the class.\n\n\n\n\nload_from_config\n\u00b6\n\n\nload_from_config\n(\nconfig\n)\n\n\n\n\n\nUtilizes the provided config to instantiate a new\ninstance of the class with the same arguments.\n\n\nArguments:\n\n\n\n\nconfig (dict):\n A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.\n\n\n\n\nReturns:\n\n\nA new instance of this class with the correct arguments.\n\n\n\n\nsample\n\u00b6\n\n\nsample\n()\n\n\n\n\n\nSamples a number of values from its set of discrete values.\n\n\nReturns:\n\n\na list of values from its set of possible values.\n\n\n\n\n[source]\n\n\nMultiUniformContinuousHyperParameter\n\u00b6\n\n\npyshac\n.\nconfig\n.\nhyperparameters\n.\nMultiUniformContinuousHyperParameter\n(\nname\n,\n \nmin_value\n,\n \nmax_value\n,\n \nlog_encode\n=\nFalse\n,\n \nsample_count\n=\n1\n)\n\n\n\n\n\nA hyper parameter that represents a parameter that can take a range\nof values from a uniform distribution, sampled multiple times.\n\n\nArguments:\n\n\n\n\nname (str):\n Name of the parameter.\n\n\nmin_value (float):\n The minimum value (inclusive) that the uniform\n    distribution can take.\n\n\nmax_value (float):\n The maximum value (exclusive) that the uniform\n    distribution can take.\n\n\nlog_encode (bool):\n Determines whether the encoding must be in natural\n    log-space or not.\n\n\nsample_count (int):\n Number of samples that are required from this\n    hyper parameter.\n\n\n\n\nRaises:\n\n\n\n\nValueErroe\n: If sample count is less than 1.\n\n\n\n\n\n\nMultiUniformContinuousHyperParameter methods\n\u00b6\n\n\ndecode\n\u00b6\n\n\ndecode\n(\nx\n)\n\n\n\n\n\nDecodes a list of floating point values into normal space if \nlog_space\n\nwas set in the constructor, else returns its original value.\n\n\nArguments:\n\n\n\n\nx (float):\n a list of encoded samples.\n\n\n\n\nReturns:\n\n\nlist of floats.\n\n\n\n\nencode\n\u00b6\n\n\nencode\n(\nx\n)\n\n\n\n\n\nEncodes a list of floating point values into log space if \nlog_space\n\nwas set in the constructor, else returns its original value.\n\n\nArguments:\n\n\n\n\nx (float):\n a list of samples.\n\n\n\n\nReturns:\n\n\nlist of floats.\n\n\n\n\nget_config\n\u00b6\n\n\nget_config\n()\n\n\n\n\n\nCreates the config of the class with all of its values.\n\n\nReturns:\n\n\na dictionary with the config of the class.\n\n\n\n\nload_from_config\n\u00b6\n\n\nload_from_config\n(\nconfig\n)\n\n\n\n\n\nUtilizes the provided config to instantiate a new\ninstance of the class with the same arguments.\n\n\nArguments:\n\n\n\n\nconfig (dict):\n A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.\n\n\n\n\nReturns:\n\n\nA new instance of this class with the correct arguments.\n\n\n\n\nsample\n\u00b6\n\n\nsample\n()\n\n\n\n\n\nSamples uniformly from the range [min_value, max_value).\n\n\nReturns:\n\n\nlist of floats.\n\n\n\n\n[source]\n\n\nMultiDiscreteHyperParameter\n\u00b6\n\n\npyshac\n.\nconfig\n.\nhyperparameters\n.\nMultiDiscreteHyperParameter\n(\nname\n,\n \nvalues\n,\n \nsample_count\n=\n1\n)\n\n\n\n\n\nDiscrete Hyper Parameter that defines a set of discrete values that it can take,\nand acts upon a list of samples.\n\n\nArguments:\n\n\n\n\nname (str):\n Name of the hyper parameter.\n\n\nvalues (list):\n A list of values (must all be pickle-able and hashable)\n    values or None.\n\n\nsample_count (int):\n Number of samples that are required from this\n    hyper parameter.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the \nname\n is not specified or if \nsample_count\n is less\n    than 1.\n.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the \nname\n is not specified or if \nsample_count\n is less\n    than 1.\n\n\n\n\n\n\nMultiDiscreteHyperParameter methods\n\u00b6\n\n\ndecode\n\u00b6\n\n\ndecode\n(\nx\n)\n\n\n\n\n\nDecodes a list of encoded integers into their original value.\n\n\nArgs:\n\n\n\n\nx (int):\n a list of integer encoded values.\n\n\n\n\nReturns:\n\n\nlist of (int | float | str) representing the actual decoded\n    values.\n\n\n\n\nencode\n\u00b6\n\n\nencode\n(\nx\n)\n\n\n\n\n\nEncodes a list of values into a list of the corresponding integer index.\n\n\nArguments:\n\n\n\n\nx (int | float | str):\n A list of values sampled from its\n    possible values.\n\n\n\n\nReturns:\n\n\nlist of int values representing their encoded index.\n\n\n\n\nget_config\n\u00b6\n\n\nget_config\n()\n\n\n\n\n\nCreates the config of the class with all of its values.\n\n\nReturns:\n\n\na dictionary with the config of the class.\n\n\n\n\nload_from_config\n\u00b6\n\n\nload_from_config\n(\nconfig\n)\n\n\n\n\n\nUtilizes the provided config to instantiate a new\ninstance of the class with the same arguments.\n\n\nArguments:\n\n\n\n\nconfig (dict):\n A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.\n\n\n\n\nReturns:\n\n\nA new instance of this class with the correct arguments.\n\n\n\n\nsample\n\u00b6\n\n\nsample\n()\n\n\n\n\n\nSamples a number of values from its set of discrete values.\n\n\nReturns:\n\n\na list of values from its set of possible values.\n\n\n\n\n[source]\n\n\nHyperParameterList\n\u00b6\n\n\npyshac\n.\nconfig\n.\nhyperparameters\n.\nHyperParameterList\n(\nhyper_parameter_list\n=\nNone\n)\n\n\n\n\n\nA composite hyper parameter, that encloses a list of hyper parameters\n(either discrete or continuous) and provides utility methods for efficient\nhandling by the engine.\n\n\nArguments:\n\n\n\n\nhyper_parameter_list (list(AnstractHyperParameter) | None):\n A list of\n    hyper parameters or None (which initializes this with 0 elements).\n\n\n\n\n\n\nHyperParameterList methods\n\u00b6\n\n\nadd_hyper_parameter\n\u00b6\n\n\nadd_hyper_parameter\n(\nparameter\n)\n\n\n\n\n\nAdds a single hyper parameter (discrete or continuous) to the list\nof hyper parameters managed by this HyperParameterList.\n\n\nArguments:\n\n\n\n\nparameter (AbstractHyperParameter):\n a subclass of AbstractHyperParameter,\n    which will be embedded into this composite class.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the passed parameter is \nNone\n, or the name already\n    exists in the list of managed parameters.\n\n\n\n\n\n\nremove_hyper_parameter\n\u00b6\n\n\nremove_hyper_parameter\n(\nparameter\n)\n\n\n\n\n\nRemoves a single hyper parameter (discrete or continuous) from the list\nof hyper parameters managed by this HyperParameterList.\n\n\nArguments:\n\n\n\n\nparameter (AbstractHyperParameter, str):\n A string name or a subclass\n    of AbstractHyperParameter which needs to be removed.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the passed parameter is \nNone\n.\n\n\n\n\n\n\nsample\n\u00b6\n\n\nsample\n()\n\n\n\n\n\nSamples all of its component parameters and returns a list of the samples.\n\n\nReturns:\n\n\nlist of sampled parameters.\n\n\n\n\nencode\n\u00b6\n\n\nencode\n(\nx\n)\n\n\n\n\n\nEncodes a list of sampled hyper parameters.\n\n\nArguments:\n\n\n\n\nx (list | np.ndarray):\n A python list or numpy array of samples\n    from the list of hyper parameters.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If a numpy array of more than 1 dimension is provided.\n\n\n\n\nReturns:\n\n\nndarray(float).\n\n\n\n\ndecode\n\u00b6\n\n\ndecode\n(\nx\n)\n\n\n\n\n\nDecodes a list of sampled hyper parameters.\n\n\nArguments:\n\n\nx (list(int | float)): a list of encoded integer or floating point\n    values that are to be decoded.\n\n\nReturns:\n\n\nlist of decoded samples.\n\n\n\n\nget_config\n\u00b6\n\n\nget_config\n()\n\n\n\n\n\nCreates the config of the class with all of its values.\n\n\nReturns:\n\n\nan ordered dictionary with the config of the class.\n\n\n\n\nload_from_config\n\u00b6\n\n\nload_from_config\n(\nconfig\n)\n\n\n\n\n\n\n\nget_parameter_names\n\u00b6\n\n\nget_parameter_names\n()\n\n\n\n\n\nGets a list of all the parameter names managed by this class.\n\n\nReturns:\n\n\na list(str) with the names of the parameters.\n\n\n\n\nget_parameter\n\u00b6\n\n\nget_parameter\n(\nname\n)\n\n\n\n\n\nUtility method to get the hyper parameter class by its name.\n\n\nArguments:\n\n\n\n\nname (str):\n Name of the class or its alias.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the class with the provided name does not exists in\n    the set of available parameters.\n\n\n\n\nReturns:\n\n\nThe hyper parameter class.\n\n\n\n\nset_custom_parameter_class\n\u00b6\n\n\nset_custom_parameter_class\n(\ncls\n)\n\n\n\n\n\nUtility function to dynamically add a custom hyper parameter\nto the set of available hyper parameters.\n\n\nArguments:\n\n\n\n\ncls (cls):\n A class which extends \nAbstractHyperParameter\n in some way\n    and implements the abstract methods.",
            "title": "Hyper Parameters"
        },
        {
            "location": "/config/hyperparameters/#hyper-parameters",
            "text": "There are 3 primary hyper parameters :   DiscreteHyperParameter (DiscreteHP)  UniformContinuousHyperParameter (UniformHP)  NormalContinuousHyperParameter (NormalHP)   As their names suggest, each hyper paramter takes specific parameters or value ranges.    Discrete Hyper Parmeters takes lists of any python data type that can be serialized.   This includes numpy values, and even numpy arrays     Continuous Hyper Parameters take ranges of values   Uniform Continuous Hyper Parameters will sample uniformly between the min and max values  Normal Continuous Hyper Parameters will sample from the normal distribution with the provided mean and standard deviation     A special composite hyper parameter, called  HyperParameterList  is used to provide a convenient interface to several\nhyper parameters at once, and is used internally by the training algorithm.",
            "title": "Hyper Parameters"
        },
        {
            "location": "/config/hyperparameters/#class-information",
            "text": "[source]",
            "title": "Class Information"
        },
        {
            "location": "/config/hyperparameters/#abstracthyperparameter",
            "text": "pyshac . config . hyperparameters . AbstractHyperParameter ( name ,   values )   Abstract Hyper Parameter that defines the methods that all hyperparameters\nneed to supply  Arguments:   name (str):  Name of the hyper parameter  values (List, None):  A list of values (must all be pickle-able and hashable)\n    values or None. If None, it is assumed to be a continuous value generator.   Raises:   ValueError : If the  name  is not specified.",
            "title": "AbstractHyperParameter"
        },
        {
            "location": "/config/hyperparameters/#abstracthyperparameter-methods",
            "text": "",
            "title": "AbstractHyperParameter methods"
        },
        {
            "location": "/config/hyperparameters/#decode",
            "text": "decode ( x )   Abstract method that defines how the parameter is decoded so\nthat the model can be properly trained.  Arguments:   x (int | float):  an encoded value that needs to be decoded.   Raises:   NotImplementedError : Must be overridden by the subclass.   Returns:  a decoded value for the encoded input  x .",
            "title": "decode"
        },
        {
            "location": "/config/hyperparameters/#encode",
            "text": "encode ( x )   Abstract method that defines how the parameter is encoded\nso that the model can properly be trained.  Arguments:   x (int | float | str):  a single value that needs to be encoded.   Raises:   NotImplementedError : Must be overridden by the subclass.   Returns:  an encoded representation of the value of  x .",
            "title": "encode"
        },
        {
            "location": "/config/hyperparameters/#get_config",
            "text": "get_config ()   Creates the config of the class with all of its values.  Returns:  a dictionary with the config of the class.",
            "title": "get_config"
        },
        {
            "location": "/config/hyperparameters/#load_from_config",
            "text": "load_from_config ( config )   Utilizes the provided config to instantiate a new\ninstance of the class with the same arguments.  Arguments:   config (dict):  A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.   Returns:  A new instance of this class with the correct arguments.",
            "title": "load_from_config"
        },
        {
            "location": "/config/hyperparameters/#sample",
            "text": "sample ()   Abstract method that defines how parameters are sampled.  Raises:   NotImplementedError : Must be overridden by the subclass.   Returns:  a singular value sampled from possible values.   [source]",
            "title": "sample"
        },
        {
            "location": "/config/hyperparameters/#abstractcontinuoushyperparameter",
            "text": "pyshac . config . hyperparameters . AbstractContinuousHyperParameter ( name ,   val1 ,   val2 ,   log_encode = False )   An abstract hyper parameter that represents a parameter that can take a range\nof values from a certain distribution.  Arguments:   name (str):  Name of the parameter.  val1 (float):  A symbolic value that is used by subclasses.  val2 (float):  A symbolic value that is used by subclasses.  log_encode (bool):  Determines whether the encoding must be in natural\n    log-space or not.   Raises:   NotImplementedError : If  sample()  is called.",
            "title": "AbstractContinuousHyperParameter"
        },
        {
            "location": "/config/hyperparameters/#abstractcontinuoushyperparameter-methods",
            "text": "",
            "title": "AbstractContinuousHyperParameter methods"
        },
        {
            "location": "/config/hyperparameters/#decode_1",
            "text": "decode ( x )   Decodes the floating point value into normal space if  log_space  was set in\nthe constructor, else returns its original value.  Arguments:   x (float):  a single encoded sample.   Returns:  float.",
            "title": "decode"
        },
        {
            "location": "/config/hyperparameters/#encode_1",
            "text": "encode ( x )   Encodes the floating point value into log space if  log_space  was set in\nthe constructor, else returns its original value.  Arguments:   x (float):  a single sample.   Returns:  float.",
            "title": "encode"
        },
        {
            "location": "/config/hyperparameters/#get_config_1",
            "text": "get_config ()   Creates the config of the class with all of its values.  Returns:  a dictionary with the config of the class.",
            "title": "get_config"
        },
        {
            "location": "/config/hyperparameters/#load_from_config_1",
            "text": "load_from_config ( config )   Utilizes the provided config to instantiate a new\ninstance of the class with the same arguments.  Arguments:   config (dict):  A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.   Returns:  A new instance of this class with the correct arguments.",
            "title": "load_from_config"
        },
        {
            "location": "/config/hyperparameters/#sample_1",
            "text": "sample ()   Abstract method that must be redefined by base classes.  Returns:  a float value.   [source]",
            "title": "sample"
        },
        {
            "location": "/config/hyperparameters/#abstractmulticontinuoushyperparameter",
            "text": "pyshac . config . hyperparameters . AbstractMultiContinuousHyperParameter ( name ,   val1 ,   val2 ,   log_encode = False ,   sample_count = 1 )   An abstract hyper parameter that represents a parameter that can take a range\nof values from a certain distribution, sampled multiple times.  Arguments:   name (str):  Name of the parameter.  val1 (float):  A symbolic value that is used by subclasses.  val2 (float):  A symbolic value that is used by subclasses.  log_encode (bool):  Determines whether the encoding must be in natural\n    log-space or not.  sample_count (int):  Number of samples that are required from this\n    hyper parameter.   Raises:   NotImplementedError : If  sample()  is called.  ValueErroe : If sample count is less than 1.",
            "title": "AbstractMultiContinuousHyperParameter"
        },
        {
            "location": "/config/hyperparameters/#abstractmulticontinuoushyperparameter-methods",
            "text": "",
            "title": "AbstractMultiContinuousHyperParameter methods"
        },
        {
            "location": "/config/hyperparameters/#decode_2",
            "text": "decode ( x )   Decodes a list of floating point values into normal space if  log_space \nwas set in the constructor, else returns its original value.  Arguments:   x (float):  a list of encoded samples.   Returns:  list of floats.",
            "title": "decode"
        },
        {
            "location": "/config/hyperparameters/#encode_2",
            "text": "encode ( x )   Encodes a list of floating point values into log space if  log_space \nwas set in the constructor, else returns its original value.  Arguments:   x (float):  a list of samples.   Returns:  list of floats.",
            "title": "encode"
        },
        {
            "location": "/config/hyperparameters/#get_config_2",
            "text": "get_config ()   Creates the config of the class with all of its values.  Returns:  a dictionary with the config of the class.",
            "title": "get_config"
        },
        {
            "location": "/config/hyperparameters/#load_from_config_2",
            "text": "load_from_config ( config )   Utilizes the provided config to instantiate a new\ninstance of the class with the same arguments.  Arguments:   config (dict):  A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.   Returns:  A new instance of this class with the correct arguments.",
            "title": "load_from_config"
        },
        {
            "location": "/config/hyperparameters/#sample_2",
            "text": "sample ()   Abstract method that must be redefined by base classes.  Returns:  a float value.   [source]",
            "title": "sample"
        },
        {
            "location": "/config/hyperparameters/#discretehyperparameter",
            "text": "pyshac . config . hyperparameters . DiscreteHyperParameter ( name ,   values )   Discrete Hyper Parameter that defines a set of discrete values that it can take.  Arguments:   name (str):  Name of the hyper parameter.  values (list):  A list of values (must all be pickle-able and hashable)\n    values or None.   Raises:   ValueError : If the  name  is not specified.\n.   Raises:   ValueError : If the  name  is not specified.",
            "title": "DiscreteHyperParameter"
        },
        {
            "location": "/config/hyperparameters/#discretehyperparameter-methods",
            "text": "",
            "title": "DiscreteHyperParameter methods"
        },
        {
            "location": "/config/hyperparameters/#decode_3",
            "text": "decode ( x )   Decodes a single encoded integer into its original value.  Args:   x (int):  an integer encoded value.   Returns:  (int | float | str) representing the actual decoded value.",
            "title": "decode"
        },
        {
            "location": "/config/hyperparameters/#encode_3",
            "text": "encode ( x )   Encodes a single value into an integer index.  Arguments:   x (int | float | str):  A value sampled from its possible values.   Returns:  int value representing its encoded index.",
            "title": "encode"
        },
        {
            "location": "/config/hyperparameters/#get_config_3",
            "text": "get_config ()   Creates the config of the class with all of its values.  Returns:  a dictionary with the config of the class.",
            "title": "get_config"
        },
        {
            "location": "/config/hyperparameters/#load_from_config_3",
            "text": "load_from_config ( config )   Utilizes the provided config to instantiate a new\ninstance of the class with the same arguments.  Arguments:   config (dict):  A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.   Returns:  A new instance of this class with the correct arguments.",
            "title": "load_from_config"
        },
        {
            "location": "/config/hyperparameters/#sample_3",
            "text": "sample ()   Samples a single value from its set of discrete values.  Returns:  a single value from its list of possible values.   [source]",
            "title": "sample"
        },
        {
            "location": "/config/hyperparameters/#uniformcontinuoushyperparameter",
            "text": "pyshac . config . hyperparameters . UniformContinuousHyperParameter ( name ,   min_value ,   max_value ,   log_encode = False )   A hyper parameter that represents a parameter that can take a range\nof values from a uniform distribution.  Arguments:   name (str):  Name of the parameter.  min_value (float):  The minimum value (inclusive) that the uniform\n    distribution can take.  max_value (float):  The maximum value (exclusive) that the uniform\n    distribution can take.  log_encode (bool):  Determines whether the encoding must be in natural\n    log-space or not.",
            "title": "UniformContinuousHyperParameter"
        },
        {
            "location": "/config/hyperparameters/#uniformcontinuoushyperparameter-methods",
            "text": "",
            "title": "UniformContinuousHyperParameter methods"
        },
        {
            "location": "/config/hyperparameters/#decode_4",
            "text": "decode ( x )   Decodes the floating point value into normal space if  log_space  was set in\nthe constructor, else returns its original value.  Arguments:   x (float):  a single encoded sample.   Returns:  float.",
            "title": "decode"
        },
        {
            "location": "/config/hyperparameters/#encode_4",
            "text": "encode ( x )   Encodes the floating point value into log space if  log_space  was set in\nthe constructor, else returns its original value.  Arguments:   x (float):  a single sample.   Returns:  float.",
            "title": "encode"
        },
        {
            "location": "/config/hyperparameters/#get_config_4",
            "text": "get_config ()   Creates the config of the class with all of its values.  Returns:  a dictionary with the config of the class.",
            "title": "get_config"
        },
        {
            "location": "/config/hyperparameters/#load_from_config_4",
            "text": "load_from_config ( config )   Utilizes the provided config to instantiate a new\ninstance of the class with the same arguments.  Arguments:   config (dict):  A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.   Returns:  A new instance of this class with the correct arguments.",
            "title": "load_from_config"
        },
        {
            "location": "/config/hyperparameters/#sample_4",
            "text": "sample ()   Samples uniformly from the range [min_value, max_value).  Returns:  float.   [source]",
            "title": "sample"
        },
        {
            "location": "/config/hyperparameters/#normalcontinuoushyperparameter",
            "text": "pyshac . config . hyperparameters . NormalContinuousHyperParameter ( name ,   mean ,   std )   A hyper parameter that represents a parameter that can take a range\nof values from a normal distribution.  Arguments:   name (str):  Name of the parameter.  mean (float):  The mean of the normal distribution.  std (float):  The standard deviation of the normal distribution.",
            "title": "NormalContinuousHyperParameter"
        },
        {
            "location": "/config/hyperparameters/#normalcontinuoushyperparameter-methods",
            "text": "",
            "title": "NormalContinuousHyperParameter methods"
        },
        {
            "location": "/config/hyperparameters/#decode_5",
            "text": "decode ( x )   Decodes the floating point value into normal space if  log_space  was set in\nthe constructor, else returns its original value.  Arguments:   x (float):  a single encoded sample.   Returns:  float.",
            "title": "decode"
        },
        {
            "location": "/config/hyperparameters/#encode_5",
            "text": "encode ( x )   Encodes the floating point value into log space if  log_space  was set in\nthe constructor, else returns its original value.  Arguments:   x (float):  a single sample.   Returns:  float.",
            "title": "encode"
        },
        {
            "location": "/config/hyperparameters/#get_config_5",
            "text": "get_config ()   Creates the config of the class with all of its values.  Returns:  a dictionary with the config of the class.",
            "title": "get_config"
        },
        {
            "location": "/config/hyperparameters/#load_from_config_5",
            "text": "load_from_config ( config )   Utilizes the provided config to instantiate a new\ninstance of the class with the same arguments.  Arguments:   config (dict):  A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.   Returns:  A new instance of this class with the correct arguments.",
            "title": "load_from_config"
        },
        {
            "location": "/config/hyperparameters/#sample_5",
            "text": "sample ()   Samples from the normal distribution with a mean and standard deviation\nas specified in the constructor.  Returns:  float.   [source]",
            "title": "sample"
        },
        {
            "location": "/config/hyperparameters/#multidiscretehyperparameter",
            "text": "pyshac . config . hyperparameters . MultiDiscreteHyperParameter ( name ,   values ,   sample_count = 1 )   Discrete Hyper Parameter that defines a set of discrete values that it can take,\nand acts upon a list of samples.  Arguments:   name (str):  Name of the hyper parameter.  values (list):  A list of values (must all be pickle-able and hashable)\n    values or None.  sample_count (int):  Number of samples that are required from this\n    hyper parameter.   Raises:   ValueError : If the  name  is not specified or if  sample_count  is less\n    than 1.\n.   Raises:   ValueError : If the  name  is not specified or if  sample_count  is less\n    than 1.",
            "title": "MultiDiscreteHyperParameter"
        },
        {
            "location": "/config/hyperparameters/#multidiscretehyperparameter-methods",
            "text": "",
            "title": "MultiDiscreteHyperParameter methods"
        },
        {
            "location": "/config/hyperparameters/#decode_6",
            "text": "decode ( x )   Decodes a list of encoded integers into their original value.  Args:   x (int):  a list of integer encoded values.   Returns:  list of (int | float | str) representing the actual decoded\n    values.",
            "title": "decode"
        },
        {
            "location": "/config/hyperparameters/#encode_6",
            "text": "encode ( x )   Encodes a list of values into a list of the corresponding integer index.  Arguments:   x (int | float | str):  A list of values sampled from its\n    possible values.   Returns:  list of int values representing their encoded index.",
            "title": "encode"
        },
        {
            "location": "/config/hyperparameters/#get_config_6",
            "text": "get_config ()   Creates the config of the class with all of its values.  Returns:  a dictionary with the config of the class.",
            "title": "get_config"
        },
        {
            "location": "/config/hyperparameters/#load_from_config_6",
            "text": "load_from_config ( config )   Utilizes the provided config to instantiate a new\ninstance of the class with the same arguments.  Arguments:   config (dict):  A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.   Returns:  A new instance of this class with the correct arguments.",
            "title": "load_from_config"
        },
        {
            "location": "/config/hyperparameters/#sample_6",
            "text": "sample ()   Samples a number of values from its set of discrete values.  Returns:  a list of values from its set of possible values.   [source]",
            "title": "sample"
        },
        {
            "location": "/config/hyperparameters/#multiuniformcontinuoushyperparameter",
            "text": "pyshac . config . hyperparameters . MultiUniformContinuousHyperParameter ( name ,   min_value ,   max_value ,   log_encode = False ,   sample_count = 1 )   A hyper parameter that represents a parameter that can take a range\nof values from a uniform distribution, sampled multiple times.  Arguments:   name (str):  Name of the parameter.  min_value (float):  The minimum value (inclusive) that the uniform\n    distribution can take.  max_value (float):  The maximum value (exclusive) that the uniform\n    distribution can take.  log_encode (bool):  Determines whether the encoding must be in natural\n    log-space or not.  sample_count (int):  Number of samples that are required from this\n    hyper parameter.   Raises:   ValueErroe : If sample count is less than 1.",
            "title": "MultiUniformContinuousHyperParameter"
        },
        {
            "location": "/config/hyperparameters/#multiuniformcontinuoushyperparameter-methods",
            "text": "",
            "title": "MultiUniformContinuousHyperParameter methods"
        },
        {
            "location": "/config/hyperparameters/#decode_7",
            "text": "decode ( x )   Decodes a list of floating point values into normal space if  log_space \nwas set in the constructor, else returns its original value.  Arguments:   x (float):  a list of encoded samples.   Returns:  list of floats.",
            "title": "decode"
        },
        {
            "location": "/config/hyperparameters/#encode_7",
            "text": "encode ( x )   Encodes a list of floating point values into log space if  log_space \nwas set in the constructor, else returns its original value.  Arguments:   x (float):  a list of samples.   Returns:  list of floats.",
            "title": "encode"
        },
        {
            "location": "/config/hyperparameters/#get_config_7",
            "text": "get_config ()   Creates the config of the class with all of its values.  Returns:  a dictionary with the config of the class.",
            "title": "get_config"
        },
        {
            "location": "/config/hyperparameters/#load_from_config_7",
            "text": "load_from_config ( config )   Utilizes the provided config to instantiate a new\ninstance of the class with the same arguments.  Arguments:   config (dict):  A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.   Returns:  A new instance of this class with the correct arguments.",
            "title": "load_from_config"
        },
        {
            "location": "/config/hyperparameters/#sample_7",
            "text": "sample ()   Samples uniformly from the range [min_value, max_value).  Returns:  list of floats.   [source]",
            "title": "sample"
        },
        {
            "location": "/config/hyperparameters/#multidiscretehyperparameter_1",
            "text": "pyshac . config . hyperparameters . MultiDiscreteHyperParameter ( name ,   values ,   sample_count = 1 )   Discrete Hyper Parameter that defines a set of discrete values that it can take,\nand acts upon a list of samples.  Arguments:   name (str):  Name of the hyper parameter.  values (list):  A list of values (must all be pickle-able and hashable)\n    values or None.  sample_count (int):  Number of samples that are required from this\n    hyper parameter.   Raises:   ValueError : If the  name  is not specified or if  sample_count  is less\n    than 1.\n.   Raises:   ValueError : If the  name  is not specified or if  sample_count  is less\n    than 1.",
            "title": "MultiDiscreteHyperParameter"
        },
        {
            "location": "/config/hyperparameters/#multidiscretehyperparameter-methods_1",
            "text": "",
            "title": "MultiDiscreteHyperParameter methods"
        },
        {
            "location": "/config/hyperparameters/#decode_8",
            "text": "decode ( x )   Decodes a list of encoded integers into their original value.  Args:   x (int):  a list of integer encoded values.   Returns:  list of (int | float | str) representing the actual decoded\n    values.",
            "title": "decode"
        },
        {
            "location": "/config/hyperparameters/#encode_8",
            "text": "encode ( x )   Encodes a list of values into a list of the corresponding integer index.  Arguments:   x (int | float | str):  A list of values sampled from its\n    possible values.   Returns:  list of int values representing their encoded index.",
            "title": "encode"
        },
        {
            "location": "/config/hyperparameters/#get_config_8",
            "text": "get_config ()   Creates the config of the class with all of its values.  Returns:  a dictionary with the config of the class.",
            "title": "get_config"
        },
        {
            "location": "/config/hyperparameters/#load_from_config_8",
            "text": "load_from_config ( config )   Utilizes the provided config to instantiate a new\ninstance of the class with the same arguments.  Arguments:   config (dict):  A dictionary having keys as the argument names\n    and values as the values specified to the class using its\n    constructor.   Returns:  A new instance of this class with the correct arguments.",
            "title": "load_from_config"
        },
        {
            "location": "/config/hyperparameters/#sample_8",
            "text": "sample ()   Samples a number of values from its set of discrete values.  Returns:  a list of values from its set of possible values.   [source]",
            "title": "sample"
        },
        {
            "location": "/config/hyperparameters/#hyperparameterlist",
            "text": "pyshac . config . hyperparameters . HyperParameterList ( hyper_parameter_list = None )   A composite hyper parameter, that encloses a list of hyper parameters\n(either discrete or continuous) and provides utility methods for efficient\nhandling by the engine.  Arguments:   hyper_parameter_list (list(AnstractHyperParameter) | None):  A list of\n    hyper parameters or None (which initializes this with 0 elements).",
            "title": "HyperParameterList"
        },
        {
            "location": "/config/hyperparameters/#hyperparameterlist-methods",
            "text": "",
            "title": "HyperParameterList methods"
        },
        {
            "location": "/config/hyperparameters/#add_hyper_parameter",
            "text": "add_hyper_parameter ( parameter )   Adds a single hyper parameter (discrete or continuous) to the list\nof hyper parameters managed by this HyperParameterList.  Arguments:   parameter (AbstractHyperParameter):  a subclass of AbstractHyperParameter,\n    which will be embedded into this composite class.   Raises:   ValueError : If the passed parameter is  None , or the name already\n    exists in the list of managed parameters.",
            "title": "add_hyper_parameter"
        },
        {
            "location": "/config/hyperparameters/#remove_hyper_parameter",
            "text": "remove_hyper_parameter ( parameter )   Removes a single hyper parameter (discrete or continuous) from the list\nof hyper parameters managed by this HyperParameterList.  Arguments:   parameter (AbstractHyperParameter, str):  A string name or a subclass\n    of AbstractHyperParameter which needs to be removed.   Raises:   ValueError : If the passed parameter is  None .",
            "title": "remove_hyper_parameter"
        },
        {
            "location": "/config/hyperparameters/#sample_9",
            "text": "sample ()   Samples all of its component parameters and returns a list of the samples.  Returns:  list of sampled parameters.",
            "title": "sample"
        },
        {
            "location": "/config/hyperparameters/#encode_9",
            "text": "encode ( x )   Encodes a list of sampled hyper parameters.  Arguments:   x (list | np.ndarray):  A python list or numpy array of samples\n    from the list of hyper parameters.   Raises:   ValueError : If a numpy array of more than 1 dimension is provided.   Returns:  ndarray(float).",
            "title": "encode"
        },
        {
            "location": "/config/hyperparameters/#decode_9",
            "text": "decode ( x )   Decodes a list of sampled hyper parameters.  Arguments:  x (list(int | float)): a list of encoded integer or floating point\n    values that are to be decoded.  Returns:  list of decoded samples.",
            "title": "decode"
        },
        {
            "location": "/config/hyperparameters/#get_config_9",
            "text": "get_config ()   Creates the config of the class with all of its values.  Returns:  an ordered dictionary with the config of the class.",
            "title": "get_config"
        },
        {
            "location": "/config/hyperparameters/#load_from_config_9",
            "text": "load_from_config ( config )",
            "title": "load_from_config"
        },
        {
            "location": "/config/hyperparameters/#get_parameter_names",
            "text": "get_parameter_names ()   Gets a list of all the parameter names managed by this class.  Returns:  a list(str) with the names of the parameters.",
            "title": "get_parameter_names"
        },
        {
            "location": "/config/hyperparameters/#get_parameter",
            "text": "get_parameter ( name )   Utility method to get the hyper parameter class by its name.  Arguments:   name (str):  Name of the class or its alias.   Raises:   ValueError : If the class with the provided name does not exists in\n    the set of available parameters.   Returns:  The hyper parameter class.",
            "title": "get_parameter"
        },
        {
            "location": "/config/hyperparameters/#set_custom_parameter_class",
            "text": "set_custom_parameter_class ( cls )   Utility function to dynamically add a custom hyper parameter\nto the set of available hyper parameters.  Arguments:   cls (cls):  A class which extends  AbstractHyperParameter  in some way\n    and implements the abstract methods.",
            "title": "set_custom_parameter_class"
        },
        {
            "location": "/config/data/",
            "text": "Datasets\n\u00b6\n\n\n\n\nThe \nDataset\n class is used to provide utilities for data management, such as adding training samples,\nencoding and decoding data points for the training, serialization and restoration to continue training and so on.\n\n\nA \nDataset\n is an internal component of the algorithm being used, and will often not be interacted with directly.\nIt provides a convenient interface to the \nHyperParameterList\n that is used to wrap the hyper parameters, and its\nserialization / recovery for multiple training runs.\n\n\nClass Information\n\u00b6\n\n\n\n\n[source]\n\n\nDataset\n\u00b6\n\n\npyshac\n.\nconfig\n.\ndata\n.\nDataset\n(\nparameter_list\n=\nNone\n,\n \nbasedir\n=\n'shac'\n)\n\n\n\n\n\nDataset manager for the engines.\n\n\nHolds the samples and their associated evaluated values in a format\nthat can be serialized / restored as well as encoder / decoded for\ntraining.\n\n\nArguments:\n\n\n\n\nparameter_list (hp.HyperParameterList | list | None):\n A python list\n    of Hyper Parameters, or a HyperParameterList that has been built.\n    Can also be None, if the parameters are to be assigned later.\n\n\nbasedir (str):\n The base directory where the data of the engine\n    will be stored.\n\n\n\n\n\n\nDataset methods\n\u00b6\n\n\nadd_sample\n\u00b6\n\n\nadd_sample\n(\nparameters\n,\n \nvalue\n)\n\n\n\n\n\nAdds a single row of data to the dataset.\nEach row contains the hyper parameter configuration as well as its associated\nevaluation measure.\n\n\nArguments:\n\n\n\n\nparameters (list):\n A list of hyper parameters that have been sampled\n\n\nvalue (float):\n The evaluation measure for the above sample.\n\n\n\n\n\n\nclear\n\u00b6\n\n\nclear\n()\n\n\n\n\n\nRemoves all the data of the dataset.\n\n\n\n\ndecode_dataset\n\u00b6\n\n\ndecode_dataset\n(\nX\n=\nNone\n)\n\n\n\n\n\nDecode the input samples such that discrete hyper parameters are mapped\nto their original values and continuous valued hyper paramters are left alone.\n\n\nArguments:\n\n\n\n\nX (np.ndarray | None):\n The input list of encoded samples. Can be None,\n    in which case it defaults to the internal samples, which are encoded\n    and then decoded.\n\n\n\n\nReturns:\n\n\nnp.ndarray\n\n\n\n\nencode_dataset\n\u00b6\n\n\nencode_dataset\n(\nX\n=\nNone\n,\n \nY\n=\nNone\n,\n \nobjective\n=\n'max'\n)\n\n\n\n\n\nEncode the entire dataset such that discrete hyper parameters are mapped\nto integer indices and continuous valued hyper paramters are left alone.\n\n\nArguments\n\n\n\n\nX (list | np.ndarray | None):\n The input list of samples. Can be None,\n    in which case it defaults to the internal samples.\n\n\nY (list | np.ndarray | None):\n The input list of evaluation measures.\n    Can be None, in which case it defaults to the internal evaluation\n    values.\n\n\nobjective (str):\n Whether to maximize or minimize the\n    value of the labels.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If \nobjective\n is not in [\nmax\n, \nmin\n]\n\n\n\n\nReturns:\n\n\nA tuple of numpy arrays (np.ndarray, np.ndarray)\n\n\n\n\nget_best_parameters\n\u00b6\n\n\nget_best_parameters\n(\nobjective\n=\n'max'\n)\n\n\n\n\n\nSelects the best hyper parameters according to the maximization\nor minimization of the objective value.\n\n\nReturns \nNone\n if there are no samples in the dataset.\n\n\nArguments:\n\n\n\n\nobjective\n: String label indicating whether to maximize or minimize\n    the objective value.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the objective is not \nmax\n or \nmin\n.\n\n\n\n\nReturns:\n\n\nA list of hyperparameter settings or \nNone\n if the dataset is empty.\n\n\n\n\nget_dataset\n\u00b6\n\n\nget_dataset\n()\n\n\n\n\n\nGets the entire dataset as a numpy array.\n\n\nReturns:\n\n\n(np.ndarray, np.ndarray)\n\n\n\n\nget_parameters\n\u00b6\n\n\nget_parameters\n()\n\n\n\n\n\nGets the hyper parameter list manager\n\n\nReturns:\n\n\nHyperParameterList\n\n\n\n\nload_from_directory\n\u00b6\n\n\nload_from_directory\n(\nbasedir\n=\n'shac'\n)\n\n\n\n\n\nStatic method to load the dataset from a directory.\n\n\nArguments:\n\n\n\n\nbasedir (str):\n The base directory where 'shac' directory is. It will\n    build the path to the data and parameters itself.\n\n\n\n\nRaises:\n\n\n\n\nFileNotFoundError\n: If the directory does not contain the data and parameters.\n\n\n\n\n\n\nprepare_parameter\n\u00b6\n\n\nprepare_parameter\n(\nsample\n)\n\n\n\n\n\nWraps a hyper parameter sample list with the name of the\nparameter in an OrderedDict.\n\n\nArguments:\n\n\n\n\nsample (list):\n A list of sampled hyper parameters\n\n\n\n\nReturns:\n\n\nOrderedDict(str, int | float | str)\n\n\n\n\nrestore_dataset\n\u00b6\n\n\nrestore_dataset\n()\n\n\n\n\n\nRestores the entire dataset from a CSV file saved at the path provided by\n\ndata_path\n. Also loads the parameters (list of hyperparameters).\n\n\nRaises:\n\n\n\n\nFileNotFoundError\n: If the dataset is not at the provided path.\n\n\n\n\n\n\nsave_dataset\n\u00b6\n\n\nsave_dataset\n()\n\n\n\n\n\nSerializes the entire dataset into a CSV file saved at the path\nprovide by \ndata_path\n. Also saves the parameters (list of hyper parameters).\n\n\nRaises:\n\n\n\n\nValueError\n: If trying to save a dataset when its parameters have not been\n    set.\n\n\n\n\n\n\nset_dataset\n\u00b6\n\n\nset_dataset\n(\nX\n,\n \nY\n)\n\n\n\n\n\nSets a numpy array as the dataset.\n\n\nArguments:\n\n\n\n\nX (list | tuple | np.ndarray):\n A numpy array or python list/tuple that contains\n    the samples of the dataset.\n\n\nY (list | tuple | np.ndarray):\n A numpy array or python list/tuple that contains\n    the evaluations of the dataset.\n\n\n\n\n\n\nset_parameters\n\u00b6\n\n\nset_parameters\n(\nparameters\n)\n\n\n\n\n\nSets the hyper parameter list manager\n\n\nArguments:\n\n\n\n\nparameters (hp.HyperParameterList | list):\n a Hyper Parameter List\n    or a python list of Hyper Parameters.\n\n\n\n\n\n\nflatten_parameters\n\u00b6\n\n\nflatten_parameters\n(\nparams\n)\n\n\n\n\n\nTakes an OrderedDict or a list of lists, and flattens it into a\nlist containing the items.\n\n\nArguments:\n\n\n\n\nparams (OrderedDict | list of lists):\n The parameters that were\n    provided by the engine, either as an OrderedDict or a list\n    of list representation.\n\n\n\n\nReturns:\n\n\na flattened python list containing just the sampled values.",
            "title": "Datasets"
        },
        {
            "location": "/config/data/#datasets",
            "text": "The  Dataset  class is used to provide utilities for data management, such as adding training samples,\nencoding and decoding data points for the training, serialization and restoration to continue training and so on.  A  Dataset  is an internal component of the algorithm being used, and will often not be interacted with directly.\nIt provides a convenient interface to the  HyperParameterList  that is used to wrap the hyper parameters, and its\nserialization / recovery for multiple training runs.",
            "title": "Datasets"
        },
        {
            "location": "/config/data/#class-information",
            "text": "[source]",
            "title": "Class Information"
        },
        {
            "location": "/config/data/#dataset",
            "text": "pyshac . config . data . Dataset ( parameter_list = None ,   basedir = 'shac' )   Dataset manager for the engines.  Holds the samples and their associated evaluated values in a format\nthat can be serialized / restored as well as encoder / decoded for\ntraining.  Arguments:   parameter_list (hp.HyperParameterList | list | None):  A python list\n    of Hyper Parameters, or a HyperParameterList that has been built.\n    Can also be None, if the parameters are to be assigned later.  basedir (str):  The base directory where the data of the engine\n    will be stored.",
            "title": "Dataset"
        },
        {
            "location": "/config/data/#dataset-methods",
            "text": "",
            "title": "Dataset methods"
        },
        {
            "location": "/config/data/#add_sample",
            "text": "add_sample ( parameters ,   value )   Adds a single row of data to the dataset.\nEach row contains the hyper parameter configuration as well as its associated\nevaluation measure.  Arguments:   parameters (list):  A list of hyper parameters that have been sampled  value (float):  The evaluation measure for the above sample.",
            "title": "add_sample"
        },
        {
            "location": "/config/data/#clear",
            "text": "clear ()   Removes all the data of the dataset.",
            "title": "clear"
        },
        {
            "location": "/config/data/#decode_dataset",
            "text": "decode_dataset ( X = None )   Decode the input samples such that discrete hyper parameters are mapped\nto their original values and continuous valued hyper paramters are left alone.  Arguments:   X (np.ndarray | None):  The input list of encoded samples. Can be None,\n    in which case it defaults to the internal samples, which are encoded\n    and then decoded.   Returns:  np.ndarray",
            "title": "decode_dataset"
        },
        {
            "location": "/config/data/#encode_dataset",
            "text": "encode_dataset ( X = None ,   Y = None ,   objective = 'max' )   Encode the entire dataset such that discrete hyper parameters are mapped\nto integer indices and continuous valued hyper paramters are left alone.  Arguments   X (list | np.ndarray | None):  The input list of samples. Can be None,\n    in which case it defaults to the internal samples.  Y (list | np.ndarray | None):  The input list of evaluation measures.\n    Can be None, in which case it defaults to the internal evaluation\n    values.  objective (str):  Whether to maximize or minimize the\n    value of the labels.   Raises:   ValueError : If  objective  is not in [ max ,  min ]   Returns:  A tuple of numpy arrays (np.ndarray, np.ndarray)",
            "title": "encode_dataset"
        },
        {
            "location": "/config/data/#get_best_parameters",
            "text": "get_best_parameters ( objective = 'max' )   Selects the best hyper parameters according to the maximization\nor minimization of the objective value.  Returns  None  if there are no samples in the dataset.  Arguments:   objective : String label indicating whether to maximize or minimize\n    the objective value.   Raises:   ValueError : If the objective is not  max  or  min .   Returns:  A list of hyperparameter settings or  None  if the dataset is empty.",
            "title": "get_best_parameters"
        },
        {
            "location": "/config/data/#get_dataset",
            "text": "get_dataset ()   Gets the entire dataset as a numpy array.  Returns:  (np.ndarray, np.ndarray)",
            "title": "get_dataset"
        },
        {
            "location": "/config/data/#get_parameters",
            "text": "get_parameters ()   Gets the hyper parameter list manager  Returns:  HyperParameterList",
            "title": "get_parameters"
        },
        {
            "location": "/config/data/#load_from_directory",
            "text": "load_from_directory ( basedir = 'shac' )   Static method to load the dataset from a directory.  Arguments:   basedir (str):  The base directory where 'shac' directory is. It will\n    build the path to the data and parameters itself.   Raises:   FileNotFoundError : If the directory does not contain the data and parameters.",
            "title": "load_from_directory"
        },
        {
            "location": "/config/data/#prepare_parameter",
            "text": "prepare_parameter ( sample )   Wraps a hyper parameter sample list with the name of the\nparameter in an OrderedDict.  Arguments:   sample (list):  A list of sampled hyper parameters   Returns:  OrderedDict(str, int | float | str)",
            "title": "prepare_parameter"
        },
        {
            "location": "/config/data/#restore_dataset",
            "text": "restore_dataset ()   Restores the entire dataset from a CSV file saved at the path provided by data_path . Also loads the parameters (list of hyperparameters).  Raises:   FileNotFoundError : If the dataset is not at the provided path.",
            "title": "restore_dataset"
        },
        {
            "location": "/config/data/#save_dataset",
            "text": "save_dataset ()   Serializes the entire dataset into a CSV file saved at the path\nprovide by  data_path . Also saves the parameters (list of hyper parameters).  Raises:   ValueError : If trying to save a dataset when its parameters have not been\n    set.",
            "title": "save_dataset"
        },
        {
            "location": "/config/data/#set_dataset",
            "text": "set_dataset ( X ,   Y )   Sets a numpy array as the dataset.  Arguments:   X (list | tuple | np.ndarray):  A numpy array or python list/tuple that contains\n    the samples of the dataset.  Y (list | tuple | np.ndarray):  A numpy array or python list/tuple that contains\n    the evaluations of the dataset.",
            "title": "set_dataset"
        },
        {
            "location": "/config/data/#set_parameters",
            "text": "set_parameters ( parameters )   Sets the hyper parameter list manager  Arguments:   parameters (hp.HyperParameterList | list):  a Hyper Parameter List\n    or a python list of Hyper Parameters.",
            "title": "set_parameters"
        },
        {
            "location": "/config/data/#flatten_parameters",
            "text": "flatten_parameters ( params )   Takes an OrderedDict or a list of lists, and flattens it into a\nlist containing the items.  Arguments:   params (OrderedDict | list of lists):  The parameters that were\n    provided by the engine, either as an OrderedDict or a list\n    of list representation.   Returns:  a flattened python list containing just the sampled values.",
            "title": "flatten_parameters"
        },
        {
            "location": "/config/callbacks/",
            "text": "Callbacks\n\u00b6\n\n\n\n\nCallbacks can be used with PySHAC for custom code execution, such as monitoring the improvement of the engine,\nmaintaining a history of the training session or simply writing the logs to files.\n\n\nCallbacks allow you the flexibility to prepare your state prior to training or evaluation, and in doing so can\nallow one to perform stateful evaluation if necessary using concurrent evaluators.\n\n\nClass Information\n\u00b6\n\n\n\n\n[source]\n\n\nCallback\n\u00b6\n\n\npyshac\n.\nconfig\n.\ncallbacks\n.\nCallback\n()\n\n\n\n\n\nAbstract base class used to build new callbacks.\n\n\nProperties\n\n\n\n\nengine\n: instance of a PySHAC Engine.\n    Reference of the model being trained.\n\n\n\n\nThe \nlogs\n dictionary that callback methods\ntake as argument will contain keys for quantities relevant to\nthe current batch or epoch.\n\n\n\n\nCallback methods\n\u00b6\n\n\non_dataset_changed\n\u00b6\n\n\non_dataset_changed\n(\ndataset\n,\n \nlogs\n=\nNone\n)\n\n\n\n\n\nCalled with the dataset maintained by the engine is\nupdated with new samples or data.\n\n\nArguments:\n\n\n\n\ndataset (Dataset):\n A Dataset object which contains\n    the history of sampled parameters and their\n    corresponding evaluation values.\n\n\nlogs (dict | None):\n dictionary of logs.\n\n\n\n\n\n\non_epoch_begin\n\u00b6\n\n\non_epoch_begin\n(\nepoch\n,\n \nlogs\n=\nNone\n)\n\n\n\n\n\nCalled at the start of an epoch.\n\n\nArguments\n\n\n\n\nepoch (int):\n index of epoch.\n\n\nlogs (dict | None):\n dictionary of logs.\n\n\n\n\n\n\non_epoch_end\n\u00b6\n\n\non_epoch_end\n(\nepoch\n,\n \nlogs\n=\nNone\n)\n\n\n\n\n\nCalled at the end of an epoch.\n\n\nArguments\n\n\n\n\nepoch (int):\n index of epoch.\n\n\nlogs (dict | None):\n dictionary of logs.\n\n\n\n\n\n\non_evaluation_begin\n\u00b6\n\n\non_evaluation_begin\n(\nparams\n,\n \nlogs\n=\nNone\n)\n\n\n\n\n\nCalled before the generated parameters are evaluated.\n\n\nArguments:\n\n\nparams (list(OrderedDict)): A list of OrderedDicts,\n    such that each item is a dictionary of the names\n    and sampled values of a HyperParemeterList.\n- \nlogs (dict | None):\n dictionary of logs.\n\n\n\n\non_evaluation_ended\n\u00b6\n\n\non_evaluation_ended\n(\nevaluations\n,\n \nlogs\n=\nNone\n)\n\n\n\n\n\nCalled after the generated parameters are evaluated.\n\n\nArguments:\n\n\nevaluations (list(float)): A list of floating point\n    values, corresponding to the provided parameter\n    settings.\n- \nlogs (dict | None):\n dictionary of logs.\n\n\n\n\non_train_begin\n\u00b6\n\n\non_train_begin\n(\nlogs\n=\nNone\n)\n\n\n\n\n\nCalled at the beginning of training.\n\n\nArguments\n\n\n\n\nlogs (dict | None):\n dictionary of logs.\n\n\n\n\n\n\non_train_end\n\u00b6\n\n\non_train_end\n(\nlogs\n=\nNone\n)\n\n\n\n\n\nCalled at the end of training.\n\n\nArguments\n\n\n\n\nlogs (dict | None):\n dictionary of logs.\n\n\n\n\n\n\nset_engine\n\u00b6\n\n\nset_engine\n(\nengine\n)\n\n\n\n\n\nSets an instance of a PySHAC Engine.\n\n\nArguments:\n\n\n\n\nengine (AbstractSHAC):\n A concrete implementation of the\n    SHAC engine.\n\n\n\n\n\n\n[source]\n\n\nHistory\n\u00b6\n\n\npyshac\n.\nconfig\n.\ncallbacks\n.\nHistory\n()\n\n\n\n\n\nCallback that records events into a \nHistory\n object.\n\n\nThis callback is automatically applied to\nevery engine. The \nHistory\n object\ngets returned by the \nfit\n or \nfit_dataset\n methods.\n\n\n\n\n[source]\n\n\nCSVLogger\n\u00b6\n\n\npyshac\n.\nconfig\n.\ncallbacks\n.\nCSVLogger\n(\nfilename\n,\n \nseparator\n=\n','\n,\n \nappend\n=\nFalse\n)\n\n\n\n\n\nCallback that streams epoch results to a csv file.\n\n\nSupports all values that can be represented as a string,\nincluding 1D iterables such as np.ndarray.\n\n\nExample\n\n\ncsv_logger\n \n=\n \nCSVLogger\n(\n'training.log'\n)\n\n\nshac\n.\nfit\n(\nevaluation_function\n,\n \ncallbacks\n=\n[\ncsv_logger\n])\n\n\n\n\n\nArguments\n\n\n\n\nfilename (str):\n filename of the csv file, e.g. 'run/log.csv'.\n\n\nseparator (str):\n string used to separate elements in the csv file.\n\n\nappend (bool):\n True: append if file exists (useful for continuing\n    training). False: overwrite existing file,\n\n\n\n\n\n\nget_history\n\u00b6\n\n\nget_history\n(\ncallbacks\n)\n\n\n\n\n\nGets the History callback from a list of callbacks.\n\n\nArgumetns:\n\n\n\n\ncallbacks (list | CallbackList):\n a list of callbacks\n\n\n\n\nReturns:\n\n\nA History callback object or None if it was not found.",
            "title": "Callbacks"
        },
        {
            "location": "/config/callbacks/#callbacks",
            "text": "Callbacks can be used with PySHAC for custom code execution, such as monitoring the improvement of the engine,\nmaintaining a history of the training session or simply writing the logs to files.  Callbacks allow you the flexibility to prepare your state prior to training or evaluation, and in doing so can\nallow one to perform stateful evaluation if necessary using concurrent evaluators.",
            "title": "Callbacks"
        },
        {
            "location": "/config/callbacks/#class-information",
            "text": "[source]",
            "title": "Class Information"
        },
        {
            "location": "/config/callbacks/#callback",
            "text": "pyshac . config . callbacks . Callback ()   Abstract base class used to build new callbacks.  Properties   engine : instance of a PySHAC Engine.\n    Reference of the model being trained.   The  logs  dictionary that callback methods\ntake as argument will contain keys for quantities relevant to\nthe current batch or epoch.",
            "title": "Callback"
        },
        {
            "location": "/config/callbacks/#callback-methods",
            "text": "",
            "title": "Callback methods"
        },
        {
            "location": "/config/callbacks/#on_dataset_changed",
            "text": "on_dataset_changed ( dataset ,   logs = None )   Called with the dataset maintained by the engine is\nupdated with new samples or data.  Arguments:   dataset (Dataset):  A Dataset object which contains\n    the history of sampled parameters and their\n    corresponding evaluation values.  logs (dict | None):  dictionary of logs.",
            "title": "on_dataset_changed"
        },
        {
            "location": "/config/callbacks/#on_epoch_begin",
            "text": "on_epoch_begin ( epoch ,   logs = None )   Called at the start of an epoch.  Arguments   epoch (int):  index of epoch.  logs (dict | None):  dictionary of logs.",
            "title": "on_epoch_begin"
        },
        {
            "location": "/config/callbacks/#on_epoch_end",
            "text": "on_epoch_end ( epoch ,   logs = None )   Called at the end of an epoch.  Arguments   epoch (int):  index of epoch.  logs (dict | None):  dictionary of logs.",
            "title": "on_epoch_end"
        },
        {
            "location": "/config/callbacks/#on_evaluation_begin",
            "text": "on_evaluation_begin ( params ,   logs = None )   Called before the generated parameters are evaluated.  Arguments:  params (list(OrderedDict)): A list of OrderedDicts,\n    such that each item is a dictionary of the names\n    and sampled values of a HyperParemeterList.\n-  logs (dict | None):  dictionary of logs.",
            "title": "on_evaluation_begin"
        },
        {
            "location": "/config/callbacks/#on_evaluation_ended",
            "text": "on_evaluation_ended ( evaluations ,   logs = None )   Called after the generated parameters are evaluated.  Arguments:  evaluations (list(float)): A list of floating point\n    values, corresponding to the provided parameter\n    settings.\n-  logs (dict | None):  dictionary of logs.",
            "title": "on_evaluation_ended"
        },
        {
            "location": "/config/callbacks/#on_train_begin",
            "text": "on_train_begin ( logs = None )   Called at the beginning of training.  Arguments   logs (dict | None):  dictionary of logs.",
            "title": "on_train_begin"
        },
        {
            "location": "/config/callbacks/#on_train_end",
            "text": "on_train_end ( logs = None )   Called at the end of training.  Arguments   logs (dict | None):  dictionary of logs.",
            "title": "on_train_end"
        },
        {
            "location": "/config/callbacks/#set_engine",
            "text": "set_engine ( engine )   Sets an instance of a PySHAC Engine.  Arguments:   engine (AbstractSHAC):  A concrete implementation of the\n    SHAC engine.    [source]",
            "title": "set_engine"
        },
        {
            "location": "/config/callbacks/#history",
            "text": "pyshac . config . callbacks . History ()   Callback that records events into a  History  object.  This callback is automatically applied to\nevery engine. The  History  object\ngets returned by the  fit  or  fit_dataset  methods.   [source]",
            "title": "History"
        },
        {
            "location": "/config/callbacks/#csvlogger",
            "text": "pyshac . config . callbacks . CSVLogger ( filename ,   separator = ',' ,   append = False )   Callback that streams epoch results to a csv file.  Supports all values that can be represented as a string,\nincluding 1D iterables such as np.ndarray.  Example  csv_logger   =   CSVLogger ( 'training.log' )  shac . fit ( evaluation_function ,   callbacks = [ csv_logger ])   Arguments   filename (str):  filename of the csv file, e.g. 'run/log.csv'.  separator (str):  string used to separate elements in the csv file.  append (bool):  True: append if file exists (useful for continuing\n    training). False: overwrite existing file,",
            "title": "CSVLogger"
        },
        {
            "location": "/config/callbacks/#get_history",
            "text": "get_history ( callbacks )   Gets the History callback from a list of callbacks.  Argumetns:   callbacks (list | CallbackList):  a list of callbacks   Returns:  A History callback object or None if it was not found.",
            "title": "get_history"
        },
        {
            "location": "/core/engine/",
            "text": "SHAC Engine\n\u00b6\n\n\n\n\nThe core algorithm from the paper \nParallel Architecture and Hyperparameter Search via Successive Halving and Classification\n.\n\n\nThis engine provides an interface similar to Scikit-Learn, with two methods - \nfit\n and \npredict\n which training and parameter sampling respectively.\n\n\nThe data for the classifiers is generated via rejection sampling, using Joblib for parallel batch generation and evaluation.\nIt even allows for halted training - such that training can resume from the previous stage without any issue.\n\n\nTwo important user inputs to this class are :\n\n\n\n\nEvaluation function\n\n\nHyper Parameter list\n\n\n\n\n\n\nNote\n\u00b6\n\n\nThe engine will generate samples at each epoch of training, and supply them to the evaluation function which will also be\nexecuted in parallel. Therefore, all stages of sample generation, training, evaluation must be thread safe.\n\n\nWhile the training algorithm can manage thread safety of the generator and training modules, the evaluation module is\nfor the user to write.\n\n\nTherefore, we provide wrappers such as \nTensorflowSHAC\n, \nKerasSHAC\n and \nTorchSHAC\n to allow safer evaluation. However, this comes\nat significant cost of execution, as a new Tensorflow Graph and likewise, a new Keras Session must be built for each evaluator thread.\n\n\n\n\nSerial Evaluation\n\n\nIf parallel evaluation is not preferred, please refer the \nSerial Evaluation\n page.\n\n\n\n\nClass Information\n\u00b6\n\n\n\n\n[source]\n\n\nSHAC\n\u00b6\n\n\npyshac\n.\ncore\n.\nengine\n.\nSHAC\n(\nhyperparameter_list\n,\n \ntotal_budget\n,\n \nnum_batches\n,\n \nobjective\n=\n'max'\n,\n \nmax_classifiers\n=\n18\n,\n \nsave_dir\n=\n'shac'\n)\n\n\n\n\n\nThe default and generic implementation of the SHAC algorithm. It is a wrapper over the\nabstract class, and performs no additional maintenance over the evaluation function.\n\n\nIt is fastest engine, but assumes that the evaluation function is thread safe and\nthe system has sufficient memory to run several copies of the evaluation function\nat the same time.\n\n\nThis engine is suitable for Numpy / PyTorch based work. Both numpy and PyTorch\ndynamically allocate memory, and therefore, as long as the system has enough memory\nto run multiple copies of the evaluation model, there is no additional memory management\nto be done.\n\n\nStill, for PyTorch, the number of evaluation processes should be carefully set,\nso as not to exhaust all CPU / GPU memory during execution.\n\n\nArguments:\n\n\n\n\nevaluation_function ((int, list) -> float):\n The evaluation function is passed\n    only the integer id (of the worker) and the sampled hyper parameters in\n    an OrderedDict.  The evaluation function is expected to pass a python\n    floating point number representing the evaluated value.\n\n\nhyperparameter_list (hp.HyperParameterList | None):\n A list of parameters\n    (or a HyperParameterList) that are passed to define the search space.\n    Can be None, so that it is loaded from disk instead.\n\n\ntotal_budget (int):\n \nN\n. Defines the total number of models to evaluate.\n\n\nnum_batches (int):\n \nM\n. Defines the number of batches the work is distributed\n    to. Must be set such that \ntotal budget\n is divisible by \nbatch size\n.\n\n\nobjective (str):\n Can be \nmax\n or \nmin\n. Whether to maximise\n    the evaluation measure or minimize it.\n\n\nmax_classifiers (int):\n Maximum number of classifiers that\n    are trained. Default (18) is according to the paper.\n\n\nsave_dir (str):\n The base directory where the data of the engine\n    will be stored.\n\n\n\n\nReferences:\n\n\n\n\nParallel Architecture and Hyperparameter Search via Successive Halving and Classification\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If \ntotal budget\n is not divisible by \nbatch size\n.\n\n\n\n\n\n\nSHAC methods\n\u00b6\n\n\nfit\n\u00b6\n\n\nfit\n(\neval_fn\n,\n \nskip_cv_checks\n=\nFalse\n,\n \nearly_stop\n=\nFalse\n,\n \nrelax_checks\n=\nFalse\n,\n \ncallbacks\n=\nNone\n)\n\n\n\n\n\nGenerated batches of samples, trains \ntotal_classifiers\n number of XGBoost models\nand evaluates each batch with the supplied function in parallel.\n\n\nAllows manually changing the number of processes that are used to generate samples\nor to evaluate them. While the defaults generally work well, further performance\ngains can be had by trying different values according to the limits of the system.\n\n\n>>>\n \neval\n \n=\n \nlambda\n \nid\n,\n \nparams\n:\n \nnp\n.\nexp\n(\nparams\n[\n'x'\n])\n\n\n>>>\n \nshac\n \n=\n \nSHAC\n(\nparams\n,\n \ntotal_budget\n=\n100\n,\n \nnum_batches\n=\n10\n)\n\n\n\n>>>\n \nshac\n.\nset_num_parallel_generators\n(\n20\n)\n  \n# change the number of generator process\n\n\n>>>\n \nshac\n.\nset_num_parallel_evaluators\n(\n1\n)\n  \n# change the number of evaluator processes\n\n\n>>>\n \nshac\n.\ngenerator_backend\n \n=\n \n'multiprocessing'\n  \n# change the backend for the generator (default is `multiprocessing`)\n\n\n>>>\n \nshac\n.\nconcurrent_evaluators\n()\n  \n# change the backend of the evaluator to use `threading`\n\n\n\n\n\nHas an adaptive behaviour based on what epoch it is on, since later epochs require\nfar more number of samples to generate a single batch of samples. When the epoch\nnumber increases beyond 10, it doubles the number of generator processes.\n\n\nThis adaptivity can be removed by setting the parameter \nlimit_memory\n to True.\n\n>>> shac.limit_memory = True\n\n\n\nArguments:\n\n\n\n\nevaluation_function ((int, list) -> float):\n The evaluation function is passed\n    only the integer id (of the worker) and the sampled hyper parameters in\n    an OrderedDict.  The evaluation function is expected to pass a python\n    floating point number representing the evaluated value.\n\n\nskip_cv_checks (bool):\n If set, will not perform 5 fold cross validation check\n    on the models before adding them to the classifer list. Useful when the\n    batch size is small.\n\n\nearly_stop (bool):\n Stop running if fail to find a classifier that beats the\n    last stage of evaluations.\n\n\nrelax_checks (bool):\n If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.\n\n\ncallbacks (list | None):\n Optional list of callbacks that are executed when\n    the engine is being trained. \nHistory\n callback is automatically added\n    for all calls to \nfit\n.\n\n\n\n\nReturns:\n\n\nA \nHistory\n object which tracks all the important information\nduring training, and can be accessed using \nhistory.history\n\nas a dictionary.\n\n\n\n\nfit_dataset\n\u00b6\n\n\nfit_dataset\n(\ndataset_path\n,\n \nskip_cv_checks\n=\nFalse\n,\n \nearly_stop\n=\nFalse\n,\n \npresort\n=\nTrue\n,\n \ncallbacks\n=\nNone\n)\n\n\n\n\n\nUses the provided dataset file to train the engine, instead of using\nthe sequentual halving and classification algorithm directly. The data\nprovided in the path must strictly follow the format of the dataset\nmaintained by the engine.\n\n\nStandard format of datasets:\n\n\nEach dataset csv file must contain an integer id column named \"id\"\nas its 1\nst\n column, followed by several columns describing the values\ntaken by the hyper parameters, and the final column must be for\nthe the objective criterion, and \nmust\n be named \"scores\".\n\n\nThe csv file \nmust\n contain a header, following the above format.\n\n\nExample:\n\n\nid,hp1,hp2,scores\n0,1,h1,1.0\n1,1,h2,0.2\n2,0,h1,0.0\n3,0,h3,0.5\n...\n\n\n\n\n\nArguments:\n\n\n\n\ndataset_path (str):\n The full or relative path to a csv file\n    containing the values of the dataset.\n\n\nskip_cv_checks (bool):\n If set, will not perform 5 fold cross\n    validation check on the models before adding them to the\n    classifer list. Useful when the batch size is small.\n\n\nearly_stop (bool):\n Stop running if fail to find a classifier\n    that beats the last stage of evaluations.\n\n\npresort (bool):\n Boolean flag to determine whether to sort\n    the values of the dataset prior to loading. Ascending or\n    descending sort is selected based on whether the engine\n    is maximizing or minimizing the objective. It is preferable\n    to set this always, to train better classifiers.\n\n\ncallbacks (list | None):\n Optional list of callbacks that are executed when\n    the engine is being trained. \nHistory\n callback is automatically added\n    for all calls to \nfit_dataset\n.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the number of hyper parameters in the file\n    are not the same as the number of hyper parameters\n    that are available to the engine or if the number of\n    samples in the provided dataset are less than the\n    required number of samples by the engine.\n\n\nFileNotFoundError\n: If the dataset is not available at the\n    provided filepath.\n\n\n\n\nReturns:\n\n\nA \nHistory\n object which tracks all the important information\nduring training, and can be accessed using \nhistory.history\n\nas a dictionary.\n\n\n\n\npredict\n\u00b6\n\n\npredict\n(\nnum_samples\n=\nNone\n,\n \nnum_batches\n=\nNone\n,\n \nnum_workers_per_batch\n=\nNone\n,\n \nrelax_checks\n=\nFalse\n,\n \nmax_classfiers\n=\nNone\n)\n\n\n\n\n\nUsing trained classifiers, sample the search space and predict which samples\ncan successfully pass through the cascade of classifiers.\n\n\nWhen using a full cascade of 18 classifiers, a vast amount of time to sample\na single sample.\n\n\n\n\nSample mode vs Batch mode\n\n\n\n\nParameters can be generated in either sample mode or batch mode or any combination\nof the two.\n\n\nnum_samples\n is on a per sample basis (1 sample generated per count). Can be \nNone\n or an int >= 0.\n\nnum_batches\n is on a per batch basis (M samples generated per count). Can be \nNone\n or an integer >= 0.\n\n\nThe two are combined to produce a total number of samples which are provided in a\nlist.\n\n\nArguments:\n\n\n\n\nnum_samples (None | int):\n Number of samples to be generated.\n\n\nnum_batches (None | int):\n Number of batches of samples to be generated.\n\n\nnum_workers_per_batch (int):\n Determines how many parallel threads / processes\n    are created to generate the batches. For small batches, it is best to use 1.\n    If left as \nNone\n, defaults to \nnum_parallel_generators\n.\n\n\nrelax_checks (bool):\n If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.\n\n\nmax_classfiers (int | None):\n Number of classifiers to use for sampling.\n    If set to None, will use all classifiers.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If \nmax_classifiers\n is larger than the number of available\n    classifiers.\n\n\n\n\nReturns:\n\n\nbatches of samples in the form of an OrderedDict\n\n\n\n\nsave_data\n\u00b6\n\n\nsave_data\n()\n\n\n\n\n\nSerialize the class objects by serializing the dataset and the trained models.\n\n\n\n\nrestore_data\n\u00b6\n\n\nrestore_data\n()\n\n\n\n\n\nRecover the serialized class objects by loading the dataset and the trained models\nfrom the default save directories.\n\n\n\n\nset_num_parallel_generators\n\u00b6\n\n\nset_num_parallel_generators\n(\nn\n)\n\n\n\n\n\nCheck and sets the number of parallel generators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.\n\n\nArguments:\n\n\n\n\nn (int | None):\n The number of parallel generators required.\n\n\n\n\n\n\nset_num_parallel_evaluators\n\u00b6\n\n\nset_num_parallel_evaluators\n(\nn\n)\n\n\n\n\n\nCheck and sets the number of parallel evaluators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.\n\n\nArguments:\n\n\n\n\nn (int | None):\n The number of parallel evaluators required.\n\n\n\n\n\n\nparallel_evaluators\n\u00b6\n\n\nparallel_evaluators\n()\n\n\n\n\n\nSets the evaluators to use the \nloky\n backend.\n\n\nThe user must take the responsibility of thread safety and memory management.\n\n\n\n\nconcurrent_evaluators\n\u00b6\n\n\nconcurrent_evaluators\n()\n\n\n\n\n\nSets the evaluators to use the threading backend, and therefore\nbe locked by Python's GIL.\n\n\nWhile technically still \"parallel\", it is in fact concurrent execution\nrather than parallel execution of the evaluators.",
            "title": "SHAC"
        },
        {
            "location": "/core/engine/#shac-engine",
            "text": "The core algorithm from the paper  Parallel Architecture and Hyperparameter Search via Successive Halving and Classification .  This engine provides an interface similar to Scikit-Learn, with two methods -  fit  and  predict  which training and parameter sampling respectively.  The data for the classifiers is generated via rejection sampling, using Joblib for parallel batch generation and evaluation.\nIt even allows for halted training - such that training can resume from the previous stage without any issue.  Two important user inputs to this class are :   Evaluation function  Hyper Parameter list",
            "title": "SHAC Engine"
        },
        {
            "location": "/core/engine/#note",
            "text": "The engine will generate samples at each epoch of training, and supply them to the evaluation function which will also be\nexecuted in parallel. Therefore, all stages of sample generation, training, evaluation must be thread safe.  While the training algorithm can manage thread safety of the generator and training modules, the evaluation module is\nfor the user to write.  Therefore, we provide wrappers such as  TensorflowSHAC ,  KerasSHAC  and  TorchSHAC  to allow safer evaluation. However, this comes\nat significant cost of execution, as a new Tensorflow Graph and likewise, a new Keras Session must be built for each evaluator thread.   Serial Evaluation  If parallel evaluation is not preferred, please refer the  Serial Evaluation  page.",
            "title": "Note"
        },
        {
            "location": "/core/engine/#class-information",
            "text": "[source]",
            "title": "Class Information"
        },
        {
            "location": "/core/engine/#shac",
            "text": "pyshac . core . engine . SHAC ( hyperparameter_list ,   total_budget ,   num_batches ,   objective = 'max' ,   max_classifiers = 18 ,   save_dir = 'shac' )   The default and generic implementation of the SHAC algorithm. It is a wrapper over the\nabstract class, and performs no additional maintenance over the evaluation function.  It is fastest engine, but assumes that the evaluation function is thread safe and\nthe system has sufficient memory to run several copies of the evaluation function\nat the same time.  This engine is suitable for Numpy / PyTorch based work. Both numpy and PyTorch\ndynamically allocate memory, and therefore, as long as the system has enough memory\nto run multiple copies of the evaluation model, there is no additional memory management\nto be done.  Still, for PyTorch, the number of evaluation processes should be carefully set,\nso as not to exhaust all CPU / GPU memory during execution.  Arguments:   evaluation_function ((int, list) -> float):  The evaluation function is passed\n    only the integer id (of the worker) and the sampled hyper parameters in\n    an OrderedDict.  The evaluation function is expected to pass a python\n    floating point number representing the evaluated value.  hyperparameter_list (hp.HyperParameterList | None):  A list of parameters\n    (or a HyperParameterList) that are passed to define the search space.\n    Can be None, so that it is loaded from disk instead.  total_budget (int):   N . Defines the total number of models to evaluate.  num_batches (int):   M . Defines the number of batches the work is distributed\n    to. Must be set such that  total budget  is divisible by  batch size .  objective (str):  Can be  max  or  min . Whether to maximise\n    the evaluation measure or minimize it.  max_classifiers (int):  Maximum number of classifiers that\n    are trained. Default (18) is according to the paper.  save_dir (str):  The base directory where the data of the engine\n    will be stored.   References:   Parallel Architecture and Hyperparameter Search via Successive Halving and Classification   Raises:   ValueError : If  total budget  is not divisible by  batch size .",
            "title": "SHAC"
        },
        {
            "location": "/core/engine/#shac-methods",
            "text": "",
            "title": "SHAC methods"
        },
        {
            "location": "/core/engine/#fit",
            "text": "fit ( eval_fn ,   skip_cv_checks = False ,   early_stop = False ,   relax_checks = False ,   callbacks = None )   Generated batches of samples, trains  total_classifiers  number of XGBoost models\nand evaluates each batch with the supplied function in parallel.  Allows manually changing the number of processes that are used to generate samples\nor to evaluate them. While the defaults generally work well, further performance\ngains can be had by trying different values according to the limits of the system.  >>>   eval   =   lambda   id ,   params :   np . exp ( params [ 'x' ])  >>>   shac   =   SHAC ( params ,   total_budget = 100 ,   num_batches = 10 )  >>>   shac . set_num_parallel_generators ( 20 )    # change the number of generator process  >>>   shac . set_num_parallel_evaluators ( 1 )    # change the number of evaluator processes  >>>   shac . generator_backend   =   'multiprocessing'    # change the backend for the generator (default is `multiprocessing`)  >>>   shac . concurrent_evaluators ()    # change the backend of the evaluator to use `threading`   Has an adaptive behaviour based on what epoch it is on, since later epochs require\nfar more number of samples to generate a single batch of samples. When the epoch\nnumber increases beyond 10, it doubles the number of generator processes.  This adaptivity can be removed by setting the parameter  limit_memory  to True. >>> shac.limit_memory = True  Arguments:   evaluation_function ((int, list) -> float):  The evaluation function is passed\n    only the integer id (of the worker) and the sampled hyper parameters in\n    an OrderedDict.  The evaluation function is expected to pass a python\n    floating point number representing the evaluated value.  skip_cv_checks (bool):  If set, will not perform 5 fold cross validation check\n    on the models before adding them to the classifer list. Useful when the\n    batch size is small.  early_stop (bool):  Stop running if fail to find a classifier that beats the\n    last stage of evaluations.  relax_checks (bool):  If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.  callbacks (list | None):  Optional list of callbacks that are executed when\n    the engine is being trained.  History  callback is automatically added\n    for all calls to  fit .   Returns:  A  History  object which tracks all the important information\nduring training, and can be accessed using  history.history \nas a dictionary.",
            "title": "fit"
        },
        {
            "location": "/core/engine/#fit_dataset",
            "text": "fit_dataset ( dataset_path ,   skip_cv_checks = False ,   early_stop = False ,   presort = True ,   callbacks = None )   Uses the provided dataset file to train the engine, instead of using\nthe sequentual halving and classification algorithm directly. The data\nprovided in the path must strictly follow the format of the dataset\nmaintained by the engine.  Standard format of datasets:  Each dataset csv file must contain an integer id column named \"id\"\nas its 1 st  column, followed by several columns describing the values\ntaken by the hyper parameters, and the final column must be for\nthe the objective criterion, and  must  be named \"scores\".  The csv file  must  contain a header, following the above format.  Example:  id,hp1,hp2,scores\n0,1,h1,1.0\n1,1,h2,0.2\n2,0,h1,0.0\n3,0,h3,0.5\n...  Arguments:   dataset_path (str):  The full or relative path to a csv file\n    containing the values of the dataset.  skip_cv_checks (bool):  If set, will not perform 5 fold cross\n    validation check on the models before adding them to the\n    classifer list. Useful when the batch size is small.  early_stop (bool):  Stop running if fail to find a classifier\n    that beats the last stage of evaluations.  presort (bool):  Boolean flag to determine whether to sort\n    the values of the dataset prior to loading. Ascending or\n    descending sort is selected based on whether the engine\n    is maximizing or minimizing the objective. It is preferable\n    to set this always, to train better classifiers.  callbacks (list | None):  Optional list of callbacks that are executed when\n    the engine is being trained.  History  callback is automatically added\n    for all calls to  fit_dataset .   Raises:   ValueError : If the number of hyper parameters in the file\n    are not the same as the number of hyper parameters\n    that are available to the engine or if the number of\n    samples in the provided dataset are less than the\n    required number of samples by the engine.  FileNotFoundError : If the dataset is not available at the\n    provided filepath.   Returns:  A  History  object which tracks all the important information\nduring training, and can be accessed using  history.history \nas a dictionary.",
            "title": "fit_dataset"
        },
        {
            "location": "/core/engine/#predict",
            "text": "predict ( num_samples = None ,   num_batches = None ,   num_workers_per_batch = None ,   relax_checks = False ,   max_classfiers = None )   Using trained classifiers, sample the search space and predict which samples\ncan successfully pass through the cascade of classifiers.  When using a full cascade of 18 classifiers, a vast amount of time to sample\na single sample.   Sample mode vs Batch mode   Parameters can be generated in either sample mode or batch mode or any combination\nof the two.  num_samples  is on a per sample basis (1 sample generated per count). Can be  None  or an int >= 0. num_batches  is on a per batch basis (M samples generated per count). Can be  None  or an integer >= 0.  The two are combined to produce a total number of samples which are provided in a\nlist.  Arguments:   num_samples (None | int):  Number of samples to be generated.  num_batches (None | int):  Number of batches of samples to be generated.  num_workers_per_batch (int):  Determines how many parallel threads / processes\n    are created to generate the batches. For small batches, it is best to use 1.\n    If left as  None , defaults to  num_parallel_generators .  relax_checks (bool):  If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.  max_classfiers (int | None):  Number of classifiers to use for sampling.\n    If set to None, will use all classifiers.   Raises:   ValueError : If  max_classifiers  is larger than the number of available\n    classifiers.   Returns:  batches of samples in the form of an OrderedDict",
            "title": "predict"
        },
        {
            "location": "/core/engine/#save_data",
            "text": "save_data ()   Serialize the class objects by serializing the dataset and the trained models.",
            "title": "save_data"
        },
        {
            "location": "/core/engine/#restore_data",
            "text": "restore_data ()   Recover the serialized class objects by loading the dataset and the trained models\nfrom the default save directories.",
            "title": "restore_data"
        },
        {
            "location": "/core/engine/#set_num_parallel_generators",
            "text": "set_num_parallel_generators ( n )   Check and sets the number of parallel generators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.  Arguments:   n (int | None):  The number of parallel generators required.",
            "title": "set_num_parallel_generators"
        },
        {
            "location": "/core/engine/#set_num_parallel_evaluators",
            "text": "set_num_parallel_evaluators ( n )   Check and sets the number of parallel evaluators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.  Arguments:   n (int | None):  The number of parallel evaluators required.",
            "title": "set_num_parallel_evaluators"
        },
        {
            "location": "/core/engine/#parallel_evaluators",
            "text": "parallel_evaluators ()   Sets the evaluators to use the  loky  backend.  The user must take the responsibility of thread safety and memory management.",
            "title": "parallel_evaluators"
        },
        {
            "location": "/core/engine/#concurrent_evaluators",
            "text": "concurrent_evaluators ()   Sets the evaluators to use the threading backend, and therefore\nbe locked by Python's GIL.  While technically still \"parallel\", it is in fact concurrent execution\nrather than parallel execution of the evaluators.",
            "title": "concurrent_evaluators"
        },
        {
            "location": "/core/torch_engine/",
            "text": "SHAC Managed Engine for PyTorch\n\u00b6\n\n\nProvides a managed engine for PyTorch workflows when using SHAC.\n\n\nSHAC Engine specifically built for PyTorch when using CPUs/GPUs.\n\n\nThis engine is used primarily for its management of how many evaluation processes\nare used, and to provide a unified interface similar to TensorflowSHAC in determining\nthe number of GPUs and CPU cores used.\n\n\nSince PyTorch allocates memory to the graph dynamically, graph maintanence is\nunnecessary. As long as the system has enough memory to run multiple copies of\nthe evaluation model, there is no additional work required by the user inside the\nevaluation function.\n\n\nIf parallel evaluation is not preferred, please refer the \nSerial Evaluation\n page.\n\n\nClass Information\n\u00b6\n\n\n\n\n[source]\n\n\nTorchSHAC\n\u00b6\n\n\npyshac\n.\ncore\n.\nmanaged\n.\ntorch_engine\n.\nTorchSHAC\n(\nhyperparameter_list\n,\n \ntotal_budget\n,\n \nnum_batches\n,\n \nmax_gpu_evaluators\n,\n \nobjective\n=\n'max'\n,\n \nmax_classifiers\n=\n18\n,\n \nmax_cpu_evaluators\n=\n1\n,\n \nsave_dir\n=\n'shac'\n)\n\n\n\n\n\nSHAC Engine specifically built for PyTorch when using CPUs/GPUs.\n\n\nThis engine is used primarily for its management of how many evaluation processes\nare used, and to provide a unified interface similar to TensorflowSHAC in determining\nthe number of GPUs and CPU cores used.\n\n\nSince PyTorch allocates memory to the graph dynamically, graph maintanence is\nunnecessary. As long as the system has enough memory to run multiple copies of\nthe evaluation model, there is no additional work required by the user inside the\nevaluation function.\n\n\nArguments:\n\n\n\n\nhyperparameter_list (hp.HyperParameterList | None):\n A list of parameters\n    (or a HyperParameterList) that are passed to define the search space.\n    Can be None, so that it is loaded from disk instead.\n\n\ntotal_budget (int):\n \nN\n. Defines the total number of models to evaluate.\n\n\nnum_batches (int):\n \nM\n. Defines the number of batches the work is distributed\n    to. Must be set such that \ntotal budget\n is divisible by \nbatch size\n.\n\n\nmax_gpu_evaluators (int):\n number of gpus. Can be 0 or more. Decides the number of\n    GPUs used to evaluate models in parallel.\n\n\nobjective (str):\n Can be \nmax\n or \nmin\n. Whether to maximise the evaluation\n    measure or minimize it.\n\n\nmax_classifiers (int):\n Maximum number of classifiers that\n    are trained. Default (18) is according to the paper.\n\n\nmax_cpu_evaluators (int):\n Positive integer > 0 or -1. Sets the number\n    of parallel evaluation functions calls are executed simultaneously.\n    Set this to 1 unless you have a lot of memory for 2 or more models\n    to be trained simultaneously. If set to -1, uses all CPU cores to\n    evaluate N models simultaneously. Will cause OOM if the models are\n    large.\n\n\nsave_dir (str):\n The base directory where the data of the engine\n    will be stored.\n\n\n\n\nReferences:\n\n\n\n\nParallel Architecture and Hyperparameter Search via Successive Halving and Classification\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If \ntotal budget\n is not divisible by \nbatch size\n.\n\n\n\n\n\n\nTorchSHAC methods\n\u00b6\n\n\nfit\n\u00b6\n\n\nfit\n(\neval_fn\n,\n \nskip_cv_checks\n=\nFalse\n,\n \nearly_stop\n=\nFalse\n,\n \nrelax_checks\n=\nFalse\n,\n \ncallbacks\n=\nNone\n)\n\n\n\n\n\nGenerated batches of samples, trains \ntotal_classifiers\n number of XGBoost models\nand evaluates each batch with the supplied function in parallel.\n\n\nAllows manually changing the number of processes that are used to generate samples\nor to evaluate them. While the defaults generally work well, further performance\ngains can be had by trying different values according to the limits of the system.\n\n\n>>>\n \neval\n \n=\n \nlambda\n \nid\n,\n \nparams\n:\n \nnp\n.\nexp\n(\nparams\n[\n'x'\n])\n\n\n>>>\n \nshac\n \n=\n \nTorchSHAC\n(\nparams\n,\n \ntotal_budget\n=\n100\n,\n \nnum_batches\n=\n10\n)\n\n\n\n>>>\n \nshac\n.\nset_num_parallel_generators\n(\n20\n)\n  \n# change the number of generator process\n\n\n>>>\n \nshac\n.\nset_num_parallel_evaluators\n(\n1\n)\n  \n# change the number of evaluator processes\n\n\n>>>\n \nshac\n.\ngenerator_backend\n \n=\n \n'multiprocessing'\n  \n# change the backend for the generator (default is `multiprocessing`)\n\n\n>>>\n \nshac\n.\nconcurrent_evaluators\n()\n  \n# change the backend of the evaluator to use `threading`\n\n\n\n\n\nHas an adaptive behaviour based on what epoch it is on, since later epochs require\nfar more number of samples to generate a single batch of samples. When the epoch\nnumber increases beyond 10, it doubles the number of generator processes.\n\n\nThis adaptivity can be removed by setting the parameter \nlimit_memory\n to True.\n\n>>> shac.limit_memory = True\n\n\n\nArguments:\n\n\n\n\nevaluation_function ((int, list) -> float):\n The evaluation function is passed\n    only the integer id (of the worker) and the sampled hyper parameters in\n    an OrderedDict.  The evaluation function is expected to pass a python\n    floating point number representing the evaluated value.\n\n\nskip_cv_checks (bool):\n If set, will not perform 5 fold cross validation check\n    on the models before adding them to the classifer list. Useful when the\n    batch size is small.\n\n\nearly_stop (bool):\n Stop running if fail to find a classifier that beats the\n    last stage of evaluations.\n\n\nrelax_checks (bool):\n If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.\n\n\ncallbacks (list | None):\n Optional list of callbacks that are executed when\n    the engine is being trained. \nHistory\n callback is automatically added\n    for all calls to \nfit\n.\n\n\n\n\nReturns:\n\n\nA \nHistory\n object which tracks all the important information\nduring training, and can be accessed using \nhistory.history\n\nas a dictionary.\n\n\n\n\nfit_dataset\n\u00b6\n\n\nfit_dataset\n(\ndataset_path\n,\n \nskip_cv_checks\n=\nFalse\n,\n \nearly_stop\n=\nFalse\n,\n \npresort\n=\nTrue\n,\n \ncallbacks\n=\nNone\n)\n\n\n\n\n\nUses the provided dataset file to train the engine, instead of using\nthe sequentual halving and classification algorithm directly. The data\nprovided in the path must strictly follow the format of the dataset\nmaintained by the engine.\n\n\nStandard format of datasets:\n\n\nEach dataset csv file must contain an integer id column named \"id\"\nas its 1\nst\n column, followed by several columns describing the values\ntaken by the hyper parameters, and the final column must be for\nthe the objective criterion, and \nmust\n be named \"scores\".\n\n\nThe csv file \nmust\n contain a header, following the above format.\n\n\nExample:\n\n\nid,hp1,hp2,scores\n0,1,h1,1.0\n1,1,h2,0.2\n2,0,h1,0.0\n3,0,h3,0.5\n...\n\n\n\n\n\nArguments:\n\n\n\n\ndataset_path (str):\n The full or relative path to a csv file\n    containing the values of the dataset.\n\n\nskip_cv_checks (bool):\n If set, will not perform 5 fold cross\n    validation check on the models before adding them to the\n    classifer list. Useful when the batch size is small.\n\n\nearly_stop (bool):\n Stop running if fail to find a classifier\n    that beats the last stage of evaluations.\n\n\npresort (bool):\n Boolean flag to determine whether to sort\n    the values of the dataset prior to loading. Ascending or\n    descending sort is selected based on whether the engine\n    is maximizing or minimizing the objective. It is preferable\n    to set this always, to train better classifiers.\n\n\ncallbacks (list | None):\n Optional list of callbacks that are executed when\n    the engine is being trained. \nHistory\n callback is automatically added\n    for all calls to \nfit_dataset\n.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the number of hyper parameters in the file\n    are not the same as the number of hyper parameters\n    that are available to the engine or if the number of\n    samples in the provided dataset are less than the\n    required number of samples by the engine.\n\n\nFileNotFoundError\n: If the dataset is not available at the\n    provided filepath.\n\n\n\n\nReturns:\n\n\nA \nHistory\n object which tracks all the important information\nduring training, and can be accessed using \nhistory.history\n\nas a dictionary.\n\n\n\n\npredict\n\u00b6\n\n\npredict\n(\nnum_samples\n=\nNone\n,\n \nnum_batches\n=\nNone\n,\n \nnum_workers_per_batch\n=\nNone\n,\n \nrelax_checks\n=\nFalse\n,\n \nmax_classfiers\n=\nNone\n)\n\n\n\n\n\nUsing trained classifiers, sample the search space and predict which samples\ncan successfully pass through the cascade of classifiers.\n\n\nWhen using a full cascade of 18 classifiers, a vast amount of time to sample\na single sample.\n\n\n\n\nSample mode vs Batch mode\n\n\n\n\nParameters can be generated in either sample mode or batch mode or any combination\nof the two.\n\n\nnum_samples\n is on a per sample basis (1 sample generated per count). Can be \nNone\n or an int >= 0.\n\nnum_batches\n is on a per batch basis (M samples generated per count). Can be \nNone\n or an integer >= 0.\n\n\nThe two are combined to produce a total number of samples which are provided in a\nlist.\n\n\nArguments:\n\n\n\n\nnum_samples (None | int):\n Number of samples to be generated.\n\n\nnum_batches (None | int):\n Number of batches of samples to be generated.\n\n\nnum_workers_per_batch (int):\n Determines how many parallel threads / processes\n    are created to generate the batches. For small batches, it is best to use 1.\n    If left as \nNone\n, defaults to \nnum_parallel_generators\n.\n\n\nrelax_checks (bool):\n If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.\n\n\nmax_classfiers (int | None):\n Number of classifiers to use for sampling.\n    If set to None, will use all classifiers.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If \nmax_classifiers\n is larger than the number of available\n    classifiers.\n\n\n\n\nReturns:\n\n\nbatches of samples in the form of an OrderedDict\n\n\n\n\nsave_data\n\u00b6\n\n\nsave_data\n()\n\n\n\n\n\nSerialize the class objects by serializing the dataset and the trained models.\n\n\n\n\nrestore_data\n\u00b6\n\n\nrestore_data\n()\n\n\n\n\n\nRecover the serialized class objects by loading the dataset and the trained models\nfrom the default save directories.\n\n\n\n\nset_num_parallel_generators\n\u00b6\n\n\nset_num_parallel_generators\n(\nn\n)\n\n\n\n\n\nCheck and sets the number of parallel generators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.\n\n\nArguments:\n\n\n\n\nn (int | None):\n The number of parallel generators required.\n\n\n\n\n\n\nset_num_parallel_evaluators\n\u00b6\n\n\nset_num_parallel_evaluators\n(\nn\n)\n\n\n\n\n\nCheck and sets the number of parallel evaluators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.\n\n\nArguments:\n\n\n\n\nn (int | None):\n The number of parallel evaluators required.\n\n\n\n\n\n\nparallel_evaluators\n\u00b6\n\n\nparallel_evaluators\n()\n\n\n\n\n\nSets the evaluators to use the \nloky\n backend.\n\n\nThe user must take the responsibility of thread safety and memory management.\n\n\n\n\nconcurrent_evaluators\n\u00b6\n\n\nconcurrent_evaluators\n()\n\n\n\n\n\nSets the evaluators to use the threading backend, and therefore\nbe locked by Python's GIL.\n\n\nWhile technically still \"parallel\", it is in fact concurrent execution\nrather than parallel execution of the evaluators.",
            "title": "PyTorch SHAC"
        },
        {
            "location": "/core/torch_engine/#shac-managed-engine-for-pytorch",
            "text": "Provides a managed engine for PyTorch workflows when using SHAC.  SHAC Engine specifically built for PyTorch when using CPUs/GPUs.  This engine is used primarily for its management of how many evaluation processes\nare used, and to provide a unified interface similar to TensorflowSHAC in determining\nthe number of GPUs and CPU cores used.  Since PyTorch allocates memory to the graph dynamically, graph maintanence is\nunnecessary. As long as the system has enough memory to run multiple copies of\nthe evaluation model, there is no additional work required by the user inside the\nevaluation function.  If parallel evaluation is not preferred, please refer the  Serial Evaluation  page.",
            "title": "SHAC Managed Engine for PyTorch"
        },
        {
            "location": "/core/torch_engine/#class-information",
            "text": "[source]",
            "title": "Class Information"
        },
        {
            "location": "/core/torch_engine/#torchshac",
            "text": "pyshac . core . managed . torch_engine . TorchSHAC ( hyperparameter_list ,   total_budget ,   num_batches ,   max_gpu_evaluators ,   objective = 'max' ,   max_classifiers = 18 ,   max_cpu_evaluators = 1 ,   save_dir = 'shac' )   SHAC Engine specifically built for PyTorch when using CPUs/GPUs.  This engine is used primarily for its management of how many evaluation processes\nare used, and to provide a unified interface similar to TensorflowSHAC in determining\nthe number of GPUs and CPU cores used.  Since PyTorch allocates memory to the graph dynamically, graph maintanence is\nunnecessary. As long as the system has enough memory to run multiple copies of\nthe evaluation model, there is no additional work required by the user inside the\nevaluation function.  Arguments:   hyperparameter_list (hp.HyperParameterList | None):  A list of parameters\n    (or a HyperParameterList) that are passed to define the search space.\n    Can be None, so that it is loaded from disk instead.  total_budget (int):   N . Defines the total number of models to evaluate.  num_batches (int):   M . Defines the number of batches the work is distributed\n    to. Must be set such that  total budget  is divisible by  batch size .  max_gpu_evaluators (int):  number of gpus. Can be 0 or more. Decides the number of\n    GPUs used to evaluate models in parallel.  objective (str):  Can be  max  or  min . Whether to maximise the evaluation\n    measure or minimize it.  max_classifiers (int):  Maximum number of classifiers that\n    are trained. Default (18) is according to the paper.  max_cpu_evaluators (int):  Positive integer > 0 or -1. Sets the number\n    of parallel evaluation functions calls are executed simultaneously.\n    Set this to 1 unless you have a lot of memory for 2 or more models\n    to be trained simultaneously. If set to -1, uses all CPU cores to\n    evaluate N models simultaneously. Will cause OOM if the models are\n    large.  save_dir (str):  The base directory where the data of the engine\n    will be stored.   References:   Parallel Architecture and Hyperparameter Search via Successive Halving and Classification   Raises:   ValueError : If  total budget  is not divisible by  batch size .",
            "title": "TorchSHAC"
        },
        {
            "location": "/core/torch_engine/#torchshac-methods",
            "text": "",
            "title": "TorchSHAC methods"
        },
        {
            "location": "/core/torch_engine/#fit",
            "text": "fit ( eval_fn ,   skip_cv_checks = False ,   early_stop = False ,   relax_checks = False ,   callbacks = None )   Generated batches of samples, trains  total_classifiers  number of XGBoost models\nand evaluates each batch with the supplied function in parallel.  Allows manually changing the number of processes that are used to generate samples\nor to evaluate them. While the defaults generally work well, further performance\ngains can be had by trying different values according to the limits of the system.  >>>   eval   =   lambda   id ,   params :   np . exp ( params [ 'x' ])  >>>   shac   =   TorchSHAC ( params ,   total_budget = 100 ,   num_batches = 10 )  >>>   shac . set_num_parallel_generators ( 20 )    # change the number of generator process  >>>   shac . set_num_parallel_evaluators ( 1 )    # change the number of evaluator processes  >>>   shac . generator_backend   =   'multiprocessing'    # change the backend for the generator (default is `multiprocessing`)  >>>   shac . concurrent_evaluators ()    # change the backend of the evaluator to use `threading`   Has an adaptive behaviour based on what epoch it is on, since later epochs require\nfar more number of samples to generate a single batch of samples. When the epoch\nnumber increases beyond 10, it doubles the number of generator processes.  This adaptivity can be removed by setting the parameter  limit_memory  to True. >>> shac.limit_memory = True  Arguments:   evaluation_function ((int, list) -> float):  The evaluation function is passed\n    only the integer id (of the worker) and the sampled hyper parameters in\n    an OrderedDict.  The evaluation function is expected to pass a python\n    floating point number representing the evaluated value.  skip_cv_checks (bool):  If set, will not perform 5 fold cross validation check\n    on the models before adding them to the classifer list. Useful when the\n    batch size is small.  early_stop (bool):  Stop running if fail to find a classifier that beats the\n    last stage of evaluations.  relax_checks (bool):  If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.  callbacks (list | None):  Optional list of callbacks that are executed when\n    the engine is being trained.  History  callback is automatically added\n    for all calls to  fit .   Returns:  A  History  object which tracks all the important information\nduring training, and can be accessed using  history.history \nas a dictionary.",
            "title": "fit"
        },
        {
            "location": "/core/torch_engine/#fit_dataset",
            "text": "fit_dataset ( dataset_path ,   skip_cv_checks = False ,   early_stop = False ,   presort = True ,   callbacks = None )   Uses the provided dataset file to train the engine, instead of using\nthe sequentual halving and classification algorithm directly. The data\nprovided in the path must strictly follow the format of the dataset\nmaintained by the engine.  Standard format of datasets:  Each dataset csv file must contain an integer id column named \"id\"\nas its 1 st  column, followed by several columns describing the values\ntaken by the hyper parameters, and the final column must be for\nthe the objective criterion, and  must  be named \"scores\".  The csv file  must  contain a header, following the above format.  Example:  id,hp1,hp2,scores\n0,1,h1,1.0\n1,1,h2,0.2\n2,0,h1,0.0\n3,0,h3,0.5\n...  Arguments:   dataset_path (str):  The full or relative path to a csv file\n    containing the values of the dataset.  skip_cv_checks (bool):  If set, will not perform 5 fold cross\n    validation check on the models before adding them to the\n    classifer list. Useful when the batch size is small.  early_stop (bool):  Stop running if fail to find a classifier\n    that beats the last stage of evaluations.  presort (bool):  Boolean flag to determine whether to sort\n    the values of the dataset prior to loading. Ascending or\n    descending sort is selected based on whether the engine\n    is maximizing or minimizing the objective. It is preferable\n    to set this always, to train better classifiers.  callbacks (list | None):  Optional list of callbacks that are executed when\n    the engine is being trained.  History  callback is automatically added\n    for all calls to  fit_dataset .   Raises:   ValueError : If the number of hyper parameters in the file\n    are not the same as the number of hyper parameters\n    that are available to the engine or if the number of\n    samples in the provided dataset are less than the\n    required number of samples by the engine.  FileNotFoundError : If the dataset is not available at the\n    provided filepath.   Returns:  A  History  object which tracks all the important information\nduring training, and can be accessed using  history.history \nas a dictionary.",
            "title": "fit_dataset"
        },
        {
            "location": "/core/torch_engine/#predict",
            "text": "predict ( num_samples = None ,   num_batches = None ,   num_workers_per_batch = None ,   relax_checks = False ,   max_classfiers = None )   Using trained classifiers, sample the search space and predict which samples\ncan successfully pass through the cascade of classifiers.  When using a full cascade of 18 classifiers, a vast amount of time to sample\na single sample.   Sample mode vs Batch mode   Parameters can be generated in either sample mode or batch mode or any combination\nof the two.  num_samples  is on a per sample basis (1 sample generated per count). Can be  None  or an int >= 0. num_batches  is on a per batch basis (M samples generated per count). Can be  None  or an integer >= 0.  The two are combined to produce a total number of samples which are provided in a\nlist.  Arguments:   num_samples (None | int):  Number of samples to be generated.  num_batches (None | int):  Number of batches of samples to be generated.  num_workers_per_batch (int):  Determines how many parallel threads / processes\n    are created to generate the batches. For small batches, it is best to use 1.\n    If left as  None , defaults to  num_parallel_generators .  relax_checks (bool):  If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.  max_classfiers (int | None):  Number of classifiers to use for sampling.\n    If set to None, will use all classifiers.   Raises:   ValueError : If  max_classifiers  is larger than the number of available\n    classifiers.   Returns:  batches of samples in the form of an OrderedDict",
            "title": "predict"
        },
        {
            "location": "/core/torch_engine/#save_data",
            "text": "save_data ()   Serialize the class objects by serializing the dataset and the trained models.",
            "title": "save_data"
        },
        {
            "location": "/core/torch_engine/#restore_data",
            "text": "restore_data ()   Recover the serialized class objects by loading the dataset and the trained models\nfrom the default save directories.",
            "title": "restore_data"
        },
        {
            "location": "/core/torch_engine/#set_num_parallel_generators",
            "text": "set_num_parallel_generators ( n )   Check and sets the number of parallel generators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.  Arguments:   n (int | None):  The number of parallel generators required.",
            "title": "set_num_parallel_generators"
        },
        {
            "location": "/core/torch_engine/#set_num_parallel_evaluators",
            "text": "set_num_parallel_evaluators ( n )   Check and sets the number of parallel evaluators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.  Arguments:   n (int | None):  The number of parallel evaluators required.",
            "title": "set_num_parallel_evaluators"
        },
        {
            "location": "/core/torch_engine/#parallel_evaluators",
            "text": "parallel_evaluators ()   Sets the evaluators to use the  loky  backend.  The user must take the responsibility of thread safety and memory management.",
            "title": "parallel_evaluators"
        },
        {
            "location": "/core/torch_engine/#concurrent_evaluators",
            "text": "concurrent_evaluators ()   Sets the evaluators to use the threading backend, and therefore\nbe locked by Python's GIL.  While technically still \"parallel\", it is in fact concurrent execution\nrather than parallel execution of the evaluators.",
            "title": "concurrent_evaluators"
        },
        {
            "location": "/core/tf_engine/",
            "text": "SHAC Managed Engine for Tensorflow\n\u00b6\n\n\n\n\nProvides a managed engine for Tensorflow workflows when using SHAC.\n\n\nPerforms a few useful tasks such as :\n\n\n\n\n\n\nProvide a tf.Session object: In addition to the worker id and the parameter dictionary, a tf.Session is provided as the first\nparameter to the evaluation function. This session wraps the underlying graph, and can be used to freely evaluate all operations\ninside the evaluation function.\n\n\n\n\n\n\nGraph scope management: All Tensorflow operations inside the evalution function will be under the scope of a managed tf.Graph,\nsuch that the provided session can be used to evaluate all ops inside the evaluation function.\n\n\n\n\n\n\nMemory Management: One the evaluation is done, the graph destruction and session closing are managed automatically.\n\n\n\n\n\n\nIf parallel evaluation is not preferred, please refer the \nSerial Evaluation\n page.\n\n\nClass Information\n\u00b6\n\n\n\n\n[source]\n\n\nTensorflowSHAC\n\u00b6\n\n\npyshac\n.\ncore\n.\nmanaged\n.\ntf_engine\n.\nTensorflowSHAC\n(\nhyperparameter_list\n,\n \ntotal_budget\n,\n \nnum_batches\n,\n \nmax_gpu_evaluators\n,\n \nobjective\n=\n'max'\n,\n \nmax_classifiers\n=\n18\n,\n \nmax_cpu_evaluators\n=\n1\n,\n \nsave_dir\n=\n'shac'\n)\n\n\n\n\n\nSHAC Engine specifically built for the Graph based workflow of Tensorflow.\n\n\nIt wraps the abstract SHAC engine with utilities to improve workflow with Tensorflow,\nand performs additional maintenance over the evaluation function, such as creating a\ngraph and session for it, and then destroying it and releasing its resources once\nevaluation is over.\n\n\nThis engine is suitable for Tensorflow based work. Since tensorflow allocates\nmemory to the graph, graph maintanence is managed as much as possible. As long\nas the system has enough memory to run multiple copies of the evaluation model,\nthere is no additional work required by the user inside the evaluation function.\n\n\nNote : When using Eager Execution, it is preferred to use the default \nSHAC\n engine,\nas memory management is done by Tensorflow automatically in such a scenario.\n\n\nArguments:\n\n\n\n\nhyperparameter_list (hp.HyperParameterList | None):\n A list of parameters\n    (or a HyperParameterList) that are passed to define the search space.\n    Can be None, so that it is loaded from disk instead.\n\n\ntotal_budget (int):\n \nN\n. Defines the total number of models to evaluate.\n\n\nnum_batches (int):\n \nM\n. Defines the number of batches the work is distributed\n    to. Must be set such that \ntotal budget\n is divisible by \nbatch size\n.\n\n\nmax_gpu_evaluators (int):\n number of gpus. Can be 0 or more. Decides the number of\n    GPUs used to evaluate models in parallel.\n\n\nobjective (str):\n Can be \nmax\n or \nmin\n. Whether to maximise the evaluation\n    measure or minimize it.\n\n\nmax_classifiers (int):\n Maximum number of classifiers that\n    are trained. Default (18) is according to the paper.\n\n\nmax_cpu_evaluators (int):\n Positive integer > 0 or -1. Sets the number\n    of parallel evaluation functions calls are executed simultaneously.\n    Set this to 1 unless you have a lot of memory for 2 or more models\n    to be trained simultaneously. If set to -1, uses all CPU cores to\n    evaluate N models simultaneously. Will cause OOM if the models are\n    large.\n\n\nsave_dir (str):\n The base directory where the data of the engine\n    will be stored.\n\n\n\n\nReferences:\n\n\n\n\nParallel Architecture and Hyperparameter Search via Successive Halving and Classification\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If \ntotal budget\n is not divisible by \nbatch size\n.\n\n\n\n\n\n\nTensorflowSHAC methods\n\u00b6\n\n\nfit\n\u00b6\n\n\nfit\n(\neval_fn\n,\n \nskip_cv_checks\n=\nFalse\n,\n \nearly_stop\n=\nFalse\n,\n \nrelax_checks\n=\nFalse\n,\n \ncallbacks\n=\nNone\n)\n\n\n\n\n\nGenerated batches of samples, trains \ntotal_classifiers\n number of XGBoost models\nand evaluates each batch with the supplied function in parallel.\n\n\nAllows manually changing the number of processes that are used to generate samples\nor to evaluate them. While the defaults generally work well, further performance\ngains can be had by trying different values according to the limits of the system.\n\n\n>>>\n \neval\n \n=\n \nlambda\n \nid\n,\n \nparams\n:\n \nnp\n.\nexp\n(\nparams\n[\n'x'\n])\n\n\n>>>\n \nshac\n \n=\n \nTensorflowSHAC\n(\nparams\n,\n \ntotal_budget\n=\n100\n,\n \nnum_batches\n=\n10\n)\n\n\n\n>>>\n \nshac\n.\nset_num_parallel_generators\n(\n20\n)\n  \n# change the number of generator process\n\n\n>>>\n \nshac\n.\nset_num_parallel_evaluators\n(\n1\n)\n  \n# change the number of evaluator processes\n\n\n>>>\n \nshac\n.\ngenerator_backend\n \n=\n \n'multiprocessing'\n  \n# change the backend for the generator (default is `multiprocessing`)\n\n\n>>>\n \nshac\n.\nconcurrent_evaluators\n()\n  \n# change the backend of the evaluator to use `threading`\n\n\n\n\n\nHas an adaptive behaviour based on what epoch it is on, since later epochs require\nfar more number of samples to generate a single batch of samples. When the epoch\nnumber increases beyond 10, it doubles the number of generator processes.\n\n\nThis adaptivity can be removed by setting the parameter \nlimit_memory\n to True.\n\n>>> shac.limit_memory = True\n\n\n\nArguments:\n\n\n\n\nevaluation_function ((tf.Session, int, list) -> float):\n The evaluation function is\npassed a managed Tensorflow Session, the integer id (of the worker) and the\nsampled hyper parameters in an OrderedDict. The evaluation function is expected\nto pass a python floating point number representing the evaluated value.\n\n\nskip_cv_checks (bool):\n If set, will not perform 5 fold cross validation check\n    on the models before adding them to the classifer list. Useful when the\n    batch size is small.\n\n\nearly_stop (bool):\n Stop running if fail to find a classifier that beats the\n    last stage of evaluations.\n\n\nrelax_checks (bool):\n If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.\n\n\ncallbacks (list | None):\n Optional list of callbacks that are executed when\n    the engine is being trained. \nHistory\n callback is automatically added\n    for all calls to \nfit\n.\n\n\n\n\nReturns:\n\n\nA \nHistory\n object which tracks all the important information\nduring training, and can be accessed using \nhistory.history\n\nas a dictionary.\n\n\n\n\nfit_dataset\n\u00b6\n\n\nfit_dataset\n(\ndataset_path\n,\n \nskip_cv_checks\n=\nFalse\n,\n \nearly_stop\n=\nFalse\n,\n \npresort\n=\nTrue\n,\n \ncallbacks\n=\nNone\n)\n\n\n\n\n\nUses the provided dataset file to train the engine, instead of using\nthe sequentual halving and classification algorithm directly. The data\nprovided in the path must strictly follow the format of the dataset\nmaintained by the engine.\n\n\nStandard format of datasets:\n\n\nEach dataset csv file must contain an integer id column named \"id\"\nas its 1\nst\n column, followed by several columns describing the values\ntaken by the hyper parameters, and the final column must be for\nthe the objective criterion, and \nmust\n be named \"scores\".\n\n\nThe csv file \nmust\n contain a header, following the above format.\n\n\nExample:\n\n\nid,hp1,hp2,scores\n0,1,h1,1.0\n1,1,h2,0.2\n2,0,h1,0.0\n3,0,h3,0.5\n...\n\n\n\n\n\nArguments:\n\n\n\n\ndataset_path (str):\n The full or relative path to a csv file\n    containing the values of the dataset.\n\n\nskip_cv_checks (bool):\n If set, will not perform 5 fold cross\n    validation check on the models before adding them to the\n    classifer list. Useful when the batch size is small.\n\n\nearly_stop (bool):\n Stop running if fail to find a classifier\n    that beats the last stage of evaluations.\n\n\npresort (bool):\n Boolean flag to determine whether to sort\n    the values of the dataset prior to loading. Ascending or\n    descending sort is selected based on whether the engine\n    is maximizing or minimizing the objective. It is preferable\n    to set this always, to train better classifiers.\n\n\ncallbacks (list | None):\n Optional list of callbacks that are executed when\n    the engine is being trained. \nHistory\n callback is automatically added\n    for all calls to \nfit_dataset\n.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the number of hyper parameters in the file\n    are not the same as the number of hyper parameters\n    that are available to the engine or if the number of\n    samples in the provided dataset are less than the\n    required number of samples by the engine.\n\n\nFileNotFoundError\n: If the dataset is not available at the\n    provided filepath.\n\n\n\n\nReturns:\n\n\nA \nHistory\n object which tracks all the important information\nduring training, and can be accessed using \nhistory.history\n\nas a dictionary.\n\n\n\n\npredict\n\u00b6\n\n\npredict\n(\nnum_samples\n=\nNone\n,\n \nnum_batches\n=\nNone\n,\n \nnum_workers_per_batch\n=\nNone\n,\n \nrelax_checks\n=\nFalse\n,\n \nmax_classfiers\n=\nNone\n)\n\n\n\n\n\nUsing trained classifiers, sample the search space and predict which samples\ncan successfully pass through the cascade of classifiers.\n\n\nWhen using a full cascade of 18 classifiers, a vast amount of time to sample\na single sample.\n\n\n\n\nSample mode vs Batch mode\n\n\n\n\nParameters can be generated in either sample mode or batch mode or any combination\nof the two.\n\n\nnum_samples\n is on a per sample basis (1 sample generated per count). Can be \nNone\n or an int >= 0.\n\nnum_batches\n is on a per batch basis (M samples generated per count). Can be \nNone\n or an integer >= 0.\n\n\nThe two are combined to produce a total number of samples which are provided in a\nlist.\n\n\nArguments:\n\n\n\n\nnum_samples (None | int):\n Number of samples to be generated.\n\n\nnum_batches (None | int):\n Number of batches of samples to be generated.\n\n\nnum_workers_per_batch (int):\n Determines how many parallel threads / processes\n    are created to generate the batches. For small batches, it is best to use 1.\n    If left as \nNone\n, defaults to \nnum_parallel_generators\n.\n\n\nrelax_checks (bool):\n If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.\n\n\nmax_classfiers (int | None):\n Number of classifiers to use for sampling.\n    If set to None, will use all classifiers.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If \nmax_classifiers\n is larger than the number of available\n    classifiers.\n\n\n\n\nReturns:\n\n\nbatches of samples in the form of an OrderedDict\n\n\n\n\nsave_data\n\u00b6\n\n\nsave_data\n()\n\n\n\n\n\nSerialize the class objects by serializing the dataset and the trained models.\n\n\n\n\nrestore_data\n\u00b6\n\n\nrestore_data\n()\n\n\n\n\n\nRecover the serialized class objects by loading the dataset and the trained models\nfrom the default save directories.\n\n\n\n\nset_num_parallel_generators\n\u00b6\n\n\nset_num_parallel_generators\n(\nn\n)\n\n\n\n\n\nCheck and sets the number of parallel generators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.\n\n\nArguments:\n\n\n\n\nn (int | None):\n The number of parallel generators required.\n\n\n\n\n\n\nset_num_parallel_evaluators\n\u00b6\n\n\nset_num_parallel_evaluators\n(\nn\n)\n\n\n\n\n\nCheck and sets the number of parallel evaluators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.\n\n\nArguments:\n\n\n\n\nn (int | None):\n The number of parallel evaluators required.\n\n\n\n\n\n\nparallel_evaluators\n\u00b6\n\n\nparallel_evaluators\n()\n\n\n\n\n\nSets the evaluators to use the \nloky\n backend.\n\n\nThe user must take the responsibility of thread safety and memory management.\n\n\n\n\nconcurrent_evaluators\n\u00b6\n\n\nconcurrent_evaluators\n()\n\n\n\n\n\nSets the evaluators to use the threading backend, and therefore\nbe locked by Python's GIL.\n\n\nWhile technically still \"parallel\", it is in fact concurrent execution\nrather than parallel execution of the evaluators.",
            "title": "Tensorflow SHAC"
        },
        {
            "location": "/core/tf_engine/#shac-managed-engine-for-tensorflow",
            "text": "Provides a managed engine for Tensorflow workflows when using SHAC.  Performs a few useful tasks such as :    Provide a tf.Session object: In addition to the worker id and the parameter dictionary, a tf.Session is provided as the first\nparameter to the evaluation function. This session wraps the underlying graph, and can be used to freely evaluate all operations\ninside the evaluation function.    Graph scope management: All Tensorflow operations inside the evalution function will be under the scope of a managed tf.Graph,\nsuch that the provided session can be used to evaluate all ops inside the evaluation function.    Memory Management: One the evaluation is done, the graph destruction and session closing are managed automatically.    If parallel evaluation is not preferred, please refer the  Serial Evaluation  page.",
            "title": "SHAC Managed Engine for Tensorflow"
        },
        {
            "location": "/core/tf_engine/#class-information",
            "text": "[source]",
            "title": "Class Information"
        },
        {
            "location": "/core/tf_engine/#tensorflowshac",
            "text": "pyshac . core . managed . tf_engine . TensorflowSHAC ( hyperparameter_list ,   total_budget ,   num_batches ,   max_gpu_evaluators ,   objective = 'max' ,   max_classifiers = 18 ,   max_cpu_evaluators = 1 ,   save_dir = 'shac' )   SHAC Engine specifically built for the Graph based workflow of Tensorflow.  It wraps the abstract SHAC engine with utilities to improve workflow with Tensorflow,\nand performs additional maintenance over the evaluation function, such as creating a\ngraph and session for it, and then destroying it and releasing its resources once\nevaluation is over.  This engine is suitable for Tensorflow based work. Since tensorflow allocates\nmemory to the graph, graph maintanence is managed as much as possible. As long\nas the system has enough memory to run multiple copies of the evaluation model,\nthere is no additional work required by the user inside the evaluation function.  Note : When using Eager Execution, it is preferred to use the default  SHAC  engine,\nas memory management is done by Tensorflow automatically in such a scenario.  Arguments:   hyperparameter_list (hp.HyperParameterList | None):  A list of parameters\n    (or a HyperParameterList) that are passed to define the search space.\n    Can be None, so that it is loaded from disk instead.  total_budget (int):   N . Defines the total number of models to evaluate.  num_batches (int):   M . Defines the number of batches the work is distributed\n    to. Must be set such that  total budget  is divisible by  batch size .  max_gpu_evaluators (int):  number of gpus. Can be 0 or more. Decides the number of\n    GPUs used to evaluate models in parallel.  objective (str):  Can be  max  or  min . Whether to maximise the evaluation\n    measure or minimize it.  max_classifiers (int):  Maximum number of classifiers that\n    are trained. Default (18) is according to the paper.  max_cpu_evaluators (int):  Positive integer > 0 or -1. Sets the number\n    of parallel evaluation functions calls are executed simultaneously.\n    Set this to 1 unless you have a lot of memory for 2 or more models\n    to be trained simultaneously. If set to -1, uses all CPU cores to\n    evaluate N models simultaneously. Will cause OOM if the models are\n    large.  save_dir (str):  The base directory where the data of the engine\n    will be stored.   References:   Parallel Architecture and Hyperparameter Search via Successive Halving and Classification   Raises:   ValueError : If  total budget  is not divisible by  batch size .",
            "title": "TensorflowSHAC"
        },
        {
            "location": "/core/tf_engine/#tensorflowshac-methods",
            "text": "",
            "title": "TensorflowSHAC methods"
        },
        {
            "location": "/core/tf_engine/#fit",
            "text": "fit ( eval_fn ,   skip_cv_checks = False ,   early_stop = False ,   relax_checks = False ,   callbacks = None )   Generated batches of samples, trains  total_classifiers  number of XGBoost models\nand evaluates each batch with the supplied function in parallel.  Allows manually changing the number of processes that are used to generate samples\nor to evaluate them. While the defaults generally work well, further performance\ngains can be had by trying different values according to the limits of the system.  >>>   eval   =   lambda   id ,   params :   np . exp ( params [ 'x' ])  >>>   shac   =   TensorflowSHAC ( params ,   total_budget = 100 ,   num_batches = 10 )  >>>   shac . set_num_parallel_generators ( 20 )    # change the number of generator process  >>>   shac . set_num_parallel_evaluators ( 1 )    # change the number of evaluator processes  >>>   shac . generator_backend   =   'multiprocessing'    # change the backend for the generator (default is `multiprocessing`)  >>>   shac . concurrent_evaluators ()    # change the backend of the evaluator to use `threading`   Has an adaptive behaviour based on what epoch it is on, since later epochs require\nfar more number of samples to generate a single batch of samples. When the epoch\nnumber increases beyond 10, it doubles the number of generator processes.  This adaptivity can be removed by setting the parameter  limit_memory  to True. >>> shac.limit_memory = True  Arguments:   evaluation_function ((tf.Session, int, list) -> float):  The evaluation function is\npassed a managed Tensorflow Session, the integer id (of the worker) and the\nsampled hyper parameters in an OrderedDict. The evaluation function is expected\nto pass a python floating point number representing the evaluated value.  skip_cv_checks (bool):  If set, will not perform 5 fold cross validation check\n    on the models before adding them to the classifer list. Useful when the\n    batch size is small.  early_stop (bool):  Stop running if fail to find a classifier that beats the\n    last stage of evaluations.  relax_checks (bool):  If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.  callbacks (list | None):  Optional list of callbacks that are executed when\n    the engine is being trained.  History  callback is automatically added\n    for all calls to  fit .   Returns:  A  History  object which tracks all the important information\nduring training, and can be accessed using  history.history \nas a dictionary.",
            "title": "fit"
        },
        {
            "location": "/core/tf_engine/#fit_dataset",
            "text": "fit_dataset ( dataset_path ,   skip_cv_checks = False ,   early_stop = False ,   presort = True ,   callbacks = None )   Uses the provided dataset file to train the engine, instead of using\nthe sequentual halving and classification algorithm directly. The data\nprovided in the path must strictly follow the format of the dataset\nmaintained by the engine.  Standard format of datasets:  Each dataset csv file must contain an integer id column named \"id\"\nas its 1 st  column, followed by several columns describing the values\ntaken by the hyper parameters, and the final column must be for\nthe the objective criterion, and  must  be named \"scores\".  The csv file  must  contain a header, following the above format.  Example:  id,hp1,hp2,scores\n0,1,h1,1.0\n1,1,h2,0.2\n2,0,h1,0.0\n3,0,h3,0.5\n...  Arguments:   dataset_path (str):  The full or relative path to a csv file\n    containing the values of the dataset.  skip_cv_checks (bool):  If set, will not perform 5 fold cross\n    validation check on the models before adding them to the\n    classifer list. Useful when the batch size is small.  early_stop (bool):  Stop running if fail to find a classifier\n    that beats the last stage of evaluations.  presort (bool):  Boolean flag to determine whether to sort\n    the values of the dataset prior to loading. Ascending or\n    descending sort is selected based on whether the engine\n    is maximizing or minimizing the objective. It is preferable\n    to set this always, to train better classifiers.  callbacks (list | None):  Optional list of callbacks that are executed when\n    the engine is being trained.  History  callback is automatically added\n    for all calls to  fit_dataset .   Raises:   ValueError : If the number of hyper parameters in the file\n    are not the same as the number of hyper parameters\n    that are available to the engine or if the number of\n    samples in the provided dataset are less than the\n    required number of samples by the engine.  FileNotFoundError : If the dataset is not available at the\n    provided filepath.   Returns:  A  History  object which tracks all the important information\nduring training, and can be accessed using  history.history \nas a dictionary.",
            "title": "fit_dataset"
        },
        {
            "location": "/core/tf_engine/#predict",
            "text": "predict ( num_samples = None ,   num_batches = None ,   num_workers_per_batch = None ,   relax_checks = False ,   max_classfiers = None )   Using trained classifiers, sample the search space and predict which samples\ncan successfully pass through the cascade of classifiers.  When using a full cascade of 18 classifiers, a vast amount of time to sample\na single sample.   Sample mode vs Batch mode   Parameters can be generated in either sample mode or batch mode or any combination\nof the two.  num_samples  is on a per sample basis (1 sample generated per count). Can be  None  or an int >= 0. num_batches  is on a per batch basis (M samples generated per count). Can be  None  or an integer >= 0.  The two are combined to produce a total number of samples which are provided in a\nlist.  Arguments:   num_samples (None | int):  Number of samples to be generated.  num_batches (None | int):  Number of batches of samples to be generated.  num_workers_per_batch (int):  Determines how many parallel threads / processes\n    are created to generate the batches. For small batches, it is best to use 1.\n    If left as  None , defaults to  num_parallel_generators .  relax_checks (bool):  If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.  max_classfiers (int | None):  Number of classifiers to use for sampling.\n    If set to None, will use all classifiers.   Raises:   ValueError : If  max_classifiers  is larger than the number of available\n    classifiers.   Returns:  batches of samples in the form of an OrderedDict",
            "title": "predict"
        },
        {
            "location": "/core/tf_engine/#save_data",
            "text": "save_data ()   Serialize the class objects by serializing the dataset and the trained models.",
            "title": "save_data"
        },
        {
            "location": "/core/tf_engine/#restore_data",
            "text": "restore_data ()   Recover the serialized class objects by loading the dataset and the trained models\nfrom the default save directories.",
            "title": "restore_data"
        },
        {
            "location": "/core/tf_engine/#set_num_parallel_generators",
            "text": "set_num_parallel_generators ( n )   Check and sets the number of parallel generators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.  Arguments:   n (int | None):  The number of parallel generators required.",
            "title": "set_num_parallel_generators"
        },
        {
            "location": "/core/tf_engine/#set_num_parallel_evaluators",
            "text": "set_num_parallel_evaluators ( n )   Check and sets the number of parallel evaluators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.  Arguments:   n (int | None):  The number of parallel evaluators required.",
            "title": "set_num_parallel_evaluators"
        },
        {
            "location": "/core/tf_engine/#parallel_evaluators",
            "text": "parallel_evaluators ()   Sets the evaluators to use the  loky  backend.  The user must take the responsibility of thread safety and memory management.",
            "title": "parallel_evaluators"
        },
        {
            "location": "/core/tf_engine/#concurrent_evaluators",
            "text": "concurrent_evaluators ()   Sets the evaluators to use the threading backend, and therefore\nbe locked by Python's GIL.  While technically still \"parallel\", it is in fact concurrent execution\nrather than parallel execution of the evaluators.",
            "title": "concurrent_evaluators"
        },
        {
            "location": "/core/keras_engine/",
            "text": "SHAC Managed Engine for Keras (Tensorflow/CNTK)\n\u00b6\n\n\n\n\nProvides a managed engine for Keras with the Tensorflow / CNTK backend when using SHAC.\n\n\nPerforms a few useful tasks (for tensorflow) such as :\n\n\n\n\n\n\nProvide a tf.Session object: In addition to the worker id and the parameter dictionary, a tf.Session is provided as the first\nparameter to the evaluation function. This session wraps the underlying graph, and can be used to freely evaluate all operations\ninside the evaluation function.\n\n\n\n\n\n\nGraph scope management: All Tensorflow operations inside the evalution function will be under the scope of a managed tf.Graph,\nsuch that the provided session can be used to evaluate all ops inside the evaluation function.\n\n\n\n\n\n\nMemory Management: One the evaluation is done, the graph destruction and session closing are managed automatically.\n\n\n\n\n\n\nIf parallel evaluation is not preferred, please refer the \nSerial Evaluation\n page.\n\n\nClass Information\n\u00b6\n\n\n\n\n[source]\n\n\nKerasSHAC\n\u00b6\n\n\npyshac\n.\ncore\n.\nmanaged\n.\nkeras_engine\n.\nKerasSHAC\n(\nhyperparameter_list\n,\n \ntotal_budget\n,\n \nnum_batches\n,\n \nmax_gpu_evaluators\n,\n \nobjective\n=\n'max'\n,\n \nmax_classifiers\n=\n18\n,\n \nmax_cpu_evaluators\n=\n1\n,\n \nsave_dir\n=\n'shac'\n)\n\n\n\n\n\nSHAC Engine specifically built for the Keras wrapper over the Graph based workflow\nof Tensorflow. It can also support CNTK, though it is not well tested.\n\n\nIt wraps the abstract SHAC engine with utilities to improve workflow with Keras,\nand performs additional maintenance over the evaluation function, such as creating a\ngraph and session for it, assigning it to the backend and then destroying it and\nreleasing its resources once evaluation is over.\n\n\nThis provides a cleaner interface to the Tensorflow codebase, and eases the building of\nmodels for evaluation. As long as the system has enough memory to run multiple copies of\nthe evaluation model, there is no additional work required by the user inside the evaluation\nfunction.\n\n\nNote : When using Eager Execution, it is preferred to use the default \nSHAC\n engine,\nand use \ntf.keras\n, as memory management is done by Tensorflow automatically in such\na scenario.\n\n\nArguments:\n\n\n\n\nhyperparameter_list (hp.HyperParameterList | None):\n A list of parameters\n    (or a HyperParameterList) that are passed to define the search space.\n    Can be None, so that it is loaded from disk instead.\n\n\ntotal_budget (int):\n \nN\n. Defines the total number of models to evaluate.\n\n\nnum_batches (int):\n \nM\n. Defines the number of batches the work is distributed\n    to. Must be set such that \ntotal budget\n is divisible by \nbatch size\n.\n\n\nmax_gpu_evaluators (int):\n number of gpus. Can be 0 or more. Decides the number of\n    GPUs used to evaluate models in parallel.\n\n\nobjective (str):\n Can be \nmax\n or \nmin\n. Whether to maximise the evaluation\n    measure or minimize it.\n\n\nmax_classifiers (int):\n Maximum number of classifiers that\n    are trained. Default (18) is according to the paper.\n\n\nmax_cpu_evaluators (int):\n Positive integer > 0 or -1. Sets the number\n    of parallel evaluation functions calls are executed simultaneously.\n    Set this to 1 unless you have a lot of memory for 2 or more models\n    to be trained simultaneously. If set to -1, uses all CPU cores to\n    evaluate N models simultaneously. Will cause OOM if the models are\n    large.\n\n\nsave_dir (str):\n The base directory where the data of the engine\n    will be stored.\n\n\n\n\nReferences:\n\n\n\n\nParallel Architecture and Hyperparameter Search via Successive Halving and Classification\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If keras backend is not Tensorflow or CNTK.\n\n\nValueError\n: If \ntotal budget\n is not divisible by \nbatch size\n.\n\n\n\n\n\n\nKerasSHAC methods\n\u00b6\n\n\nfit\n\u00b6\n\n\nfit\n(\neval_fn\n,\n \nskip_cv_checks\n=\nFalse\n,\n \nearly_stop\n=\nFalse\n,\n \nrelax_checks\n=\nFalse\n,\n \ncallbacks\n=\nNone\n)\n\n\n\n\n\nGenerated batches of samples, trains \ntotal_classifiers\n number of XGBoost models\nand evaluates each batch with the supplied function in parallel.\n\n\nAllows manually changing the number of processes that are used to generate samples\nor to evaluate them. While the defaults generally work well, further performance\ngains can be had by trying different values according to the limits of the system.\n\n\n>>>\n \neval\n \n=\n \nlambda\n \nid\n,\n \nparams\n:\n \nnp\n.\nexp\n(\nparams\n[\n'x'\n])\n\n\n>>>\n \nshac\n \n=\n \nKerasSHAC\n(\nparams\n,\n \ntotal_budget\n=\n100\n,\n \nnum_batches\n=\n10\n)\n\n\n\n>>>\n \nshac\n.\nset_num_parallel_generators\n(\n20\n)\n  \n# change the number of generator process\n\n\n>>>\n \nshac\n.\nset_num_parallel_evaluators\n(\n1\n)\n  \n# change the number of evaluator processes\n\n\n>>>\n \nshac\n.\ngenerator_backend\n \n=\n \n'multiprocessing'\n  \n# change the backend for the generator (default is `multiprocessing`)\n\n\n>>>\n \nshac\n.\nconcurrent_evaluators\n()\n  \n# change the backend of the evaluator to use `threading`\n\n\n\n\n\nHas an adaptive behaviour based on what epoch it is on, since later epochs require\nfar more number of samples to generate a single batch of samples. When the epoch\nnumber increases beyond 10, it doubles the number of generator processes.\n\n\nThis adaptivity can be removed by setting the parameter \nlimit_memory\n to True.\n\n>>> shac.limit_memory = True\n\n\n\nArguments:\n\n\n\n\nevaluation_function ((tf.Session, int, list) -> float):\n The evaluation function is\n    passed a managed Tensorflow Session, the integer id (of the worker) and the\n    sampled hyper parameters in an OrderedDict. The evaluation function is expected\n    to pass a python floating point number representing the evaluated value.\n\n\nskip_cv_checks (bool):\n If set, will not perform 5 fold cross validation check\n    on the models before adding them to the classifer list. Useful when the\n    batch size is small.\n\n\nearly_stop (bool):\n Stop running if fail to find a classifier that beats the\n    last stage of evaluations.\n\n\nrelax_checks (bool):\n If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.\n\n\ncallbacks (list | None):\n Optional list of callbacks that are executed when\n    the engine is being trained. \nHistory\n callback is automatically added\n    for all calls to \nfit\n.\n\n\n\n\nReturns:\n\n\nA \nHistory\n object which tracks all the important information\nduring training, and can be accessed using \nhistory.history\n\nas a dictionary.\n\n\n\n\nfit_dataset\n\u00b6\n\n\nfit_dataset\n(\ndataset_path\n,\n \nskip_cv_checks\n=\nFalse\n,\n \nearly_stop\n=\nFalse\n,\n \npresort\n=\nTrue\n,\n \ncallbacks\n=\nNone\n)\n\n\n\n\n\nUses the provided dataset file to train the engine, instead of using\nthe sequentual halving and classification algorithm directly. The data\nprovided in the path must strictly follow the format of the dataset\nmaintained by the engine.\n\n\nStandard format of datasets:\n\n\nEach dataset csv file must contain an integer id column named \"id\"\nas its 1\nst\n column, followed by several columns describing the values\ntaken by the hyper parameters, and the final column must be for\nthe the objective criterion, and \nmust\n be named \"scores\".\n\n\nThe csv file \nmust\n contain a header, following the above format.\n\n\nExample:\n\n\nid,hp1,hp2,scores\n0,1,h1,1.0\n1,1,h2,0.2\n2,0,h1,0.0\n3,0,h3,0.5\n...\n\n\n\n\n\nArguments:\n\n\n\n\ndataset_path (str):\n The full or relative path to a csv file\n    containing the values of the dataset.\n\n\nskip_cv_checks (bool):\n If set, will not perform 5 fold cross\n    validation check on the models before adding them to the\n    classifer list. Useful when the batch size is small.\n\n\nearly_stop (bool):\n Stop running if fail to find a classifier\n    that beats the last stage of evaluations.\n\n\npresort (bool):\n Boolean flag to determine whether to sort\n    the values of the dataset prior to loading. Ascending or\n    descending sort is selected based on whether the engine\n    is maximizing or minimizing the objective. It is preferable\n    to set this always, to train better classifiers.\n\n\ncallbacks (list | None):\n Optional list of callbacks that are executed when\n    the engine is being trained. \nHistory\n callback is automatically added\n    for all calls to \nfit_dataset\n.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If the number of hyper parameters in the file\n    are not the same as the number of hyper parameters\n    that are available to the engine or if the number of\n    samples in the provided dataset are less than the\n    required number of samples by the engine.\n\n\nFileNotFoundError\n: If the dataset is not available at the\n    provided filepath.\n\n\n\n\nReturns:\n\n\nA \nHistory\n object which tracks all the important information\nduring training, and can be accessed using \nhistory.history\n\nas a dictionary.\n\n\n\n\npredict\n\u00b6\n\n\npredict\n(\nnum_samples\n=\nNone\n,\n \nnum_batches\n=\nNone\n,\n \nnum_workers_per_batch\n=\nNone\n,\n \nrelax_checks\n=\nFalse\n,\n \nmax_classfiers\n=\nNone\n)\n\n\n\n\n\nUsing trained classifiers, sample the search space and predict which samples\ncan successfully pass through the cascade of classifiers.\n\n\nWhen using a full cascade of 18 classifiers, a vast amount of time to sample\na single sample.\n\n\n\n\nSample mode vs Batch mode\n\n\n\n\nParameters can be generated in either sample mode or batch mode or any combination\nof the two.\n\n\nnum_samples\n is on a per sample basis (1 sample generated per count). Can be \nNone\n or an int >= 0.\n\nnum_batches\n is on a per batch basis (M samples generated per count). Can be \nNone\n or an integer >= 0.\n\n\nThe two are combined to produce a total number of samples which are provided in a\nlist.\n\n\nArguments:\n\n\n\n\nnum_samples (None | int):\n Number of samples to be generated.\n\n\nnum_batches (None | int):\n Number of batches of samples to be generated.\n\n\nnum_workers_per_batch (int):\n Determines how many parallel threads / processes\n    are created to generate the batches. For small batches, it is best to use 1.\n    If left as \nNone\n, defaults to \nnum_parallel_generators\n.\n\n\nrelax_checks (bool):\n If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.\n\n\nmax_classfiers (int | None):\n Number of classifiers to use for sampling.\n    If set to None, will use all classifiers.\n\n\n\n\nRaises:\n\n\n\n\nValueError\n: If \nmax_classifiers\n is larger than the number of available\n    classifiers.\n\n\n\n\nReturns:\n\n\nbatches of samples in the form of an OrderedDict\n\n\n\n\nsave_data\n\u00b6\n\n\nsave_data\n()\n\n\n\n\n\nSerialize the class objects by serializing the dataset and the trained models.\n\n\n\n\nrestore_data\n\u00b6\n\n\nrestore_data\n()\n\n\n\n\n\nRecover the serialized class objects by loading the dataset and the trained models\nfrom the default save directories.\n\n\n\n\nset_num_parallel_generators\n\u00b6\n\n\nset_num_parallel_generators\n(\nn\n)\n\n\n\n\n\nCheck and sets the number of parallel generators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.\n\n\nArguments:\n\n\n\n\nn (int | None):\n The number of parallel generators required.\n\n\n\n\n\n\nset_num_parallel_evaluators\n\u00b6\n\n\nset_num_parallel_evaluators\n(\nn\n)\n\n\n\n\n\nCheck and sets the number of parallel evaluators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.\n\n\nArguments:\n\n\n\n\nn (int | None):\n The number of parallel evaluators required.\n\n\n\n\n\n\nparallel_evaluators\n\u00b6\n\n\nparallel_evaluators\n()\n\n\n\n\n\nSets the evaluators to use the \nloky\n backend.\n\n\nThe user must take the responsibility of thread safety and memory management.\n\n\n\n\nconcurrent_evaluators\n\u00b6\n\n\nconcurrent_evaluators\n()\n\n\n\n\n\nSets the evaluators to use the threading backend, and therefore\nbe locked by Python's GIL.\n\n\nWhile technically still \"parallel\", it is in fact concurrent execution\nrather than parallel execution of the evaluators.",
            "title": "Keras SHAC"
        },
        {
            "location": "/core/keras_engine/#shac-managed-engine-for-keras-tensorflowcntk",
            "text": "Provides a managed engine for Keras with the Tensorflow / CNTK backend when using SHAC.  Performs a few useful tasks (for tensorflow) such as :    Provide a tf.Session object: In addition to the worker id and the parameter dictionary, a tf.Session is provided as the first\nparameter to the evaluation function. This session wraps the underlying graph, and can be used to freely evaluate all operations\ninside the evaluation function.    Graph scope management: All Tensorflow operations inside the evalution function will be under the scope of a managed tf.Graph,\nsuch that the provided session can be used to evaluate all ops inside the evaluation function.    Memory Management: One the evaluation is done, the graph destruction and session closing are managed automatically.    If parallel evaluation is not preferred, please refer the  Serial Evaluation  page.",
            "title": "SHAC Managed Engine for Keras (Tensorflow/CNTK)"
        },
        {
            "location": "/core/keras_engine/#class-information",
            "text": "[source]",
            "title": "Class Information"
        },
        {
            "location": "/core/keras_engine/#kerasshac",
            "text": "pyshac . core . managed . keras_engine . KerasSHAC ( hyperparameter_list ,   total_budget ,   num_batches ,   max_gpu_evaluators ,   objective = 'max' ,   max_classifiers = 18 ,   max_cpu_evaluators = 1 ,   save_dir = 'shac' )   SHAC Engine specifically built for the Keras wrapper over the Graph based workflow\nof Tensorflow. It can also support CNTK, though it is not well tested.  It wraps the abstract SHAC engine with utilities to improve workflow with Keras,\nand performs additional maintenance over the evaluation function, such as creating a\ngraph and session for it, assigning it to the backend and then destroying it and\nreleasing its resources once evaluation is over.  This provides a cleaner interface to the Tensorflow codebase, and eases the building of\nmodels for evaluation. As long as the system has enough memory to run multiple copies of\nthe evaluation model, there is no additional work required by the user inside the evaluation\nfunction.  Note : When using Eager Execution, it is preferred to use the default  SHAC  engine,\nand use  tf.keras , as memory management is done by Tensorflow automatically in such\na scenario.  Arguments:   hyperparameter_list (hp.HyperParameterList | None):  A list of parameters\n    (or a HyperParameterList) that are passed to define the search space.\n    Can be None, so that it is loaded from disk instead.  total_budget (int):   N . Defines the total number of models to evaluate.  num_batches (int):   M . Defines the number of batches the work is distributed\n    to. Must be set such that  total budget  is divisible by  batch size .  max_gpu_evaluators (int):  number of gpus. Can be 0 or more. Decides the number of\n    GPUs used to evaluate models in parallel.  objective (str):  Can be  max  or  min . Whether to maximise the evaluation\n    measure or minimize it.  max_classifiers (int):  Maximum number of classifiers that\n    are trained. Default (18) is according to the paper.  max_cpu_evaluators (int):  Positive integer > 0 or -1. Sets the number\n    of parallel evaluation functions calls are executed simultaneously.\n    Set this to 1 unless you have a lot of memory for 2 or more models\n    to be trained simultaneously. If set to -1, uses all CPU cores to\n    evaluate N models simultaneously. Will cause OOM if the models are\n    large.  save_dir (str):  The base directory where the data of the engine\n    will be stored.   References:   Parallel Architecture and Hyperparameter Search via Successive Halving and Classification   Raises:   ValueError : If keras backend is not Tensorflow or CNTK.  ValueError : If  total budget  is not divisible by  batch size .",
            "title": "KerasSHAC"
        },
        {
            "location": "/core/keras_engine/#kerasshac-methods",
            "text": "",
            "title": "KerasSHAC methods"
        },
        {
            "location": "/core/keras_engine/#fit",
            "text": "fit ( eval_fn ,   skip_cv_checks = False ,   early_stop = False ,   relax_checks = False ,   callbacks = None )   Generated batches of samples, trains  total_classifiers  number of XGBoost models\nand evaluates each batch with the supplied function in parallel.  Allows manually changing the number of processes that are used to generate samples\nor to evaluate them. While the defaults generally work well, further performance\ngains can be had by trying different values according to the limits of the system.  >>>   eval   =   lambda   id ,   params :   np . exp ( params [ 'x' ])  >>>   shac   =   KerasSHAC ( params ,   total_budget = 100 ,   num_batches = 10 )  >>>   shac . set_num_parallel_generators ( 20 )    # change the number of generator process  >>>   shac . set_num_parallel_evaluators ( 1 )    # change the number of evaluator processes  >>>   shac . generator_backend   =   'multiprocessing'    # change the backend for the generator (default is `multiprocessing`)  >>>   shac . concurrent_evaluators ()    # change the backend of the evaluator to use `threading`   Has an adaptive behaviour based on what epoch it is on, since later epochs require\nfar more number of samples to generate a single batch of samples. When the epoch\nnumber increases beyond 10, it doubles the number of generator processes.  This adaptivity can be removed by setting the parameter  limit_memory  to True. >>> shac.limit_memory = True  Arguments:   evaluation_function ((tf.Session, int, list) -> float):  The evaluation function is\n    passed a managed Tensorflow Session, the integer id (of the worker) and the\n    sampled hyper parameters in an OrderedDict. The evaluation function is expected\n    to pass a python floating point number representing the evaluated value.  skip_cv_checks (bool):  If set, will not perform 5 fold cross validation check\n    on the models before adding them to the classifer list. Useful when the\n    batch size is small.  early_stop (bool):  Stop running if fail to find a classifier that beats the\n    last stage of evaluations.  relax_checks (bool):  If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.  callbacks (list | None):  Optional list of callbacks that are executed when\n    the engine is being trained.  History  callback is automatically added\n    for all calls to  fit .   Returns:  A  History  object which tracks all the important information\nduring training, and can be accessed using  history.history \nas a dictionary.",
            "title": "fit"
        },
        {
            "location": "/core/keras_engine/#fit_dataset",
            "text": "fit_dataset ( dataset_path ,   skip_cv_checks = False ,   early_stop = False ,   presort = True ,   callbacks = None )   Uses the provided dataset file to train the engine, instead of using\nthe sequentual halving and classification algorithm directly. The data\nprovided in the path must strictly follow the format of the dataset\nmaintained by the engine.  Standard format of datasets:  Each dataset csv file must contain an integer id column named \"id\"\nas its 1 st  column, followed by several columns describing the values\ntaken by the hyper parameters, and the final column must be for\nthe the objective criterion, and  must  be named \"scores\".  The csv file  must  contain a header, following the above format.  Example:  id,hp1,hp2,scores\n0,1,h1,1.0\n1,1,h2,0.2\n2,0,h1,0.0\n3,0,h3,0.5\n...  Arguments:   dataset_path (str):  The full or relative path to a csv file\n    containing the values of the dataset.  skip_cv_checks (bool):  If set, will not perform 5 fold cross\n    validation check on the models before adding them to the\n    classifer list. Useful when the batch size is small.  early_stop (bool):  Stop running if fail to find a classifier\n    that beats the last stage of evaluations.  presort (bool):  Boolean flag to determine whether to sort\n    the values of the dataset prior to loading. Ascending or\n    descending sort is selected based on whether the engine\n    is maximizing or minimizing the objective. It is preferable\n    to set this always, to train better classifiers.  callbacks (list | None):  Optional list of callbacks that are executed when\n    the engine is being trained.  History  callback is automatically added\n    for all calls to  fit_dataset .   Raises:   ValueError : If the number of hyper parameters in the file\n    are not the same as the number of hyper parameters\n    that are available to the engine or if the number of\n    samples in the provided dataset are less than the\n    required number of samples by the engine.  FileNotFoundError : If the dataset is not available at the\n    provided filepath.   Returns:  A  History  object which tracks all the important information\nduring training, and can be accessed using  history.history \nas a dictionary.",
            "title": "fit_dataset"
        },
        {
            "location": "/core/keras_engine/#predict",
            "text": "predict ( num_samples = None ,   num_batches = None ,   num_workers_per_batch = None ,   relax_checks = False ,   max_classfiers = None )   Using trained classifiers, sample the search space and predict which samples\ncan successfully pass through the cascade of classifiers.  When using a full cascade of 18 classifiers, a vast amount of time to sample\na single sample.   Sample mode vs Batch mode   Parameters can be generated in either sample mode or batch mode or any combination\nof the two.  num_samples  is on a per sample basis (1 sample generated per count). Can be  None  or an int >= 0. num_batches  is on a per batch basis (M samples generated per count). Can be  None  or an integer >= 0.  The two are combined to produce a total number of samples which are provided in a\nlist.  Arguments:   num_samples (None | int):  Number of samples to be generated.  num_batches (None | int):  Number of batches of samples to be generated.  num_workers_per_batch (int):  Determines how many parallel threads / processes\n    are created to generate the batches. For small batches, it is best to use 1.\n    If left as  None , defaults to  num_parallel_generators .  relax_checks (bool):  If set, will allow samples who do not pass all of the\n    checks from all classifiers. Can be useful when large number of models\n    are present and remaining search space is not big enough to allow sample\n    to pass through all checks.  max_classfiers (int | None):  Number of classifiers to use for sampling.\n    If set to None, will use all classifiers.   Raises:   ValueError : If  max_classifiers  is larger than the number of available\n    classifiers.   Returns:  batches of samples in the form of an OrderedDict",
            "title": "predict"
        },
        {
            "location": "/core/keras_engine/#save_data",
            "text": "save_data ()   Serialize the class objects by serializing the dataset and the trained models.",
            "title": "save_data"
        },
        {
            "location": "/core/keras_engine/#restore_data",
            "text": "restore_data ()   Recover the serialized class objects by loading the dataset and the trained models\nfrom the default save directories.",
            "title": "restore_data"
        },
        {
            "location": "/core/keras_engine/#set_num_parallel_generators",
            "text": "set_num_parallel_generators ( n )   Check and sets the number of parallel generators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.  Arguments:   n (int | None):  The number of parallel generators required.",
            "title": "set_num_parallel_generators"
        },
        {
            "location": "/core/keras_engine/#set_num_parallel_evaluators",
            "text": "set_num_parallel_evaluators ( n )   Check and sets the number of parallel evaluators. If None, checks if the number\nof workers exceeds the number of virtual cores. If it does, it warns about it\nand sets the max parallel generators to be the number of cores.  Arguments:   n (int | None):  The number of parallel evaluators required.",
            "title": "set_num_parallel_evaluators"
        },
        {
            "location": "/core/keras_engine/#parallel_evaluators",
            "text": "parallel_evaluators ()   Sets the evaluators to use the  loky  backend.  The user must take the responsibility of thread safety and memory management.",
            "title": "parallel_evaluators"
        },
        {
            "location": "/core/keras_engine/#concurrent_evaluators",
            "text": "concurrent_evaluators ()   Sets the evaluators to use the threading backend, and therefore\nbe locked by Python's GIL.  While technically still \"parallel\", it is in fact concurrent execution\nrather than parallel execution of the evaluators.",
            "title": "concurrent_evaluators"
        },
        {
            "location": "/utils/vis_utils/",
            "text": "plot_dataset\n\u00b6\n\n\nplot_dataset\n(\ndataset\n,\n \nto_file\n=\n'dataset.png'\n,\n \ntitle\n=\n'Dataset evaluation'\n,\n \neval_label\n=\n'Score'\n,\n \ntrend_deg\n=\n3\n)\n\n\n\n\n\nPlots the training history of the provided dataset.\nCan be provided either the \nDataset\n object itself,\n\n\nArguments:\n\n\n\n\ndataset (Dataset | str):\n A Dataset which has been\n    restored or a string path to the root of the\n    shac directory where the dataset is stored.\n\n\nto_file (str | None):\n A string file name if the\n    dataset plot is to be stored in a file, or\n    \nNone\n if the image should not be saved to\n    a file.\n\n\ntitle (str):\n String label used as the title of\n    the plot.\n\n\neval_label (str):\n String label used as the y axis\n    label of the plot.\n\n\ntrend_degree (int):\n Degree of the polynomial which\n    fits the dataset to create the trend line.\n\n\n\n\nRaises:\n\n\n\n\nFileNotFoundError\n: If the provided dataset is a string\n    that does not point to the root of a shac\n    directory.\n\n\nValueError\n: If a loaded dataset object could not be\n    obtained to visualize.",
            "title": "Visualization"
        },
        {
            "location": "/utils/vis_utils/#plot_dataset",
            "text": "plot_dataset ( dataset ,   to_file = 'dataset.png' ,   title = 'Dataset evaluation' ,   eval_label = 'Score' ,   trend_deg = 3 )   Plots the training history of the provided dataset.\nCan be provided either the  Dataset  object itself,  Arguments:   dataset (Dataset | str):  A Dataset which has been\n    restored or a string path to the root of the\n    shac directory where the dataset is stored.  to_file (str | None):  A string file name if the\n    dataset plot is to be stored in a file, or\n     None  if the image should not be saved to\n    a file.  title (str):  String label used as the title of\n    the plot.  eval_label (str):  String label used as the y axis\n    label of the plot.  trend_degree (int):  Degree of the polynomial which\n    fits the dataset to create the trend line.   Raises:   FileNotFoundError : If the provided dataset is a string\n    that does not point to the root of a shac\n    directory.  ValueError : If a loaded dataset object could not be\n    obtained to visualize.",
            "title": "plot_dataset"
        }
    ]
}